[{"path":"https://zwcrowley.github.io/bre/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 bre authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"vignette-for-data-analysis-at-the-mark-usa-inc-","dir":"Articles","previous_headings":"","what":"Vignette for Data Analysis at The Mark USA, Inc.:","title":"bre","text":"file starting point data analysis task Mark. examples provided baseline-annual (pre-post) survey comparison, many ways workflow can used data tasks. vignette corresponding available template titled: “Data Analysis Mark USA, Inc.”. Please provide feedback use vignette determine tasks include templates construct.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"how-to-read-in--xlsx-data","dir":"Articles","previous_headings":"Loading baseline and annual data from .csv and .xlsx:","what":"How to read in .xlsx data:","title":"bre","text":"","code":"# readxl is a package that has the most up to date function for reading in excel files either .xls or xlsx, read_excel(), if you know the file is .xlsx you can use  # the function read_xlsx(), both are shown below: # For this example, the baseline data is in a folder called \"extdata\" which is located up four folders so ../ moves up one folder- # Read in the baseline.xlsx data using read_excel(): baseline <- readxl::read_excel(\"../inst/extdata/baseline.xlsx\")  # Read in the annual.xlsx data using read_xlsx(): annual <- readxl::read_xlsx(\"../inst/extdata/annual.xlsx\") # Remove to resuse names: rm(annual, baseline)"},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"how-to-read-in--csv-data","dir":"Articles","previous_headings":"Loading baseline and annual data from .csv and .xlsx:","what":"How to read in .csv data:","title":"bre","text":"","code":"# readr is a package included in \"tidyverse\" that has the most up to date function for reading in .csv data, read_csv(): # For this example, the baseline data is in a folder called \"extdata\" which is located up four folders so ../ moves up one folder- # Read in the baseline.csv data: baseline <- readr::read_csv(\"../inst/extdata/baseline.csv\")  # Read in the annual.csv data: annual <- readr::read_csv(\"../inst/extdata/annual.csv\")"},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"info-about-example-data-in-baseline-and-annual-datasets","dir":"Articles","previous_headings":"Loading baseline and annual data from .csv and .xlsx: > How to read in .csv data:","what":"Info about example data in baseline and annual datasets:","title":"bre","text":"dataset contains 7 variables 20 observations. Unique Identifier: unique ID (1 20) role: 1= “Undergraduate student”, 2 =“Graduate student”, 3= “Postdoc”, 4 = “Faculty” Gender: 1 = “male”, 2 = “female”, 3 = “” Institution: 1 = “University Place”, 2 = “State University Another Place”, 3 = “Technical State”, 4 = “University One Place” 5 variables make composite scale: Organization, Source, Publish, Write, Research 5-point Likert scale 1 5 needs recoded : c(“Minimal”, “Slight”, “Moderate”, “Good”, “Extensive”)","code":""},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"merging-data","dir":"Articles","previous_headings":"","what":"Merging data:","title":"bre","text":"R package dplyr, included tidyverse, includes many functions merge data sets, common “outer join” functions left_join() full_join(). Use full_join() want merge two datasets include observations datasets, commonly used want join datasets top bottom, see dpylr’s documentation examples. uses Mark, data merged using left_join(), function used merge data share common unique identifier keep observations occur one datasets. Specically, left_join() keeps observations first supplied dataset merges observations second dataset matches user supplied “” variable first dataset.","code":"# Merge the baseline and annual datasets using the variable `Unique Identifier` as the by argument inside join_by(\"\"), this is the variable that will match the observations from both datasets, the suffix argument is a c() of length two which is added to variables taken from the respective datasets, so for this example variables from baseline will have a suffix of \"{variable_name}_pre\" and variables from annual will have  \"{variable_name}_post\": merged_data <- baseline %>% left_join(., annual, by = join_by(\"Unique Identifier\"), suffix = c(\"_pre\",\"_post\")) # can also be written: merged_data <- left_join(baseline, annual, by = join_by(\"Unique Identifier\", \"role\"), suffix = c(\"_pre\",\"_post\")) # the new merged data has 14 variables, the original 9 from baseline and the 5 that match from the annuals dataset. # head(merged_data, n = 4)   # If you would rather use a prefix for pre and post this is one way to do that: # add prefix before joining, for baseline skip the first 4 vars and annual skip first var: names(baseline)[5:9] <- paste0(\"pre_\", names(baseline)[5:9]) names(annual)[2:6] <- paste0(\"post_\", names(annual)[2:6]) # in join, use names with prefixes merged_data <- baseline %>% left_join(annual, by = join_by(\"Unique Identifier\"))  # check variables from the merged_data using str() and summary(): str(merged_data) #> spc_tbl_ [20 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame) #>  $ Unique Identifier: num [1:20] 1 2 3 4 5 6 7 8 9 10 ... #>  $ Gender           : num [1:20] 1 2 2 2 2 2 1 2 1 1 ... #>  $ Role             : num [1:20] 1 2 2 4 4 1 2 2 1 2 ... #>  $ Institution      : num [1:20] 2 1 2 1 2 2 3 1 2 4 ... #>  $ pre_Organization : num [1:20] 5 3 3 1 2 2 5 2 5 2 ... #>  $ pre_Source       : num [1:20] 1 2 4 5 4 4 2 5 4 3 ... #>  $ pre_Publish      : num [1:20] 2 2 2 3 4 1 5 4 3 5 ... #>  $ pre_Write        : num [1:20] 4 1 3 3 2 2 5 2 2 2 ... #>  $ pre_Research     : num [1:20] 5 2 2 2 5 1 2 2 5 2 ... #>  $ post_Organization: num [1:20] 5 4 4 2 3 3 5 3 5 3 ... #>  $ post_Source      : num [1:20] 3 4 4 5 4 4 4 5 4 5 ... #>  $ post_Publish     : num [1:20] 3 3 3 4 5 2 5 5 4 5 ... #>  $ post_Write       : num [1:20] 4 3 5 5 4 4 5 4 4 4 ... #>  $ post_Research    : num [1:20] 5 3 3 3 5 2 3 3 5 3 ... #>  - attr(*, \"spec\")= #>   .. cols( #>   ..   `Unique Identifier` = col_double(), #>   ..   Gender = col_double(), #>   ..   Role = col_double(), #>   ..   Institution = col_double(), #>   ..   Organization = col_double(), #>   ..   Source = col_double(), #>   ..   Publish = col_double(), #>   ..   Write = col_double(), #>   ..   Research = col_double() #>   .. ) #>  - attr(*, \"problems\")=<externalptr> # merged_data contains all numeric variables with has 14 variables and 20 observations."},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"clean-up-variable-names","dir":"Articles","previous_headings":"","what":"Clean up variable names:","title":"bre","text":"","code":"# The janitor package has a lot of functions to help clean data below will do the following: # Clean up column names and take out empty/constant columns (not necessary here but showing its available): merged_data <- merged_data %>% janitor::clean_names() %>% janitor::remove_empty() %>% janitor::remove_constant()   # Get a list of all columns names: colnames(merged_data) #>  [1] \"unique_identifier\" \"gender\"            \"role\"              #>  [4] \"institution\"       \"pre_organization\"  \"pre_source\"        #>  [7] \"pre_publish\"       \"pre_write\"         \"pre_research\"      #> [10] \"post_organization\" \"post_source\"       \"post_publish\"      #> [13] \"post_write\"        \"post_research\"  # All the column names are pretty easy to use but one change may be better-  # Rename column names, this renames unique_identifier as unique_id: merged_data <- merged_data %>% rename(., unique_id = unique_identifier)"},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"how-to-recode-numeric-variables-to-factorcategorical-variables","dir":"Articles","previous_headings":"","what":"How to recode numeric variables to factor/categorical variables:","title":"bre","text":"First, order use variable “role” merged_data need change factor/categorical variables: Next, order use variable “gender” merged_data need change factor/categorical variables: Recode institution merged_data change factor/categorical variable:","code":"# For all of the data analysis in this template, the tidyverse will be the basis of all the data manipulation, the use of the mutate() and case_when() from \"dplyr\" is a simple way to create a new variable in R, I will add a prefix of \"cat_{variable_name}\" to signifiy the new variable is a category not numeric: # role = role of respondent takes on a scale of 1 to 4 needs to be recoded to:1= \"Undergraduate student\", 2 =\"Graduate student\", 3= \"Postdoc\", 4 = \"Faculty\" merged_data <- merged_data %>% mutate(cat_role = factor(case_when(                                            role == 1 ~ \"Undergraduate student\",                                            role == 2 ~ \"Graduate student\",                                            role == 3 ~ \"Postdoc\",                                            role == 4 ~ \"Faculty\"                                           ), levels = c(\"Undergraduate student\", \"Graduate student\", \"Postdoc\", \"Faculty\"))                       ) # case_when() takes in a statement on the left side of the ~ and when that is true returns the statement on the right side of the ~ to the new variable, in this case cat_role # so when role == 1 then cat_role will be == \"Undergraduate student\" and so on. # bre package also has a function that works similar to the above code called recodeCat(), This function takes in a df, use the scale_labels argument to pass the new labels along with the original value, returns a the original variable(s) new factor variable named \"cat_{variable(s)}\": cat_role <- merged_data %>% select(role) %>%      recodeCat(scale_labels = c(\"Undergraduate student\" = \"1\", \"Graduate student\" = \"2\", \"Postdoc\" = \"3\", \"Faculty\" = \"4\")) %>% select(cat_role)  # Add new cat_role variable back to merged data: merged_data <- merged_data %>% mutate(cat_role) # recode gender with recodeCat(): cat_gender <- merged_data %>% select(gender) %>%      recodeCat(scale_labels = c(\"male\"= \"1\", \"female\"= \"2\", \"other\"= \"3\")) %>% select(cat_gender)  # Add new cat_gender variable back to merged data: merged_data <- merged_data %>% mutate(cat_gender) # recode institution with recodeCat(): cat_institution <- merged_data %>% select(institution) %>%      recodeCat(scale_labels = c(\"University of Place\" = \"1\", \"State University of Another Place\"= \"2\", \"Technical State\"= \"3\", \"University of One More Place\"= \"4\")) %>%      select(cat_institution)  # Add new cat_institution variable back to merged data: merged_data <- merged_data %>% mutate(cat_institution)"},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"frequency-tables-for-all-demographics","dir":"Articles","previous_headings":"","what":"Frequency Tables for all demographics:","title":"bre","text":"common task Mark data analysis creating frequency tables, next examples show bre package. Response Percent Count Undergraduate student 30% 6 Graduate student 35% 7 Postdoc 15% 3 Faculty 20% 4 Total - 20 Now, thing gender institution: Response Percent Count male 50% 10 female 45% 9 5% 1 Total - 20 Response Percent Count University Place 15% 3 State University Another Place 45% 9 Technical State 25% 5 University One Place 15% 3 Total - 20","code":"# The first step is to us the dataSumm() from \"bre\" to calculate frequency and percentages of the variable, be sure to use the recoded factor var with \"cat_\" prefix: role_summ <- merged_data %>% select(cat_role) %>% bre::dataSumm() role_summ #> # A tibble: 4 × 5 #>   question response              n_answers percent_answers percent_answers_label #>   <chr>    <fct>                     <int>           <dbl> <chr>                 #> 1 cat_role Undergraduate student         6            0.3  30%                   #> 2 cat_role Graduate student              7            0.35 35%                   #> 3 cat_role Postdoc                       3            0.15 15%                   #> 4 cat_role Faculty                       4            0.2  20% # Next, the tblSumm() from \"bre\" will use flextable() to create a nice formatted table that can be rendered to html and also works nicely in .pptx and .docx tbl_role <- role_summ %>% tblSumm() tbl_role # dataSumm() and tblSumm() from \"bre\" can be used in one line to calculate frequency and percentages of the variable and make flextable output: # gender tbl_gender <- merged_data %>% select(cat_gender) %>% dataSumm() %>% tblSumm() tbl_gender # institution tbl_institution <- merged_data %>% select(cat_institution) %>% dataSumm() %>% tblSumm() tbl_institution"},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"how-to-recode-likert-scale-items","dir":"Articles","previous_headings":"","what":"How to recode Likert scale items:","title":"bre","text":"current Mark workflow, common data analysis survey items Likert scales, usually 1-5 point scales. example data provided, 5 variables named: Organization, Source, Publish, Write, Research. variables represent items 5-point Likert scales. following code create new factor variables numeric variables 1-5 point scales correct labels : “Minimal”, “Slight”, “Moderate”, “Good”, “Extensive”. new items added merged_data tibble now factor variables ready use.","code":"# recodeCat() from bre package takes in a tibble/data frame of as many variables that share the same desired scale_labels, use the scale_labels argument to pass the new labels in the order of the number_levels which you can also pass as an argument. # Returns the original variable(s) and the new factor variable(s) named \"cat_{variable(s)}\": # use the : symbol to select all the variables that are consecutive in the tibble, i.e. select(pre_organization:post_write) selects all the likert scale items, # the second select call (select()) selects all the new variables created with the prefix \"cat_{variable(s)}\": cat_likert_items <- merged_data %>% select(pre_organization:post_research) %>%      recodeCat(scale_labels = c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\", \"Good\" = \"4\", \"Extensive\" = \"5\")) %>% select(contains(\"cat\"))  # Add the new cat_items df to merged data: merged_data <- merged_data %>% mutate(cat_likert_items) # Check the data: str(merged_data) #> tibble [20 × 27] (S3: tbl_df/tbl/data.frame) #>  $ unique_id            : num [1:20] 1 2 3 4 5 6 7 8 9 10 ... #>  $ gender               : num [1:20] 1 2 2 2 2 2 1 2 1 1 ... #>  $ role                 : num [1:20] 1 2 2 4 4 1 2 2 1 2 ... #>  $ institution          : num [1:20] 2 1 2 1 2 2 3 1 2 4 ... #>  $ pre_organization     : num [1:20] 5 3 3 1 2 2 5 2 5 2 ... #>  $ pre_source           : num [1:20] 1 2 4 5 4 4 2 5 4 3 ... #>  $ pre_publish          : num [1:20] 2 2 2 3 4 1 5 4 3 5 ... #>  $ pre_write            : num [1:20] 4 1 3 3 2 2 5 2 2 2 ... #>  $ pre_research         : num [1:20] 5 2 2 2 5 1 2 2 5 2 ... #>  $ post_organization    : num [1:20] 5 4 4 2 3 3 5 3 5 3 ... #>  $ post_source          : num [1:20] 3 4 4 5 4 4 4 5 4 5 ... #>  $ post_publish         : num [1:20] 3 3 3 4 5 2 5 5 4 5 ... #>  $ post_write           : num [1:20] 4 3 5 5 4 4 5 4 4 4 ... #>  $ post_research        : num [1:20] 5 3 3 3 5 2 3 3 5 3 ... #>  $ cat_role             : Factor w/ 4 levels \"Undergraduate student\",..: 1 2 2 4 4 1 2 2 1 2 ... #>  $ cat_gender           : Factor w/ 3 levels \"male\",\"female\",..: 1 2 2 2 2 2 1 2 1 1 ... #>  $ cat_institution      : Factor w/ 4 levels \"University of Place\",..: 2 1 2 1 2 2 3 1 2 4 ... #>  $ cat_pre_organization : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 5 3 3 1 2 2 5 2 5 2 ... #>  $ cat_pre_source       : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 1 2 4 5 4 4 2 5 4 3 ... #>  $ cat_pre_publish      : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 2 2 2 3 4 1 5 4 3 5 ... #>  $ cat_pre_write        : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 4 1 3 3 2 2 5 2 2 2 ... #>  $ cat_pre_research     : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 5 2 2 2 5 1 2 2 5 2 ... #>  $ cat_post_organization: Factor w/ 5 levels \"Minimal\",\"Slight\",..: 5 4 4 2 3 3 5 3 5 3 ... #>  $ cat_post_source      : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 3 4 4 5 4 4 4 5 4 5 ... #>  $ cat_post_publish     : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 3 3 3 4 5 2 5 5 4 5 ... #>  $ cat_post_write       : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 4 3 5 5 4 4 5 4 4 4 ... #>  $ cat_post_research    : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 5 3 3 3 5 2 3 3 5 3 ..."},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"table-with-mean-and-standard-deviation-sd-for-numeric-items","dir":"Articles","previous_headings":"","what":"Table with Mean and Standard Deviation (SD) for Numeric Items:","title":"bre","text":"following code create three new variables: mean “pre_” “post_” Likert items, mean “post_” Likert items, difference score “post_” mean minus “pre_” mean. , create table mean SD using function tbl_summary gtsummary package: Mean SD Likert Items","code":"# use the original numeric variables: pre Likert items = pre_organization:pre_research, post Likert items = post_organization:post_research # First, if we needed to change a value to NA this is one way to do it quickly, not needed for this data so will comment out: # merged_data <- merged_data %>% mutate(across(pre_organization:pre_research, ~ifelse(. == 9, NA, .)), #                                      (across(post_organization:post_research, ~ifelse(. == 9, NA, .))))  # Create Composites means for the 5 pre Likert items (pre_items) and 5 post Likert items (post_items): # Also, create a new variable for difference btw pre and post= diff_items (this will be used in a test for normality, shapiro test), rowwise() is a function from dplyr package that allows you to compute new row by row, this will return means for pre and post for each individual row, not overall: merged_data <- merged_data %>% rowwise() %>% mutate(pre_items = mean(c_across(pre_organization:pre_research), na.rm = TRUE),                                                     post_items = mean(c_across(post_organization:post_research), na.rm = TRUE),                                                     diff_items = post_items - pre_items)   # Table for M and SD for pre-post composites: merged_data %>%   select(pre_items, post_items) %>%   gtsummary::tbl_summary(statistic = list(gtsummary::all_continuous() ~ \"{mean}, ({sd})\"),               type = list(pre_items ~ 'continuous', post_items ~ 'continuous'),               label =  list(pre_items ~ 'Pre Likert Items',                             post_items ~ 'Post Likert Items'),               missing_text = \"Missing\") %>%   gtsummary::add_stat_label() %>%   gtsummary::bold_labels() %>%   gtsummary::modify_header(label ~ \"**Variable**\") %>%   gtsummary::modify_caption(\"Mean and SD of Likert Items\")"},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"how-to-test-for-normality-using-pre-post-difference-scores","dir":"Articles","previous_headings":"","what":"How to Test for Normality using pre-post difference scores:","title":"bre","text":"want check see pre-post means/composite scores normally distributed (order use parametric tests like t-tests), use Shapiro-Wilk Test. requires difference score pre-post means. Shapiro-Wilk tests null hypothesis data distributed normally, test significant means data distributed normally parametric tests used. (Use non-parametric tests like Wilcoxon test). Shapiro-Wilk significant data distributed normally parametric tests (like t-tests) can used. Test significant data normally distributed, can use t-test pre-post analysis.","code":"# test for normality on the differences score of the Likert items: shapiro.test(merged_data$diff_items) #>  #>  Shapiro-Wilk normality test #>  #> data:  merged_data$diff_items #> W = 0.91, p-value = 0.06"},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"how-to-use-a-t-test-with-pre-post-meancomposite-scores","dir":"Articles","previous_headings":"","what":"How to use a t-test with pre-post mean/composite scores:","title":"bre","text":"data pre-post paired t-test used, shows code : t-test null hypothesis data meaningfully different, test significant can reject null hypothesis conclude pre-post means meaningfully different. t-test significant shown small p-value = 0.","code":"# t-tests for parametric analysis t_test_items <- t.test(merged_data$pre_items, merged_data$post_items, paired = TRUE) t_test_items #>  #>  Paired t-test #>  #> data:  merged_data$pre_items and merged_data$post_items #> t = -15, df = 19, p-value = 0.000000000003 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -1.0784 -0.8216 #> sample estimates: #> mean difference  #>           -0.95"},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"how-to-use-a-wilcoxon-test-with-pre-post-meancomposite-scores","dir":"Articles","previous_headings":"","what":"How to use a Wilcoxon test with pre-post mean/composite scores:","title":"bre","text":"data normally distributed, use Wilcoxon test, data pre-post paired Wilcoxon test used, shows code :","code":"# Wilcoxon test for non-parametric analysis wilcox_test_items <- wilcox.test(merged_data$pre_items, merged_data$post_items, paired = TRUE) wilcox_test_items #>  #>  Wilcoxon signed rank test with continuity correction #>  #> data:  merged_data$pre_items and merged_data$post_items #> V = 0, p-value = 0.00008 #> alternative hypothesis: true location shift is not equal to 0"},{"path":"https://zwcrowley.github.io/bre/articles/TheMarkUSA.html","id":"t-tests-for-individual-items","dir":"Articles","previous_headings":"","what":"t-tests for individual items:","title":"bre","text":"run t-test likert items, paired t-tests since data pre-post individuals:","code":"# t-tests for parametric analysis: Organization, Source, Publish, Write, Research # organization: t.test(merged_data$pre_organization, merged_data$post_organization, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_organization and merged_data$post_organization #> t = -8.7, df = 19, p-value = 0.00000005 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -0.9921 -0.6079 #> sample estimates: #> mean difference  #>            -0.8 # Source: t.test(merged_data$pre_source, merged_data$post_source, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_source and merged_data$post_source #> t = -4.4, df = 19, p-value = 0.0003 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -1.4802 -0.5198 #> sample estimates: #> mean difference  #>              -1 # Publish: t.test(merged_data$pre_publish, merged_data$post_publish, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_publish and merged_data$post_publish #> t = -7.5, df = 19, p-value = 0.0000004 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -0.9579 -0.5421 #> sample estimates: #> mean difference  #>           -0.75 # Write: t.test(merged_data$pre_write, merged_data$post_write, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_write and merged_data$post_write #> t = -6.7, df = 19, p-value = 0.000002 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -1.8401 -0.9599 #> sample estimates: #> mean difference  #>            -1.4 # Research: t.test(merged_data$pre_research, merged_data$post_research, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_research and merged_data$post_research #> t = -8.7, df = 19, p-value = 0.00000005 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -0.9921 -0.6079 #> sample estimates: #> mean difference  #>            -0.8"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"vignette-for-data-analysis-at-blackstone-research-and-evaluation","dir":"Articles","previous_headings":"","what":"Vignette for Data Analysis at Blackstone Research and Evaluation:","title":"bre","text":"file starting point data analysis task Blackstone Research Evaluation. examples provided baseline-annual (pre-post) survey comparison, many ways workflow can used data tasks. vignette corresponding available template titled: “Data Analysis Blackstone Research Evaluation”. Please provide feedback use vignette determine tasks include templates construct.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"how-to-read-in--xlsx-data","dir":"Articles","previous_headings":"Loading baseline and annual data from .csv and .xlsx:","what":"How to read in .xlsx data:","title":"bre","text":"","code":"# readxl is a package that has the most up to date function for reading in excel files either .xls or xlsx, read_excel(), if you know the file is .xlsx you can use  # the function read_xlsx(), both are shown below: # For this example, the baseline data is in a folder called \"extdata\" which is located up four folders so ../ moves up one folder- # Read in the baseline.xlsx data using read_excel(): baseline <- readxl::read_excel(\"../inst/extdata/baseline.xlsx\")  # Read in the annual.xlsx data using read_xlsx(): annual <- readxl::read_xlsx(\"../inst/extdata/annual.xlsx\") # Remove to resuse names: rm(annual, baseline)"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"how-to-read-in--csv-data","dir":"Articles","previous_headings":"Loading baseline and annual data from .csv and .xlsx:","what":"How to read in .csv data:","title":"bre","text":"","code":"# readr is a package included in \"tidyverse\" that has the most up to date function for reading in .csv data, read_csv(): # For this example, the baseline data is in a folder called \"extdata\" which is located up four folders so ../ moves up one folder- # Read in the baseline.csv data: baseline <- readr::read_csv(\"../inst/extdata/baseline.csv\")  # Read in the annual.csv data: annual <- readr::read_csv(\"../inst/extdata/annual.csv\")"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"info-about-example-data-in-baseline-and-annual-datasets","dir":"Articles","previous_headings":"Loading baseline and annual data from .csv and .xlsx: > How to read in .csv data:","what":"Info about example data in baseline and annual datasets:","title":"bre","text":"dataset contains 7 variables 20 observations. Unique Identifier: unique ID (1 20) role: 1= “Undergraduate student”, 2 =“Graduate student”, 3= “Postdoc”, 4 = “Faculty” Gender: 1 = “male”, 2 = “female”, 3 = “” Institution: 1 = “University Place”, 2 = “State University Another Place”, 3 = “Technical State”, 4 = “University One Place” 5 variables make composite scale: Organization, Source, Publish, Write, Research 5-point Likert scale 1 5 needs recoded : c(“Minimal”, “Slight”, “Moderate”, “Good”, “Extensive”)","code":""},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"merging-data","dir":"Articles","previous_headings":"","what":"Merging data:","title":"bre","text":"R package dplyr, included tidyverse, includes many functions merge data sets, common “outer join” functions left_join() full_join(). Use full_join() want merge two datasets include observations datasets, commonly used want join datasets top bottom, see dpylr’s documentation examples. uses Blackstone Research Evaluation, data merged using left_join(), function used merge data share common unique identifier keep observations occur one datasets. Specically, left_join() keeps observations first supplied dataset merges observations second dataset matches user supplied “” variable first dataset.","code":"# Merge the baseline and annual datasets using the variable `Unique Identifier` as the by argument inside join_by(\"\"), this is the variable that will match the observations from both datasets, the suffix argument is a c() of length two which is added to variables taken from the respective datasets, so for this example variables from baseline will have a suffix of \"{variable_name}_pre\" and variables from annual will have  \"{variable_name}_post\": merged_data <- baseline %>% left_join(., annual, by = join_by(\"Unique Identifier\"), suffix = c(\"_pre\",\"_post\")) # can also be written: merged_data <- left_join(baseline, annual, by = join_by(\"Unique Identifier\", \"role\"), suffix = c(\"_pre\",\"_post\")) # the new merged data has 14 variables, the original 9 from baseline and the 5 that match from the annuals dataset. # head(merged_data, n = 4)   # If you would rather use a prefix for pre and post this is one way to do that: # add prefix before joining, for baseline skip the first 4 vars and annual skip first var: names(baseline)[5:9] <- paste0(\"pre_\", names(baseline)[5:9]) names(annual)[2:6] <- paste0(\"post_\", names(annual)[2:6]) # in join, use names with prefixes merged_data <- baseline %>% left_join(annual, by = join_by(\"Unique Identifier\"))  # check variables from the merged_data using str() and summary(): str(merged_data) #> spc_tbl_ [20 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame) #>  $ Unique Identifier: num [1:20] 1 2 3 4 5 6 7 8 9 10 ... #>  $ Gender           : num [1:20] 1 2 2 2 2 2 1 2 1 1 ... #>  $ Role             : num [1:20] 1 2 2 4 4 1 2 2 1 2 ... #>  $ Institution      : num [1:20] 2 1 2 1 2 2 3 1 2 4 ... #>  $ pre_Organization : num [1:20] 5 3 3 1 2 2 5 2 5 2 ... #>  $ pre_Source       : num [1:20] 1 2 4 5 4 4 2 5 4 3 ... #>  $ pre_Publish      : num [1:20] 2 2 2 3 4 1 5 4 3 5 ... #>  $ pre_Write        : num [1:20] 4 1 3 3 2 2 5 2 2 2 ... #>  $ pre_Research     : num [1:20] 5 2 2 2 5 1 2 2 5 2 ... #>  $ post_Organization: num [1:20] 5 4 4 2 3 3 5 3 5 3 ... #>  $ post_Source      : num [1:20] 3 4 4 5 4 4 4 5 4 5 ... #>  $ post_Publish     : num [1:20] 3 3 3 4 5 2 5 5 4 5 ... #>  $ post_Write       : num [1:20] 4 3 5 5 4 4 5 4 4 4 ... #>  $ post_Research    : num [1:20] 5 3 3 3 5 2 3 3 5 3 ... #>  - attr(*, \"spec\")= #>   .. cols( #>   ..   `Unique Identifier` = col_double(), #>   ..   Gender = col_double(), #>   ..   Role = col_double(), #>   ..   Institution = col_double(), #>   ..   Organization = col_double(), #>   ..   Source = col_double(), #>   ..   Publish = col_double(), #>   ..   Write = col_double(), #>   ..   Research = col_double() #>   .. ) #>  - attr(*, \"problems\")=<externalptr> # merged_data contains all numeric variables with has 14 variables and 20 observations."},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"clean-up-variable-names","dir":"Articles","previous_headings":"","what":"Clean up variable names:","title":"bre","text":"","code":"# The janitor package has a lot of functions to help clean data below will do the following: # Clean up column names and take out empty/constant columns (not necessary here but showing its available): merged_data <- merged_data %>% janitor::clean_names() %>% janitor::remove_empty() %>% janitor::remove_constant()   # Get a list of all columns names: colnames(merged_data) #>  [1] \"unique_identifier\" \"gender\"            \"role\"              #>  [4] \"institution\"       \"pre_organization\"  \"pre_source\"        #>  [7] \"pre_publish\"       \"pre_write\"         \"pre_research\"      #> [10] \"post_organization\" \"post_source\"       \"post_publish\"      #> [13] \"post_write\"        \"post_research\" # All the column names are pretty easy to use but one change may be better-  # Rename column names, this renames unique_identifier as unique_id: merged_data <- merged_data %>% rename(., unique_id = unique_identifier)"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"how-to-recode-numeric-variables-to-factorcategorical-variables","dir":"Articles","previous_headings":"","what":"How to recode numeric variables to factor/categorical variables:","title":"bre","text":"First, order use variable “role” merged_data need change factor/categorical variables: Next, order use variable “gender” merged_data need change factor/categorical variables: Recode institution merged_data change factor/categorical variable:","code":"# For all of the data analysis in this template, the tidyverse will be the basis of all the data manipulation, the use of the mutate() and case_when() from \"dplyr\" is a simple way to create a new variable in R, I will add a prefix of \"cat_{variable_name}\" to signifiy the new variable is a category not numeric: # role = role of respondent takes on a scale of 1 to 4 needs to be recoded to:1= \"Undergraduate student\", 2 =\"Graduate student\", 3= \"Postdoc\", 4 = \"Faculty\" merged_data <- merged_data %>% mutate(cat_role = factor(case_when(                                            role == 1 ~ \"Undergraduate student\",                                            role == 2 ~ \"Graduate student\",                                            role == 3 ~ \"Postdoc\",                                            role == 4 ~ \"Faculty\"                                           ), levels = c(\"Undergraduate student\", \"Graduate student\", \"Postdoc\", \"Faculty\"))                       ) # case_when() takes in a statement on the left side of the ~ and when that is true returns the statement on the right side of the ~ to the new variable, in this case cat_role # so when role == 1 then cat_role will be == \"Undergraduate student\" and so on. # bre package also has a function that works similar to the above code called recodeCat(), This function takes in a df, use the scale_labels argument to pass the new labels along with the original value, returns a the original variable(s) new factor variable named \"cat_{variable(s)}\": cat_role <- merged_data %>% select(role) %>%      recodeCat(scale_labels = c(\"Undergraduate student\" = \"1\", \"Graduate student\" = \"2\", \"Postdoc\" = \"3\", \"Faculty\" = \"4\")) %>% select(cat_role)  # Add new cat_role variable back to merged data: merged_data <- merged_data %>% mutate(cat_role) # recode gender with recodeCat(): cat_gender <- merged_data %>% select(gender) %>%      recodeCat(scale_labels = c(\"male\"= \"1\", \"female\"= \"2\", \"other\"= \"3\")) %>% select(cat_gender)  # Add new cat_gender variable back to merged data: merged_data <- merged_data %>% mutate(cat_gender) # recode institution with recodeCat(): cat_institution <- merged_data %>% select(institution) %>%      recodeCat(scale_labels = c(\"University of Place\" = \"1\", \"State University of Another Place\"= \"2\", \"Technical State\"= \"3\", \"University of One More Place\"= \"4\")) %>%      select(cat_institution)  # Add new cat_institution variable back to merged data: merged_data <- merged_data %>% mutate(cat_institution)"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"frequency-tables-for-all-demographics","dir":"Articles","previous_headings":"","what":"Frequency Tables for all demographics:","title":"bre","text":"common task Blackstone Research Evaluation data analysis creating frequency tables, next examples show bre package. Response Percent Count Undergraduate student 30% 6 Graduate student 35% 7 Postdoc 15% 3 Faculty 20% 4 Total - 20 Now, thing gender institution: Response Percent Count male 50% 10 female 45% 9 5% 1 Total - 20 Response Percent Count University Place 15% 3 State University Another Place 45% 9 Technical State 25% 5 University One Place 15% 3 Total - 20","code":"# The first step is to us the dataSumm() from \"bre\" to calculate frequency and percentages of the variable, be sure to use the recoded factor var with \"cat_\" prefix: role_summ <- merged_data %>% select(cat_role) %>% bre::dataSumm() role_summ #> # A tibble: 4 × 5 #>   question response              n_answers percent_answers percent_answers_label #>   <chr>    <fct>                     <int>           <dbl> <chr>                 #> 1 cat_role Undergraduate student         6            0.3  30%                   #> 2 cat_role Graduate student              7            0.35 35%                   #> 3 cat_role Postdoc                       3            0.15 15%                   #> 4 cat_role Faculty                       4            0.2  20% # Next, the tblSumm() from \"bre\" will use flextable() to create a nice formatted table that can be rendered to html and also works nicely in .pptx and .docx tbl_role <- role_summ %>% tblSumm() tbl_role # dataSumm() and tblSumm() from \"bre\" can be used in one line to calculate frequency and percentages of the variable and make flextable output: # gender tbl_gender <- merged_data %>% select(cat_gender) %>% dataSumm() %>% tblSumm() tbl_gender # institution tbl_institution <- merged_data %>% select(cat_institution) %>% dataSumm() %>% tblSumm() tbl_institution"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"how-to-recode-likert-scale-items","dir":"Articles","previous_headings":"","what":"How to recode Likert scale items:","title":"bre","text":"current Blackstone Research Evaluation workflow, common data analysis survey items Likert scales, usually 1-5 point scales. example data provided, 5 variables named: Organization, Source, Publish, Write, Research. variables represent items 5-point Likert scales. following code create new factor variables numeric variables 1-5 point scales correct labels : “Minimal”, “Slight”, “Moderate”, “Good”, “Extensive”. new items added merged_data tibble now factor variables ready use.","code":"# recodeCat() from bre package takes in a tibble/data frame of as many variables that share the same desired scale_labels, use the scale_labels argument to pass the new labels in the order of the number_levels which you can also pass as an argument. # Returns the original variable(s) and the new factor variable(s) named \"cat_{variable(s)}\": # use the : symbol to select all the variables that are consecutive in the tibble, i.e. select(pre_organization:post_write) selects all the likert scale items, # the second select call (select()) selects all the new variables created with the prefix \"cat_{variable(s)}\": cat_likert_items <- merged_data %>% select(pre_organization:post_research) %>%      recodeCat(scale_labels = c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\", \"Good\" = \"4\", \"Extensive\" = \"5\")) %>% select(contains(\"cat\"))  # Add the new cat_items df to merged data: merged_data <- merged_data %>% mutate(cat_likert_items) # Check the data: str(merged_data) #> tibble [20 × 27] (S3: tbl_df/tbl/data.frame) #>  $ unique_id            : num [1:20] 1 2 3 4 5 6 7 8 9 10 ... #>  $ gender               : num [1:20] 1 2 2 2 2 2 1 2 1 1 ... #>  $ role                 : num [1:20] 1 2 2 4 4 1 2 2 1 2 ... #>  $ institution          : num [1:20] 2 1 2 1 2 2 3 1 2 4 ... #>  $ pre_organization     : num [1:20] 5 3 3 1 2 2 5 2 5 2 ... #>  $ pre_source           : num [1:20] 1 2 4 5 4 4 2 5 4 3 ... #>  $ pre_publish          : num [1:20] 2 2 2 3 4 1 5 4 3 5 ... #>  $ pre_write            : num [1:20] 4 1 3 3 2 2 5 2 2 2 ... #>  $ pre_research         : num [1:20] 5 2 2 2 5 1 2 2 5 2 ... #>  $ post_organization    : num [1:20] 5 4 4 2 3 3 5 3 5 3 ... #>  $ post_source          : num [1:20] 3 4 4 5 4 4 4 5 4 5 ... #>  $ post_publish         : num [1:20] 3 3 3 4 5 2 5 5 4 5 ... #>  $ post_write           : num [1:20] 4 3 5 5 4 4 5 4 4 4 ... #>  $ post_research        : num [1:20] 5 3 3 3 5 2 3 3 5 3 ... #>  $ cat_role             : Factor w/ 4 levels \"Undergraduate student\",..: 1 2 2 4 4 1 2 2 1 2 ... #>  $ cat_gender           : Factor w/ 3 levels \"male\",\"female\",..: 1 2 2 2 2 2 1 2 1 1 ... #>  $ cat_institution      : Factor w/ 4 levels \"University of Place\",..: 2 1 2 1 2 2 3 1 2 4 ... #>  $ cat_pre_organization : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 5 3 3 1 2 2 5 2 5 2 ... #>  $ cat_pre_source       : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 1 2 4 5 4 4 2 5 4 3 ... #>  $ cat_pre_publish      : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 2 2 2 3 4 1 5 4 3 5 ... #>  $ cat_pre_write        : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 4 1 3 3 2 2 5 2 2 2 ... #>  $ cat_pre_research     : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 5 2 2 2 5 1 2 2 5 2 ... #>  $ cat_post_organization: Factor w/ 5 levels \"Minimal\",\"Slight\",..: 5 4 4 2 3 3 5 3 5 3 ... #>  $ cat_post_source      : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 3 4 4 5 4 4 4 5 4 5 ... #>  $ cat_post_publish     : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 3 3 3 4 5 2 5 5 4 5 ... #>  $ cat_post_write       : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 4 3 5 5 4 4 5 4 4 4 ... #>  $ cat_post_research    : Factor w/ 5 levels \"Minimal\",\"Slight\",..: 5 3 3 3 5 2 3 3 5 3 ..."},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"table-with-mean-and-standard-deviation-sd-for-numeric-items","dir":"Articles","previous_headings":"","what":"Table with Mean and Standard Deviation (SD) for Numeric Items:","title":"bre","text":"following code create three new variables: mean “pre_” “post_” Likert items, mean “post_” Likert items, difference score “post_” mean minus “pre_” mean. , create table mean SD using function tbl_summary gtsummary package: Mean SD Likert Items","code":"# use the original numeric variables: pre Likert items = pre_organization:pre_research, post Likert items = post_organization:post_research # First, if we needed to change a value to NA this is one way to do it quickly, not needed for this data so will comment out: # merged_data <- merged_data %>% mutate(across(pre_organization:pre_research, ~ifelse(. == 9, NA, .)), #                                      (across(post_organization:post_research, ~ifelse(. == 9, NA, .))))  # Create Composites means for the 5 pre Likert items (pre_items) and 5 post Likert items (post_items): # Also, create a new variable for difference btw pre and post= diff_items (this will be used in a test for normality, shapiro test), rowwise() is a function from dplyr package that allows you to compute new row by row, this will return means for pre and post for each individual row, not overall: merged_data <- merged_data %>% rowwise() %>% mutate(pre_items = mean(c_across(pre_organization:pre_research), na.rm = TRUE),                                                     post_items = mean(c_across(post_organization:post_research), na.rm = TRUE),                                                     diff_items = post_items - pre_items)   # Table for M and SD for pre-post composites: merged_data %>%   select(pre_items, post_items) %>%   gtsummary::tbl_summary(statistic = list(gtsummary::all_continuous() ~ \"{mean}, ({sd})\"),               type = list(pre_items ~ 'continuous', post_items ~ 'continuous'),               label =  list(pre_items ~ 'Pre Likert Items',                             post_items ~ 'Post Likert Items'),               missing_text = \"Missing\") %>%   gtsummary::add_stat_label() %>%   gtsummary::bold_labels() %>%   gtsummary::modify_header(label ~ \"**Variable**\") %>%   gtsummary::modify_caption(\"Mean and SD of Likert Items\")"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"how-to-test-for-normality-using-pre-post-difference-scores","dir":"Articles","previous_headings":"","what":"How to Test for Normality using pre-post difference scores:","title":"bre","text":"want check see pre-post means/composite scores normally distributed (order use parametric tests like t-tests), use Shapiro-Wilk Test. requires difference score pre-post means. Shapiro-Wilk tests null hypothesis data distributed normally, test significant means data distributed normally parametric tests used. (Use non-parametric tests like Wilcoxon test). Shapiro-Wilk significant data distributed normally parametric tests (like t-tests) can used. Test significant data normally distributed, can use t-test pre-post analysis.","code":"# test for normality on the differences score of the Likert items: shapiro.test(merged_data$diff_items) #>  #>  Shapiro-Wilk normality test #>  #> data:  merged_data$diff_items #> W = 0.91, p-value = 0.06"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"how-to-use-a-t-test-with-pre-post-meancomposite-scores","dir":"Articles","previous_headings":"","what":"How to use a t-test with pre-post mean/composite scores:","title":"bre","text":"data pre-post paired t-test used, shows code : t-test null hypothesis data meaningfully different, test significant can reject null hypothesis conclude pre-post means meaningfully different. t-test significant shown small p-value = 0.","code":"# t-tests for parametric analysis t_test_items <- t.test(merged_data$pre_items, merged_data$post_items, paired = TRUE) t_test_items #>  #>  Paired t-test #>  #> data:  merged_data$pre_items and merged_data$post_items #> t = -15, df = 19, p-value = 0.000000000003 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -1.0784 -0.8216 #> sample estimates: #> mean difference  #>           -0.95"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"how-to-use-a-wilcoxon-test-with-pre-post-meancomposite-scores","dir":"Articles","previous_headings":"","what":"How to use a Wilcoxon test with pre-post mean/composite scores:","title":"bre","text":"data normally distributed, use Wilcoxon test, data pre-post paired Wilcoxon test used, shows code :","code":"# Wilcoxon test for non-parametric analysis wilcox_test_items <- wilcox.test(merged_data$pre_items, merged_data$post_items, paired = TRUE) wilcox_test_items #>  #>  Wilcoxon signed rank test with continuity correction #>  #> data:  merged_data$pre_items and merged_data$post_items #> V = 0, p-value = 0.00008 #> alternative hypothesis: true location shift is not equal to 0"},{"path":"https://zwcrowley.github.io/bre/articles/bre.html","id":"t-tests-for-individual-items","dir":"Articles","previous_headings":"","what":"t-tests for individual items:","title":"bre","text":"run t-test likert items, paired t-tests since data pre-post individuals:","code":"# t-tests for parametric analysis: Organization, Source, Publish, Write, Research # organization: t.test(merged_data$pre_organization, merged_data$post_organization, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_organization and merged_data$post_organization #> t = -8.7, df = 19, p-value = 0.00000005 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -0.9921 -0.6079 #> sample estimates: #> mean difference  #>            -0.8 # Source: t.test(merged_data$pre_source, merged_data$post_source, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_source and merged_data$post_source #> t = -4.4, df = 19, p-value = 0.0003 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -1.4802 -0.5198 #> sample estimates: #> mean difference  #>              -1 # Publish: t.test(merged_data$pre_publish, merged_data$post_publish, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_publish and merged_data$post_publish #> t = -7.5, df = 19, p-value = 0.0000004 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -0.9579 -0.5421 #> sample estimates: #> mean difference  #>           -0.75 # Write: t.test(merged_data$pre_write, merged_data$post_write, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_write and merged_data$post_write #> t = -6.7, df = 19, p-value = 0.000002 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -1.8401 -0.9599 #> sample estimates: #> mean difference  #>            -1.4 # Research: t.test(merged_data$pre_research, merged_data$post_research, paired = TRUE) #>  #>  Paired t-test #>  #> data:  merged_data$pre_research and merged_data$post_research #> t = -8.7, df = 19, p-value = 0.00000005 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  -0.9921 -0.6079 #> sample estimates: #> mean difference  #>            -0.8"},{"path":"https://zwcrowley.github.io/bre/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Zack Crowley. Author, maintainer. Blackstone Research Evaluation. Copyright holder, funder.","code":""},{"path":"https://zwcrowley.github.io/bre/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Crowley Z (2024). bre: Helper Functions Blackstone Research Evaluation. R package version 0.0.0.9000, https://zwcrowley.github.io/bre/, https://github.com/zwcrowley/bre.","code":"@Manual{,   title = {bre: Helper Functions for Blackstone Research and Evaluation},   author = {Zack Crowley},   year = {2024},   note = {R package version 0.0.0.9000, https://zwcrowley.github.io/bre/},   url = {https://github.com/zwcrowley/bre}, }"},{"path":"https://zwcrowley.github.io/bre/index.html","id":"bre-","dir":"","previous_headings":"","what":"Helper Functions for Blackstone Research and Evaluation","title":"Helper Functions for Blackstone Research and Evaluation","text":"goal bre make data cleaning creation visualizations easier faster Blackstone Research Evaluation. bre contains functions create visuals Blackstone Research Evaluation branding helper functions common data cleaning manipulation tasks everyone Blackstone Research Evaluation.","code":""},{"path":"https://zwcrowley.github.io/bre/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Helper Functions for Blackstone Research and Evaluation","text":"can install development version bre GitHub : initial installation also install import fonts extrafont package:","code":"# install.packages(\"devtools\") devtools::install_github(\"zwcrowley/bre\") # install.packages(\"extrafont\") library(extrafont) # Import fonts to get \"Arial\", this only has to be done one time, then `bre` package will use the code below to load the fonts automatically  # for the functions that require that step: extrafont::font_import() # Load all fonts: extrafont::loadfonts(\"all\", quiet = TRUE)"},{"path":"https://zwcrowley.github.io/bre/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Helper Functions for Blackstone Research and Evaluation","text":"begin, best convert numeric data use Blackstone Research Evaluation factor variables:","code":"library(bre)"},{"path":"https://zwcrowley.github.io/bre/index.html","id":"recodecat","dir":"","previous_headings":"Usage","what":"recodeCat()","title":"Helper Functions for Blackstone Research and Evaluation","text":"recodeCat() helper function recode numeric data factor variables desired levels. recodeCat() takes two arguments: df Required, tibble/data frame survey items numeric variables need converted factor variables. Numeric variables data can anywhere 3 7 point scales. scale_labels Required, named character vector labels desired scale levels new factor variables. function use vector convert numeric variables factor variables, levels must supplied correct range otherwise else NA returned variables outside range user supplied values. named character vector new labels “name” old labels “variable” like : c(“” = “”) look like : levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\", \"Good\" = \"4\", \"Extensive\" = \"5\") user simply passes data frame items recoded named character vector 5 scale likert levels corresponding order numeric data.","code":"items <- dplyr::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 ) # Set up the named vector to pass to scale_labels, follow this pattern- c(\"<new label>\" = \"<original variable value>\"): levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\", \"Good\" = \"4\", \"Extensive\" = \"5\") cat_items_1 <- bre::recodeCat(df = items, scale_labels = levels_min_ext) cat_items_1 #> # A tibble: 9 × 20 #>   pre_Organization post_Organization pre_Source post_Source pre_Publish #>              <dbl>             <dbl>      <dbl>       <dbl>       <dbl> #> 1                1                 2          2           4           1 #> 2                2                 3          2           4           1 #> 3                3                 4          3           5           1 #> 4                4                 5          5           5           2 #> 5                5                 5          4           4           2 #> 6                4                 5          3           5           2 #> 7                3                 4          2           4           3 #> 8                2                 3          1           3           3 #> 9                1                 2          2           4           3 #> # ℹ 15 more variables: post_Publish <dbl>, pre_Write <dbl>, post_Write <dbl>, #> #   pre_Research <dbl>, post_Research <dbl>, cat_pre_Organization <fct>, #> #   cat_post_Organization <fct>, cat_pre_Source <fct>, cat_post_Source <fct>, #> #   cat_pre_Publish <fct>, cat_post_Publish <fct>, cat_pre_Write <fct>, #> #   cat_post_Write <fct>, cat_pre_Research <fct>, cat_post_Research <fct>"},{"path":"https://zwcrowley.github.io/bre/index.html","id":"data-visualizations-examples","dir":"","previous_headings":"","what":"Data Visualizations Examples","title":"Helper Functions for Blackstone Research and Evaluation","text":"bre currently contains three helper functions generating visualizations: stackedBarChart(), divBarChart(), arrowChart(), arrowChartGroup().","code":""},{"path":"https://zwcrowley.github.io/bre/index.html","id":"stackedbarchart","dir":"","previous_headings":"Data Visualizations Examples","what":"stackedBarChart()","title":"Helper Functions for Blackstone Research and Evaluation","text":"stackedBarChart() creates fully stacked bar chart branding/style Blackstone Research Evaluation. stackedBarChart() takes 8 arguments, first 2 required: df Required, tibble data frame survey items categorical/factor variables, 5 point scales, can single time point pre-post, inserted stacked bar chart Blackstone Research Evaluation branding. scale_labels scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). argument accepts character vector 3 7 items. pre_post Logical, default FALSE. true, returns pre-post stacked bar chart, arranged question, requires data structured pre-post. FALSE, returns stacked bar chart single time point. overall_n Logical, default FALSE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. percent_label Logical, default TRUE. Labels bars based percentages. FALSE, labels bars number answers per response. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels “name” old labels “variable” sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest positive valenced response options top plot descending. width Input value 0.3 0.8 set thickness bars. Default NULL.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/bre/index.html","id":"single-time-point-data-with-percentage-labels-example-for-stackedbarchart","dir":"","previous_headings":"Data Visualizations Examples > stackedBarChart()","what":"Single Time Point Data with Percentage labels Example for stackedBarChart():","title":"Helper Functions for Blackstone Research and Evaluation","text":"","code":"# Single time point data: items_single <- dplyr::tibble(   Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4) ) # scale_labels as a named character vector, items in correct order: levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\", \"Good\" = \"4\", \"Extensive\" = \"5\")  # bar_scale_labels as just the names from levels_min_ext: bar_scale_labels <- names(levels_min_ext)  # Question labels as a named vector with the naming structure like this: c(\"{new label}\" = \"{original variable name}\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                      \"Write a lot of research papers\" = \"Write\",                      \"Research in a lab with faculty\" = \"Research\",                      \"Organization of a large research project\" = \"Organization\",                      \"Source work for a research paper\" = \"Source\") # Recode the numeric to factor variables using the levels from levels_min_ext: cat_items_single <- bre::recodeCat(items_single, levels_min_ext) # Select the factor variables: cat_items_single <- cat_items_single %>% dplyr::select(dplyr::where(is.factor)) # Pass the factor variables and the levels to 'stackedBarChart()': stacked_chart_single <- bre::stackedBarChart(    df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,    percent_label = TRUE, width = 0.6 ) stacked_chart_single # With new labels and order taken from `question_labels` argument, each  # item has it's own sample size in the label: stacked_chart_single_labels <- bre::stackedBarChart(    df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels, overall_n = FALSE,    question_labels = question_labels, question_order = TRUE, percent_label = TRUE, width = 0.6 ) stacked_chart_single_labels"},{"path":"https://zwcrowley.github.io/bre/index.html","id":"pre-post-data-example-for-stackedbarchart","dir":"","previous_headings":"Data Visualizations Examples > stackedBarChart()","what":"Pre-Post Data Example for stackedBarChart()","title":"Helper Functions for Blackstone Research and Evaluation","text":"","code":"# Select only the categorical/factor vars from the df in the from the oriinal recodeCat() in the first chunk (cat_items_1) using select(tidyselect::where(is.factor): cat_items <- cat_items_1 %>% dplyr::select(tidyselect::where(is.factor))  # Run the function with the factor items and the character vector of the factor levels: stacked_chart_pre_post <- bre::stackedBarChart(    df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,    percent_label = TRUE, width = NULL ) stacked_chart_pre_post # With new labels and order taken from question_labels argument, each  # item has it's own sample size in the label: stacked_chart_pre_post_labels <- bre::stackedBarChart(    df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels, overall_n = FALSE,    question_labels = question_labels, question_order = TRUE, percent_label = TRUE, width = NULL ) stacked_chart_pre_post_labels"},{"path":"https://zwcrowley.github.io/bre/index.html","id":"divbarchart","dir":"","previous_headings":"Data Visualizations Examples","what":"divBarChart()","title":"Helper Functions for Blackstone Research and Evaluation","text":"divBarChart() creates diverging fully stacked bar chart branding style Blackstone Research Evaluation. divBarChart() takes 7 arguments, first 2 required: df Required, tibble/data frame survey items categorical/character variables, 3 7 point scales, inserted diverging bar chart Blackstone Research Evaluation branding. scale_labelsscale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). argument accepts character vector 3 7 items. overall_n Logical, default FALSE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. percent_label Logical, default TRUE. FALSE, labels bars number answers per response. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels “name” old labels “variable” sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest positive valenced response options top plot descending. width Input value 0.3 0.8 set thickness bars. Default NULL.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/bre/index.html","id":"single-time-point-data-with-percentage-labels-example-for-divbarchart","dir":"","previous_headings":"Data Visualizations Examples > divBarChart()","what":"Single Time Point Data with Percentage labels Example for divBarChart():","title":"Helper Functions for Blackstone Research and Evaluation","text":"","code":"# Pass the single time point factor variables and the levels to 'divBarChart()': div_chart_single <- bre::divBarChart(    df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,    percent_label = TRUE, width = 0.6 ) div_chart_single # With new labels and order taken from `question_labels` argument, each  # item has it's own sample size in the label: div_chart_single_labels <- bre::divBarChart(    df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels, overall_n = FALSE,    question_labels = question_labels, question_order = TRUE, percent_label = TRUE, width = 0.6 ) div_chart_single_labels"},{"path":"https://zwcrowley.github.io/bre/index.html","id":"pre-post-data-example-for-divbarchart","dir":"","previous_headings":"Data Visualizations Examples > divBarChart()","what":"Pre-Post Data Example for divBarChart()","title":"Helper Functions for Blackstone Research and Evaluation","text":"","code":"# Pass the factor variables and the levels to 'divBarChart()', set so that it  # returns the percent labels on the bars: div_chart <- divBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = NULL, percent_label = TRUE, width = NULL, fill_colors = \"seq\" ) div_chart # With new labels and order taken from question_labels argument: div_chart_labels <- divBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = question_labels, question_order = TRUE,   percent_label = TRUE, width = NULL, fill_colors = \"seq\" ) div_chart_labels"},{"path":"https://zwcrowley.github.io/bre/index.html","id":"arrowchart","dir":"","previous_headings":"Data Visualizations Examples","what":"arrowChart()","title":"Helper Functions for Blackstone Research and Evaluation","text":"arrowChart() takes 6 arguments, first 3 required: df Required, tibble data frame numeric data items prefix pre_ post_. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). arrow_colors Required, character vector hex codes colors associate item, needs length longer items place chart. overall_n Logical, default FALSE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels “name” old labels “variable” sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest post score average top plot descending. arrowChart() creates arrow chart numeric data based pre-post averages item branding style Blackstone Research Evaluation. arrowChart() sorts chart highest post scores top lowest bottom.","code":""},{"path":"https://zwcrowley.github.io/bre/index.html","id":"examples-using-arrowchart","dir":"","previous_headings":"Data Visualizations Examples > arrowChart()","what":"Examples using arrowChart()","title":"Helper Functions for Blackstone Research and Evaluation","text":"","code":"# Select only the numeric variables from the df in the last chunk (cat_items_1) using tidy select(contains(\"cat\")), adding a group variable that is set as a factor: items <- dplyr::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 )  # Set up the labels for the x-axis, this will match the numeric response in the data: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\")  # Question labels as a named vector with the naming structure like this: c(\"{new label}\" = \"{original variable name}\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                     \"Write a lot of research papers\" = \"Write\",                     \"Research in a lab with faculty\" = \"Research\",                     \"Organization of a large research project\" = \"Organization\",                     \"Source work for a research paper\" = \"Source\")   # Example with n for each question and original labels: arrow_chart_1 <- bre::arrowChart(df = items, scale_labels = levels_min_ext,                                   overall_n = FALSE, question_labels = NULL, question_order = FALSE) arrow_chart_1 # With new labels, question_order = FALSE, and overall_n set to TRUE: arrow_chart_labels <- bre::arrowChart(df = items, scale_labels = levels_min_ext,                                        overall_n = FALSE, question_labels = question_labels, question_order = FALSE) arrow_chart_labels # With new labels and order taken from question_labels argument, and overall_n set to FALSE: arrow_chart_labels_ordered <- bre::arrowChart(df = items, scale_labels = levels_min_ext,                                                overall_n = FALSE, question_labels = question_labels, question_order = TRUE) arrow_chart_labels_ordered"},{"path":"https://zwcrowley.github.io/bre/index.html","id":"arrowchartgroup","dir":"","previous_headings":"Data Visualizations Examples","what":"arrowChartGroup()","title":"Helper Functions for Blackstone Research and Evaluation","text":"arrowChartGroup() takes 6 arguments, first 3 required: df Required, tibble data frame numeric data items prefix pre_ post_; categorical group variable split data (e.g. role, gender, education level, etc.). group Required, name grouping variable quoted character string (e.g. “role”, “gender”, “edu_level”, etc.). scale_labels scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). group_colors Required, character vector hex codes colors associate group , e.g. data two groups function creates overall group function need ‘group_colors’ character vector three colors. ‘group_colors’ need order want associated group based factor levels group variable, last color overall group “” overall_n Logical, default FALSE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels “name” old labels “variable” sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest post score average top plot descending. arrowChartGroup() creates arrow chart numeric data based pre-post averages group overall group whole data set branding style Blackstone Research Evaluation. arrowChartGroup() sorts chart highest post scores top lowest bottom.","code":""},{"path":"https://zwcrowley.github.io/bre/index.html","id":"examples-using-arrowchartgroup","dir":"","previous_headings":"Data Visualizations Examples > arrowChartGroup()","what":"Examples using arrowChartGroup()","title":"Helper Functions for Blackstone Research and Evaluation","text":"functions visuals added bre package needed, sure reach ideas package issues!","code":"# Add a group variable `edu_level` that is set as a factor to the numeric items above called `items`: arrow_items <- items %>%   dplyr::mutate(     edu_level = factor(c(       \"grad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\", \"undergrad\", \"undergrad\", \"grad\", \"undergrad\"     ), levels = c(\"grad\", \"undergrad\"))   )  # Set up the labels for the x-axis, this will match the numeric response in the data: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\")  # Question labels as a named vector with the naming structure like this: c(\"{new label}\" = \"{original variable name}\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                     \"Write a lot of research papers\" = \"Write\",                     \"Research in a lab with faculty\" = \"Research\",                     \"Organization of a large research project\" = \"Organization\",                     \"Source work for a research paper\" = \"Source\")  # Example with n for each question and original labels: arrow_chart_grouped <- bre::arrowChartGroup(df = arrow_items, group = \"edu_level\", group_levels = c(\"grad\", \"undergrad\"),                                             scale_labels = levels_min_ext, overall_n = FALSE, question_labels = NULL,                                              question_order = FALSE) arrow_chart_grouped # With new labels, question_order = FALSE, and overall_n set to TRUE: arrow_chart_grouped_labels <- bre::arrowChartGroup(df = arrow_items, group = \"edu_level\", group_levels = c(\"grad\", \"undergrad\"),                                                    scale_labels = levels_min_ext, overall_n = FALSE, question_labels = question_labels,                                                     question_order = FALSE) arrow_chart_grouped_labels # With new labels and order taken from question_labels argument, and overall_n set to FALSE: arrow_chart_grouped_labels_ordered <- bre::arrowChartGroup(df = arrow_items, group = \"edu_level\", group_levels = c(\"grad\", \"undergrad\"),                                                             scale_labels = levels_min_ext, overall_n = FALSE, question_labels = question_labels,                                                             question_order = TRUE) arrow_chart_grouped_labels_ordered"},{"path":"https://zwcrowley.github.io/bre/reference/TheMarkUSA-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bre: Helper Functions for The Mark USA, INC — bre-package","title":"bre: Helper Functions for The Mark USA, INC — bre-package","text":"goal bre make data cleaning creation visualizations easier faster Mark USA, INC. bre contains functions create visuals Mark USA branding helper functions common data cleaning manipulation tasks use everyone Mark USA, INC.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/bre/reference/TheMarkUSA-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bre: Helper Functions for The Mark USA, INC — bre-package","text":"Maintainer: Zack Crowley zcrowley@themarkusa.com contributors: Mark USA, INC. [copyright holder, funder]","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addBarChartPrePostTheme.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","title":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","text":"function add plot theme options Pre-Post bar chart, pass args font size family.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addBarChartPrePostTheme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","text":"","code":"addBarChartPrePostTheme(font_size, font_family)"},{"path":"https://zwcrowley.github.io/bre/reference/addBarChartPrePostTheme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","text":"font_size Required, numeric, font size chart. font_family Required, character, name font family use chart.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addBarChartPrePostTheme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","text":"list ggplot2 guides theme objects add ggplot2 object.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addBarChartTheme.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper Functions for ggplot2 visuals for the bre package — addBarChartTheme","title":"Helper Functions for ggplot2 visuals for the bre package — addBarChartTheme","text":"function add plot theme options bar chart, pass args font size family.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addBarChartTheme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper Functions for ggplot2 visuals for the bre package — addBarChartTheme","text":"","code":"addBarChartTheme(font_size, font_family)"},{"path":"https://zwcrowley.github.io/bre/reference/addBarChartTheme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper Functions for ggplot2 visuals for the bre package — addBarChartTheme","text":"font_size Required, numeric, font size chart. font_family Required, character, name font family use chart.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addBarChartTheme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper Functions for ggplot2 visuals for the bre package — addBarChartTheme","text":"list ggplot2 guides theme objects add ggplot2 object.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addBarChartTheme.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Helper Functions for ggplot2 visuals for the bre package — addBarChartTheme","text":"Helper function Add Theme Options Bar Chart","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addPlotTag.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to Add a Plot Tag — addPlotTag","title":"Helper function to Add a Plot Tag — addPlotTag","text":"function add plot tag upper left corner ggplot total n sample. Pass args total n, font size family.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addPlotTag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to Add a Plot Tag — addPlotTag","text":"","code":"addPlotTag(n, font_size, font_family, plot_tag_position = c(-0.01, 1.05))"},{"path":"https://zwcrowley.github.io/bre/reference/addPlotTag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to Add a Plot Tag — addPlotTag","text":"n Required, numeric, total n sample chart font_size Required, numeric, font size chart. font_family Required, character, name font family use chart. plot_tag_position Required, character vector length two specifies x y coordinates places plot tag, defaults c(-0.01, 1.05).","code":""},{"path":"https://zwcrowley.github.io/bre/reference/addPlotTag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to Add a Plot Tag — addPlotTag","text":"list ggplot2 labs theme objects add ggplot2 object.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/arrowChart.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"arrowChart() creates pre-post arrow chart averages returns ggplot object.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/arrowChart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"","code":"arrowChart(   df,   scale_labels,   arrow_colors = \"#283251\",   overall_n = TRUE,   question_labels = NULL,   question_order = FALSE,   font_family = \"Arial\",   font_size = 10 )"},{"path":"https://zwcrowley.github.io/bre/reference/arrowChart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"df Required, tibble data frame numeric data items prefix pre_ post_. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). arrow_colors Required, defaults dark blue BRE color code \"#283251\" values, character vector hex codes colors associate item, needs length longer items place chart. overall_n Logical, default TRUE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest post score average top plot descending. font_family Character value set font family text chart, defaults \"Arial\". font_size Numeric value set font size points text chart, defaults size 10.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/arrowChart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"ggplot2 object plots items arrow bar chart.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/arrowChart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"","code":"items <- dplyr::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 ) # Labels for response scales to recode the numeric variables to on the plot: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                      \"Write a lot of research papers\" = \"Write\",                      \"Research in a lab with faculty\" = \"Research\",                      \"Organization of a large research project\" = \"Organization\",                      \"Source work for a research paper\" = \"Source\")  # Example with n for each question and original labels: arrowChart(df = items, scale_labels = levels_min_ext, overall_n = FALSE,            question_labels = NULL, question_order = FALSE)  # With new labels, question_order = FALSE, and overall_n set to TRUE: arrowChart(df = items, scale_labels = levels_min_ext, overall_n = TRUE,            question_labels = question_labels, question_order = FALSE)  # With new labels and order taken from question_labels argument, and overall_n set to FALSE: arrowChart(df = items, scale_labels = levels_min_ext, overall_n = FALSE,            question_labels = question_labels, question_order = TRUE)"},{"path":"https://zwcrowley.github.io/bre/reference/arrowChartGroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"arrowChartGroup() creates pre-post arrow chart group averages returns ggplot object.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/arrowChartGroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"","code":"arrowChartGroup(   df,   group,   scale_labels,   group_colors = NULL,   group_levels,   overall_n = TRUE,   question_labels = NULL,   question_order = FALSE,   font_family = \"Arial\",   font_size = 10 )"},{"path":"https://zwcrowley.github.io/bre/reference/arrowChartGroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"df Required, tibble data frame numeric data items prefix pre_ post_; categorical group variable split data (e.g. role, gender, education level, etc.). group Required, name grouping variable quoted character string, e.g. \"role\", \"gender\", \"edu_level\", etc.. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). group_colors Required, character vector hex codes colors associate group supplied group_levels argument. , e.g. data two groups function creates overall group function need 'group_colors' character vector three colors. group_colors need order want associated group based factor levels group variable. Defaults BRE custom qualitative palette black always color \"Overall\" group. group_levels Required, character vector factor levels grouping variable, e.g. grouping variable gender : \"male\", \"female\", \"non-binary\". overall_n Logical, default TRUE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest post score average top plot descending. font_family Character value set font family text chart, defaults \"Arial\". font_size Numeric value set font size points text chart, defaults size 10.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/arrowChartGroup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"ggplot2 object plots items arrow bar chart.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/arrowChartGroup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"","code":"items <- dplyr::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1,   edu_level = factor(        c(       \"grad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\",       \"undergrad\", \"undergrad\", \"grad\", \"undergrad\"       ),       levels = c(\"grad\", \"undergrad\")       ) )  # Labels for response scales to recode the numeric variables to on the plot: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                      \"Write a lot of research papers\" = \"Write\",                      \"Research in a lab with faculty\" = \"Research\",                      \"Organization of a large research project\" = \"Organization\",                      \"Source work for a research paper\" = \"Source\")  # Example grouped by the variable \"edu_level\", with n for each question and original labels: arrowChartGroup(df = items, group = \"edu_level\", scale_labels = levels_min_ext,                 group_levels = c(\"grad\", \"undergrad\"), overall_n = FALSE,                 question_labels = NULL, question_order = FALSE)   # With new labels, question_order = FALSE, and overall_n set to TRUE: arrowChartGroup(df = items, group = \"edu_level\", scale_labels = levels_min_ext,                 group_levels = c(\"grad\", \"undergrad\"), overall_n = TRUE,                 question_labels = question_labels, question_order = FALSE)   # With new labels and order taken from question_labels argument, and overall_n set to FALSE: arrowChartGroup(df = items, group = \"edu_level\", scale_labels = levels_min_ext,                 group_levels = c(\"grad\", \"undergrad\"), overall_n = FALSE,                 question_labels = question_labels, question_order = TRUE)"},{"path":"https://zwcrowley.github.io/bre/reference/bre-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bre: Helper Functions for Blackstone Research and Evaluation — bre-package","title":"bre: Helper Functions for Blackstone Research and Evaluation — bre-package","text":"goal `bre` make data cleaning creation visualizations easier faster Blackstone Research Evaluation. `bre` contains functions create visuals Blackstone Research Evaluation branding helper functions common data cleaning manipulation tasks everyone Blackstone Research Evaluation.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/bre/reference/bre-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bre: Helper Functions for Blackstone Research and Evaluation — bre-package","text":"Maintainer: Zack Crowley zcrowley@blackstoneevaluation.com contributors: Blackstone Research Evaluation [copyright holder, funder]","code":""},{"path":"https://zwcrowley.github.io/bre/reference/breColors.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper Functions for colors of visuals for the bre package — breColors","title":"Helper Functions for colors of visuals for the bre package — breColors","text":"utils function loading Blackstone Research Evaluation colors charts.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/breColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper Functions for colors of visuals for the bre package — breColors","text":"","code":"breColors"},{"path":"https://zwcrowley.github.io/bre/reference/breColors.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Helper Functions for colors of visuals for the bre package — breColors","text":"object class character length 4.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/breColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper Functions for colors of visuals for the bre package — breColors","text":"named vector hex colors Blackstone Research Evaluation.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/breColors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Helper Functions for colors of visuals for the bre package — breColors","text":"BRE Colors Named Vector","code":""},{"path":"https://zwcrowley.github.io/bre/reference/customCols.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function that makes selections from a color palette. — customCols","title":"Helper function that makes selections from a color palette. — customCols","text":"function return hex color codes color palette name numbered position.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/customCols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function that makes selections from a color palette. — customCols","text":"","code":"customCols(pal = qualColors(), cols = NULL)"},{"path":"https://zwcrowley.github.io/bre/reference/customCols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function that makes selections from a color palette. — customCols","text":"pal Required, named color palette named vector color hex codes, defaults qualColors. cols Required, character vector names numbered position use select named vector color hex codes , defaults NULL returns full palette.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/customCols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function that makes selections from a color palette. — customCols","text":"named character vector color hex codes.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/dataSumm.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a data frame that is a summary table of counts and percentages — dataSumm","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"Creates data frame summary table counts percentages","code":""},{"path":"https://zwcrowley.github.io/bre/reference/dataSumm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"","code":"dataSumm(var, na.rm = TRUE, sort_n = FALSE)"},{"path":"https://zwcrowley.github.io/bre/reference/dataSumm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"var column selected tibble/data frame categorical/factor variable summarized table. na.rm Logical, defaults TRUE. Drops NA values. sort_n Logical, defaults FALSE. TRUE, sorts data count response (n_answers). FALSE, sorts response.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/dataSumm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"tibble data 5 columns: item, response, n_answers, percent_answers percent_answers_label. Item name original item, Response categorical responses possible item. n_answers count response, percent_answers percentage response percent_answers_label character variable percentage labelled percent sign use label.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/dataSumm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"","code":"data <- tibble::tibble(   role = factor(c(     \"Faculty\", \"Postdoc\", \"Undergraduate student\", \"Graduate student\",     \"Graduate student\", \"Postdoc\", \"Postdoc\", \"Faculty\",     \"Faculty\", \"Graduate student\", \"Graduate student\", \"Postdoc\",     \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Graduate student\",     \"Undergraduate student\", \"Undergraduate student\", \"NA\", \"NA\"   ), levels = c(\"Undergraduate student\", \"Graduate student\", \"Postdoc\",\"Faculty\")) )  data %>%   dplyr::select(role) %>%   dataSumm() #> # A tibble: 4 × 5 #>   question response              n_answers percent_answers percent_answers_label #>   <chr>    <fct>                     <int>           <dbl> <chr>                 #> 1 role     Undergraduate student         3            0.15 15%                   #> 2 role     Graduate student              5            0.25 25%                   #> 3 role     Postdoc                       4            0.2  20%                   #> 4 role     Faculty                       8            0.4  40%                    # Includes NA values and sorted by count of response: data %>%   dplyr::select(role) %>%   dataSumm(na.rm = FALSE, sort_n = TRUE) #> # A tibble: 5 × 5 #>   question response              n_answers percent_answers percent_answers_label #>   <chr>    <fct>                     <int>           <dbl> <chr>                 #> 1 role     Faculty                       8          0.364  36%                   #> 2 role     Graduate student              5          0.227  23%                   #> 3 role     Postdoc                       4          0.182  18%                   #> 4 role     Undergraduate student         3          0.136  14%                   #> 5 role     NA                            2          0.0909 9%"},{"path":"https://zwcrowley.github.io/bre/reference/dataVizCleaning.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"Creates data frame summary table counts percentages","code":""},{"path":"https://zwcrowley.github.io/bre/reference/dataVizCleaning.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"","code":"dataVizCleaning(df, scale_labels, pre_post = FALSE, na_remove = TRUE)"},{"path":"https://zwcrowley.github.io/bre/reference/dataVizCleaning.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"df Required, tibble/data frame survey items categorical/character variables. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). pre_post Logical, default FALSE. true, returns tibble additional column timing factor variable either Pre Post. na_remove Logical, defaults TRUE. TRUE, Drops NA values; FALSE, turns NA's \"Missing\" adds factor first position scale_labels.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/dataVizCleaning.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"tibble data 5 columns: question, response, n_answers, percent_answers percent_answers_label. question name original item, response categorical responses possible item. n_answers count response, percent_answers percentage response percent_answers_label character variable percentage labelled percent sign use text label. pre_post arg TRUE, column timing added factor variable either Pre Post.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/dataVizCleaning.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"","code":"# Fake data for examples, first are single items and the second has pre-post data with # correct prefixes in variable names: items_single <- tibble::tibble(     Organization = c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\",                      \"Good\", \"Moderate\", \"Slight\", \"Minimal\"),     Source = c(\"Slight\", \"Slight\", \"Moderate\", \"Extensive\", \"Good\", \"Moderate\",                 \"Slight\", \"Minimal\", \"Slight\"),     Publish = c(\"Minimal\", \"Minimal\", \"Minimal\", \"Slight\", \"Slight\", \"Slight\",                 \"Moderate\", \"Moderate\", \"Moderate\"),     Write = c(\"Slight\", \"Slight\", \"Slight\", \"Moderate\", \"Moderate\", \"Moderate\",                 \"Good\", \"Good\", \"Good\"),     Research = c(\"Minimal\", \"Minimal\", \"Slight\", \"Slight\", \"Moderate\",                 \"Moderate\", \"Good\", \"Good\", \"Good\") )  items_pre_post <- tibble::tibble(     pre_Organization = c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\",                     \"Extensive\", \"Good\", \"Moderate\", \"Slight\", \"Minimal\"),     post_Organization = c(\"Slight\", \"Moderate\", \"Good\", \"Extensive\",                     \"Extensive\", \"Extensive\", \"Good\", \"Moderate\", \"Slight\"),     pre_Source = c(\"Slight\", \"Slight\", \"Moderate\", \"Extensive\", \"Good\",                     \"Moderate\", \"Slight\", \"Minimal\", \"Slight\"),     post_Source = c(\"Good\", \"Good\", \"Extensive\", \"Extensive\", \"Good\",                     \"Extensive\", \"Good\", \"Moderate\", \"Good\"),     pre_Publish = c(\"Minimal\", \"Minimal\", \"Minimal\", \"Slight\", \"Slight\",                     \"Slight\", \"Moderate\", \"Moderate\", \"Moderate\"),     post_Publish = c(\"Moderate\", \"Moderate\", \"Moderate\", \"Good\", \"Good\",                     \"Good\", \"Extensive\", \"Extensive\", \"Extensive\"),     pre_Write = c(\"Slight\", \"Slight\", \"Slight\", \"Moderate\", \"Moderate\",                     \"Moderate\", \"Good\", \"Good\", \"Good\"),     post_Write = c(\"Moderate\", \"Moderate\", \"Moderate\", \"Good\", \"Good\",                     \"Good\", \"Extensive\", \"Extensive\", \"Extensive\"),     pre_Research = c(\"Minimal\", \"Minimal\", \"Slight\", \"Slight\", \"Moderate\",                     \"Moderate\", \"Good\", \"Good\", \"Good\"),     post_Research = c(\"Slight\", \"Slight\", \"Moderate\", \"Moderate\", \"Good\",                     \"Good\", \"Extensive\", \"Extensive\", \"Extensive\") ) # Add a row of NA values to each fake data set: items_pre_post_na <- dplyr::rows_append(items_pre_post,          tibble::as_tibble_row(purrr::set_names(rep(NA, NCOL(items_pre_post)),          names(items_pre_post)))) items_single_na <- dplyr::rows_append(items_single,          tibble::as_tibble_row(purrr::set_names(rep(NA, NCOL(items_single)),          names(items_single))))  # Likert scale to pass to `scale_labels` that is the order to arrange each variable: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\")  dataVizCleaning(df = items_single, pre_post = FALSE,                 scale_labels = levels_min_ext, na_remove = TRUE) #> # A tibble: 20 × 5 #>    question     response  n_answers percent_answers percent_answers_label #>    <chr>        <fct>         <int>           <dbl> <chr>                 #>  1 Organization Minimal           2           0.222 22%                   #>  2 Organization Slight            2           0.222 22%                   #>  3 Organization Moderate          2           0.222 22%                   #>  4 Organization Good              2           0.222 22%                   #>  5 Organization Extensive         1           0.111 11%                   #>  6 Publish      Minimal           3           0.333 33%                   #>  7 Publish      Slight            3           0.333 33%                   #>  8 Publish      Moderate          3           0.333 33%                   #>  9 Research     Minimal           2           0.222 22%                   #> 10 Research     Slight            2           0.222 22%                   #> 11 Research     Moderate          2           0.222 22%                   #> 12 Research     Good              3           0.333 33%                   #> 13 Source       Minimal           1           0.111 11%                   #> 14 Source       Slight            4           0.444 44%                   #> 15 Source       Moderate          2           0.222 22%                   #> 16 Source       Good              1           0.111 11%                   #> 17 Source       Extensive         1           0.111 11%                   #> 18 Write        Slight            3           0.333 33%                   #> 19 Write        Moderate          3           0.333 33%                   #> 20 Write        Good              3           0.333 33%                   dataVizCleaning(df = items_single_na, pre_post = FALSE,                 scale_labels = levels_min_ext, na_remove = FALSE) #> # A tibble: 25 × 5 #>    question     response  n_answers percent_answers percent_answers_label #>    <chr>        <fct>         <int>           <dbl> <chr>                 #>  1 Organization Missing           1             0.1 10%                   #>  2 Organization Minimal           2             0.2 20%                   #>  3 Organization Slight            2             0.2 20%                   #>  4 Organization Moderate          2             0.2 20%                   #>  5 Organization Good              2             0.2 20%                   #>  6 Organization Extensive         1             0.1 10%                   #>  7 Publish      Missing           1             0.1 10%                   #>  8 Publish      Minimal           3             0.3 30%                   #>  9 Publish      Slight            3             0.3 30%                   #> 10 Publish      Moderate          3             0.3 30%                   #> # ℹ 15 more rows dataVizCleaning(df = items_pre_post, pre_post = TRUE,                 scale_labels = levels_min_ext, na_remove = TRUE) #> # A tibble: 37 × 6 #>    question     timing response  n_answers percent_answers percent_answers_label #>    <chr>        <fct>  <fct>         <int>           <dbl> <chr>                 #>  1 Organization Pre    Minimal           2           0.222 22%                   #>  2 Organization Pre    Slight            2           0.222 22%                   #>  3 Organization Pre    Moderate          2           0.222 22%                   #>  4 Organization Pre    Good              2           0.222 22%                   #>  5 Organization Pre    Extensive         1           0.111 11%                   #>  6 Organization Post   Slight            2           0.222 22%                   #>  7 Organization Post   Moderate          2           0.222 22%                   #>  8 Organization Post   Good              2           0.222 22%                   #>  9 Organization Post   Extensive         3           0.333 33%                   #> 10 Publish      Pre    Minimal           3           0.333 33%                   #> # ℹ 27 more rows dataVizCleaning(df = items_pre_post_na, pre_post = TRUE,                 scale_labels = levels_min_ext, na_remove = FALSE) #> # A tibble: 47 × 6 #>    question     timing response  n_answers percent_answers percent_answers_label #>    <chr>        <fct>  <fct>         <int>           <dbl> <chr>                 #>  1 Organization Pre    Missing           1             0.1 10%                   #>  2 Organization Pre    Minimal           2             0.2 20%                   #>  3 Organization Pre    Slight            2             0.2 20%                   #>  4 Organization Pre    Moderate          2             0.2 20%                   #>  5 Organization Pre    Good              2             0.2 20%                   #>  6 Organization Pre    Extensive         1             0.1 10%                   #>  7 Organization Post   Missing           1             0.1 10%                   #>  8 Organization Post   Slight            2             0.2 20%                   #>  9 Organization Post   Moderate          2             0.2 20%                   #> 10 Organization Post   Good              2             0.2 20%                   #> # ℹ 37 more rows"},{"path":"https://zwcrowley.github.io/bre/reference/divBarChart.html","id":null,"dir":"Reference","previous_headings":"","what":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"divBarChart() creates diverging bar chart returns ggplot object Blackstone Research Evaluation branding.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/divBarChart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"","code":"divBarChart(   df,   scale_labels,   fill_colors = \"seq\",   pre_post = FALSE,   overall_n = TRUE,   percent_label = TRUE,   question_labels = NULL,   question_order = FALSE,   width = NULL,   font_family = \"Arial\",   font_size = 10 )"},{"path":"https://zwcrowley.github.io/bre/reference/divBarChart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"df Required, tibble/data frame survey items categorical/character variables, inserted stacked bar chart Blackstone Research Evaluation branding. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). fill_colors Default \"seq\", \"seq\", color scale fill bar set blue sequential palette. set \"div\", blue-red diverging color palette, otherwise user can input character vector hex codes least long character vector passed scale_labels argument. pre_post Logical, default FALSE. true, returns pre-post stacked bar chart. overall_n Logical, default TRUE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. percent_label Logical, default TRUE. FALSE, labels bars number answers per response. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest positive valenced response options top plot descending. width Input value 0.3 0.8 set thickness bars. Default NULL. font_family Character value set font family text chart, defaults \"Arial\". font_size Numeric value set font size points text chart, defaults size 10.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/divBarChart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"ggplot2 object plots items stacked bar chart can exported.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/divBarChart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"","code":"items <- tibble::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 )  items_single <- tibble::tibble(   Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4), )  # Set scale_labels for recodeCat function: # scale_labels as a named character vector, items in correct order: levels_min_ext <- c(   \"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\",   \"Good\" = \"4\", \"Extensive\" = \"5\" )  # bar_scale_labels as just the names from levels_min_ext: bar_scale_labels <- names(levels_min_ext)  # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(   \"Publish a lot of high quality papers\" = \"Publish\",   \"Write a lot of research papers\" = \"Write\",   \"Research in a lab with faculty\" = \"Research\",   \"Organization of a large research project\" = \"Organization\",   \"Source work for a research paper\" = \"Source\" )  # Recode the numeric to factor variables using the levels from levels_min_ext and # select the factor variables:: cat_items <- bre::recodeCat(items, levels_min_ext) %>%                  dplyr::select(dplyr::where(is.factor)) cat_items_single <- bre::recodeCat(items_single, levels_min_ext) %>%                         dplyr::select(dplyr::where(is.factor))  # Pass the factor variables and the levels to stackedBarChart: divBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = NULL, percent_label = TRUE, width = NULL )  divBarChart(   df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,   question_labels = NULL, percent_label = TRUE, width = NULL )  divBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = question_labels, question_order = FALSE, percent_label = TRUE, width = NULL )  divBarChart(   df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,   question_labels = question_labels, question_order = FALSE, percent_label = TRUE, width = NULL )"},{"path":"https://zwcrowley.github.io/bre/reference/divFillColors.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"function create diverging color palette using Blue-Red 3 reversed slightly darkened.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/divFillColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"","code":"divFillColors(n_colors)"},{"path":"https://zwcrowley.github.io/bre/reference/divFillColors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"n_colors Required, number color hex codes return.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/divFillColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"character vector hex color codes length n_colorsfrom Blue-Red 3 palette package colorspace.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/divFillColors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"","code":"# Returns the 5 colors in the diverging palette: divFillColors(n_colors = 5) #> [1] \"#600204\" \"#B88081\" \"#DADADA\" \"#7F8EB8\" \"#012B67\"  # Returns the 7 colors colors in the diverging palette:: divFillColors(n_colors = 7) #> [1] \"#600204\" \"#A25959\" \"#CDA2A3\" \"#DADADA\" \"#A3ADCB\" \"#536DA8\" \"#012B67\""},{"path":"https://zwcrowley.github.io/bre/reference/groupedTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"groupedTable() creates summary table frequencies percentages can show breakdowns groups totals data passed . table shows item responses row.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/groupedTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"","code":"groupedTable(df, col_group = NULL, question_labels = NULL, str_width = 20)"},{"path":"https://zwcrowley.github.io/bre/reference/groupedTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"df Required, tibble data frame categorical/factor data also can contain categorical group variable split data, e.g. role, gender, education level, etc. col_group Default NULL. name categorical group variable split data, e.g. role, gender, education level, etc. Must quotes (e.g. \"role\"). question_labels Default NULL. Takes named character vector supply labels questions sort order questions.named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing table, first item appear top table. See examples. str_width Default 20. character length wrap question column. question_labels supplied long use keep question column large table.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/groupedTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"flextable object columns question, response, counts percentages group total column. Colors set Blackstone Research Evaluation branding","code":""},{"path":"https://zwcrowley.github.io/bre/reference/groupedTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"Question Response 1 (n = 6) 2 (n = 6) Total (n = 12)1 Gender      Female 3 (25%) 4 (33%) 7 (58%)  Male 3 (25%) 2 (17%) 5 (42%) Ethnicity      Asian 1 (8%) 2 (17%) 3 (25%)  Black 1 (8%) 1 (8%) 2 (17%)  Hispanic Latino 1 (8%) 2 (17%) 3 (25%)  white 3 (25%) 1 (8%) 4 (33%) Year school      grad 5 (42%) - 5 (42%)  undergrad 1 (8%) 6 (50%) 7 (58%) Department ofAffiliation      Biology 1 (8%) 4 (33%) 5 (42%)  Chemistry 3 (25%) 1 (8%) 4 (33%)  Physics 2 (17%) 1 (8%) 3 (25%) 1n (%) Question Response n = 121 Gender    Female 7 (58%)  Male 5 (42%) Ethnicity    Asian 3 (25%)  Black 2 (17%)  Hispanic Latino 3 (25%)  white 4 (33%) Year school    grad 5 (42%)  undergrad 7 (58%) Department ofAffiliation    Biology 5 (42%)  Chemistry 4 (33%)  Physics 3 (25%) Cohort    1 6 (50%)  2 6 (50%) 1n (%)","code":"data <- dplyr::tibble(   Cohort = factor(c(1,2,1,2,1,2,1,2,1,2,1,2), levels = c(1, 2)),   gender = factor(c(              \"Female\", \"Female\",\"Female\",\"Male\", \"Female\",\"Male\",              \"Male\", \"Female\",\"Male\", \"Female\", \"Male\", \"Female\"              ), levels = c(\"Female\", \"Male\")),   year = factor(c(       \"grad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\",\"undergrad\",       \"undergrad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\",\"undergrad\"                 ), levels = c(\"grad\", \"undergrad\")),  department = factor(c(       \"Chemistry\", \"Biology\", \"Chemistry\", \"Biology\", \"Physics\",\"Biology\",       \"Biology\", \"Physics\", \"Chemistry\", \"Chemistry\", \"Physics\",\"Biology\"                ), levels = c(\"Biology\", \"Chemistry\", \"Physics\")),  ethnicity = factor(c(       \"Asian\", \"Black\", \"white\", \"Hispanic or Latino\", \"white\",\"Asian\",       \"Black\", \"Asian\", \"white\", \"white\", \"Hispanic or Latino\",\"Hispanic or Latino\"                   ), levels = c( \"Asian\", \"Black\", \"Hispanic or Latino\", \"white\")) )  # Labels for questions column of table, pass to question_labels argument: labels <- c('Gender' = \"gender\",              'Ethnicity' = \"ethnicity\",              'Year in school' = \"year\",              'Department of Affiliation' = \"department\")  # Call groupedTable with a grouping variable: data %>% groupedTable(col_group = \"Cohort\", question_labels = labels) .cl-ba18d2fe{}.cl-ba15735c{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-ba157370{font-family:'Arial';font-size:6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;position: relative;bottom:3pt;}.cl-ba157371{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-ba157372{font-family:'Arial';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-ba15737a{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-ba16c7f2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-ba16c7fc{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-ba16d210{width:1.077in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d21a{width:1.286in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d21b{width:0.729in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d224{width:0.845in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d225{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d22e{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d22f{width:0.729in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d238{width:0.845in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d242{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d243{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d244{width:0.729in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d245{width:0.845in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d24c{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d24d{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d24e{width:0.729in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d256{width:0.845in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d260{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d261{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d26a{width:0.729in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d26b{width:0.845in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d26c{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d26d{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d274{width:0.729in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d275{width:0.845in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d276{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d277{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d278{width:0.729in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba16d27e{width:0.845in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}QuestionResponse1 (n = 6)2 (n = 6)Total (n = 12)1GenderFemale3 (25%)4 (33%)7 (58%)Male3 (25%)2 (17%)5 (42%)EthnicityAsian1 (8%)2 (17%)3 (25%)Black1 (8%)1 (8%)2 (17%)Hispanic or Latino1 (8%)2 (17%)3 (25%)white3 (25%)1 (8%)4 (33%)Year in schoolgrad5 (42%)-5 (42%)undergrad1 (8%)6 (50%)7 (58%)Department ofAffiliationBiology1 (8%)4 (33%)5 (42%)Chemistry3 (25%)1 (8%)4 (33%)Physics2 (17%)1 (8%)3 (25%)1n (%)# Call groupedTable without a grouping variable: data %>% groupedTable(question_labels = labels) .cl-ba2fcc84{}.cl-ba2cba8a{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-ba2cba94{font-family:'Arial';font-size:6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;position: relative;bottom:3pt;}.cl-ba2cba9e{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-ba2cbaa8{font-family:'Arial';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-ba2cbaa9{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-ba2e0642{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-ba2e064c{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-ba2e0eb2{width:1.077in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0eb3{width:1.286in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ebc{width:0.723in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ebd{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ebe{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ec6{width:0.723in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ec7{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ed0{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ed1{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0eda{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0edb{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ee4{width:0.723in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ee5{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0eee{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0eef{width:0.723in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ef0{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ef8{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0ef9{width:0.723in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0f02{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0f03{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0f04{width:0.723in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0f0c{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0f0d{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ba2e0f0e{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}QuestionResponsen = 121GenderFemale7 (58%)Male5 (42%)EthnicityAsian3 (25%)Black2 (17%)Hispanic or Latino3 (25%)white4 (33%)Year in schoolgrad5 (42%)undergrad7 (58%)Department ofAffiliationBiology5 (42%)Chemistry4 (33%)Physics3 (25%)Cohort16 (50%)26 (50%)1n (%)"},{"path":"https://zwcrowley.github.io/bre/reference/horzBarChart.html","id":null,"dir":"Reference","previous_headings":"","what":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"horzBarChart() creates horizontal bar chart returns ggplot object Blackstone Research Evaluation branding.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/horzBarChart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"","code":"horzBarChart(df, scale_colors, width = NULL)"},{"path":"https://zwcrowley.github.io/bre/reference/horzBarChart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"df Required, tibble/data frame pre-processed dataSumm(). scale_colors Required, character vector colors scale items. width Input value 0.3 0.8 set thickness bars. Default NULL.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/horzBarChart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"ggplot2 object plots items horizontal bar chart can exported.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/horzBarChart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"","code":"data <- dplyr::tibble(   role = c(     \"Faculty\", \"Postdoc\", \"Undergraduate student\", \"Graduate student\",     \"Graduate student\", \"Postdoc\", \"Postdoc\", \"Faculty\",     \"Faculty\", \"Graduate student\", \"Graduate student\", \"Postdoc\",     \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Graduate student\",     \"Undergraduate student\", \"Undergraduate student\"   ) )  role_summ <- data %>%   dplyr::select(role) %>%   bre::dataSumm()  role_color <- c(\"#2C2C4F\", \"#4B9FA6\", \"#79AB53\", \"#767171\")  horzBarChart(df = role_summ, scale_colors = role_color, width = 0.6)"},{"path":"https://zwcrowley.github.io/bre/reference/labelColorMaker.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function that creates text label colors. — labelColorMaker","title":"Helper function that creates text label colors. — labelColorMaker","text":"function label text color charts inside fill bar charts, returns either \"black\" \"white\" depending luminance color scale passed .","code":""},{"path":"https://zwcrowley.github.io/bre/reference/labelColorMaker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function that creates text label colors. — labelColorMaker","text":"","code":"labelColorMaker(colors, names = NULL)"},{"path":"https://zwcrowley.github.io/bre/reference/labelColorMaker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function that creates text label colors. — labelColorMaker","text":"colors Required, character vector hex color codes, usually color palette chart. names Optional, character vector length colors argument add names returned vector.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/labelColorMaker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function that creates text label colors. — labelColorMaker","text":"character vector colors either \"black\" \"white\" labeling text fill colors.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/levelsEnv.html","id":null,"dir":"Reference","previous_headings":"","what":"Levels Environment and home to all scale_labels vectors: — levelsEnv","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"Levels Environment home scale_labels vectors:","code":""},{"path":"https://zwcrowley.github.io/bre/reference/levelsEnv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"","code":"levelsEnv"},{"path":"https://zwcrowley.github.io/bre/reference/levelsEnv.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"object class environment length 3.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/levelsEnv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"levelsEnv","code":""},{"path":"https://zwcrowley.github.io/bre/reference/levelsEnv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"","code":"# TODO: Figure out how to store all scale_labels vectors and how to then # retrieve them when building charts # One potential solution- use environments and retrieve the vectors when using the package # inside scripts and Rmd docs, and eventually when moving to automating reporting in R. # # Try with three levels that are normally used like this in vectors to pass to the # scale_labels argument across bre package: # # levels min_ext: # levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # # # levels never to always: # levels_never_always <- c(\"Never\", \"Rarely\", \"Sometimes\", \"Frequently\", \"Always\") # # # levels useful: # levels_useful <- c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", # \"Very useful\", \"Extremely useful\") # # How to make them into a Named list of stacked levels: # stacked_levels <- list(levels_min_ext,levels_never_always,levels_useful) # # Names for named list of \"stacked levels\" using the suffixes for stacked bar charts: # names(stacked_levels) <- c(\"levels_min_ext\",\"levels_never_always\",\"levels_useful\") # # TODO: Test in the file \"R_Reporting_template.Rmd\": # # # EXAMPLE: # url <- \"http://mytext.com\" # file <- \"This is the content I downloaded\" # cacheEnv <- new.env() # assign(url, file, envir=cacheEnv) # get(url, envir=cacheEnv) # # Creating and fill new environment with vectors and parameters for use across the whole package: # Name new environment- \"levelsEnv\": # levelsEnv <- new.env() # Assign each vector to the new environment using this code: # assign(<name of var/vector>, <content of var/vector>, envir=cacheEnv) # both the name and content can be already assigned alias/vars that you pass to the assign() # like in the example above: # # levels min_ext: # levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # assign(\"levels_min_ext\", c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"), # envir = levelsEnv) # how to retrieve and name back to the original vector name- Two Ways- # 1. using get() or 2. using the familiar list extraction: env[[<name of var/vector>]]: # levels_min_ext <- get(\"levels_min_ext\", envir = levelsEnv) # levels_min_ext <- levelsEnv[[\"levels_min_ext\"]] # # Assign two other vectors to the new environment- \"levelsEnv\": # # levels never to always: # levels_never_always <- c(\"Never\", \"Rarely\", \"Sometimes\", \"Frequently\", \"Always\") # assign(\"levels_never_always\", c(\"Never\", \"Rarely\", \"Sometimes\", \"Frequently\", \"Always\"), # envir = levelsEnv) # levels_never_always <- get(\"levels_never_always\", envir = levelsEnv) # # levels useful: # levels_useful <- c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", # \"Very useful\", \"Extremely useful\") # assign(\"levels_useful\", c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", # \"Very useful\", \"Extremely useful\"), envir = levelsEnv) # levels_useful <- get(\"levels_useful\", envir = levelsEnv) # Continue adding variables/vectors/parameters as needed for package/reporting needs..."},{"path":"https://zwcrowley.github.io/bre/reference/likertTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"likertTable() creates summary table frequencies percentages Likert scale items can show breakdowns data passed . table contains frequency percent row column Likert scale response, items must scale labels.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/likertTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"","code":"likertTable(df, scale_labels, question_labels = NULL, str_width = 20)"},{"path":"https://zwcrowley.github.io/bre/reference/likertTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"df Required, tibble data frame categorical/factor data scale labels. scale_labels Required, character vector labels response scale Likert items, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). question_labels Default NULL. Takes named character vector supply labels questions sort order questions.named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing table, first item appear top table. See examples. str_width Default 20. character length wrap question column. question_labels supplied long use keep question column large table.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/likertTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"flextable object columns question, likert response item, total column items total n item. Colors set Blackstone Research Evaluation branding","code":""},{"path":"https://zwcrowley.github.io/bre/reference/likertTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"Question Minimal Slight Moderate Good Extensive n Publish lot ofhigh quality papers - 3 (15%) 3 (15%) 4 (20%) 10 (50%) 20 Write lot ofresearch papers - - 2 (10%) 10 (50%) 8 (40%) 20 Research labwith faculty - 1 (5%) 8 (40%) 3 (15%) 8 (40%) 20 Organization ofa large researchproject - 3 (15%) 6 (30%) 5 (25%) 6 (30%) 20 Source work aresearch paper - - 3 (15%) 11 (55%) 6 (30%) 20 Question Minimal Slight Moderate Good Extensive n Organization - 3 (15%) 6 (30%) 5 (25%) 6 (30%) 20 Source - - 3 (15%) 11 (55%) 6 (30%) 20 Publish - 3 (15%) 3 (15%) 4 (20%) 10 (50%) 20 Write - - 2 (10%) 10 (50%) 8 (40%) 20 Research - 1 (5%) 8 (40%) 3 (15%) 8 (40%) 20","code":"data <- tibble::tribble(      ~Organization, ~Source, ~Publish, ~Write, ~Research,                 5L,      3L,       3L,     4L,        5L,                 4L,      4L,       3L,     3L,        3L,                 4L,      4L,       3L,     5L,        3L,                 2L,      5L,       4L,     5L,        3L,                 3L,      4L,       5L,     4L,        5L,                 3L,      4L,       2L,     4L,        2L,                 5L,      4L,       5L,     5L,        3L,                 3L,      5L,       5L,     4L,        3L,                 5L,      4L,       4L,     4L,        5L,                 3L,      5L,       5L,     4L,        3L,                 5L,      4L,       2L,     5L,        5L,                 4L,      3L,       5L,     5L,        4L,                 2L,      4L,       5L,     4L,        3L,                 5L,      4L,       4L,     5L,        4L,                 3L,      5L,       2L,     5L,        5L,                 5L,      4L,       4L,     4L,        5L,                 4L,      4L,       5L,     3L,        5L,                 3L,      5L,       5L,     4L,        4L,                 4L,      3L,       5L,     4L,        5L,                 2L,      5L,       5L,     5L,        3L      )  # Scale labels for the Likert items: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                   \"Write a lot of research papers\" = \"Write\",                   \"Research in a lab with faculty\" = \"Research\",                   \"Organization of a large research project\" = \"Organization\",                   \"Source work for a research paper\" = \"Source\") # Named Vector for recodeCat(): named_levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\",                     \"Good\" = \"4\", \"Extensive\" = \"5\") # Recode the numeric to factor variables using the levels from levels_min_ext: cat_items <- bre::recodeCat(data, named_levels_min_ext) # Select the factor variables, and remove the prefix that recodeCat() added to the factor variables: cat_items <- cat_items %>% dplyr::select(dplyr::where(is.factor)) %>%                            dplyr::rename_with(., ~ stringr::str_remove(.,\"cat_\")) # Another way to convert all to factor variables with levels if already character variables : # cat_items <- data %>% #   mutate(across(everything(),~ factor(., levels = levels_min_ext))) # Pass the factor variables and the levels to likertTable : cat_items %>% likertTable(scale_labels = levels_min_ext, question_labels = question_labels) .cl-badfaf14{}.cl-badcc6fa{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-badcc704{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-badcc70e{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-badde6ca{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-badde6d4{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-baddeeae{width:1.335in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeeaf{width:0.764in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeeb8{width:0.723in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeeb9{width:0.872in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeec2{width:0.792in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeec3{width:0.887in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeecc{width:0.424in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeecd{width:1.335in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeed6{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeed7{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeee0{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeee1{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeee2{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeeea{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeeeb{width:1.335in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeef4{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeefe{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddeeff{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef00{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef08{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef09{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef0a{width:1.335in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef12{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef13{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef1c{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef1d{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef1e{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef26{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef30{width:1.335in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef31{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef32{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef3a{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef44{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef45{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef46{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef47{width:1.335in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef4e{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef58{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef59{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef62{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef63{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baddef64{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}QuestionMinimalSlightModerateGoodExtensivenPublish a lot ofhigh quality papers-3 (15%)3 (15%)4 (20%)10 (50%)20Write a lot ofresearch papers--2 (10%)10 (50%)8 (40%)20Research in a labwith faculty-1 (5%)8 (40%)3 (15%)8 (40%)20Organization ofa large researchproject-3 (15%)6 (30%)5 (25%)6 (30%)20Source work for aresearch paper--3 (15%)11 (55%)6 (30%)20# Call likertTable without a question_labels: cat_items %>% likertTable(scale_labels = levels_min_ext) .cl-baf15610{}.cl-baee9466{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-baee9470{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-baee9471{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-baefaacc{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-baefaad6{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-baefb2ba{width:0.994in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2bb{width:0.764in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2c4{width:0.723in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2ce{width:0.872in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2cf{width:0.792in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2d8{width:0.887in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2e2{width:0.424in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2e3{width:0.994in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2e4{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2ec{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2ed{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb2f6{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb300{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb301{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb302{width:0.994in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb30a{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb30b{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb30c{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb314{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb315{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-baefb31e{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}QuestionMinimalSlightModerateGoodExtensivenOrganization-3 (15%)6 (30%)5 (25%)6 (30%)20Source--3 (15%)11 (55%)6 (30%)20Publish-3 (15%)3 (15%)4 (20%)10 (50%)20Write--2 (10%)10 (50%)8 (40%)20Research-1 (5%)8 (40%)3 (15%)8 (40%)20"},{"path":"https://zwcrowley.github.io/bre/reference/openendedCleanup.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean Up and Format Open-ended Text — openendedCleanup","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"Clean Format Open-ended Text","code":""},{"path":"https://zwcrowley.github.io/bre/reference/openendedCleanup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"","code":"openendedCleanup(df, var, remove_values)"},{"path":"https://zwcrowley.github.io/bre/reference/openendedCleanup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"df Required, tibble/data frame containing character variable text. var Required, character variable clean tibble/data frame, needs quotes. remove_values Required, character vector additional text remove text, see example.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/openendedCleanup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"tibble contains one character variable clean text ready use output.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/openendedCleanup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"","code":"# Example data: #  Training usefulness composite scale- 5 variables of that make up a scale: # Responsible, Ethics, Standards, Practices, Morals #  these are all on a 5-point likert scale of 1 to 5 needs to be #  recoded to: c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", #                \"Very useful\", \"Extremely useful\") # levels useful: levels_useful <- c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\",                    \"Very useful\", \"Extremely useful\") # Data: data <- dplyr::tibble(  Responsible = sample(levels_useful, size = 100, replace = TRUE,                        prob = c(0.1, 0.2, 0.3, 0.2, 0.1)),  Ethics = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.2, 0.3, 0.2, 0.1)),  Standards = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.3, 0.3)),  Practices = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.3, 0.3)),  Morals = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.05, 0.05, 0.2, 0.3, 0.4)),  Responsible_oe = ifelse(Responsible == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Ethics_oe = ifelse(Ethics == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Standards_oe = ifelse(Standards == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Practices_oe = ifelse(Practices == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Morals_oe = ifelse(Morals == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_)  ) %>% dplyr::select(dplyr::ends_with(\"_oe\"))  # Set up character vector of text or other things like punctuation to remove from the text data: remove_values <- c(\"N/A\", \".\", \"A\")  # Cleanup the open-ended response in the variable \"Responsible_oe\" with the function: data %>% openendedCleanup(., \"Responsible_oe\", remove_values) #> # A tibble: 11 × 1 #>    Responsible_oe                                                                #>    <chr>                                                                         #>  1 \"Commodo nisi sapien tellus ipsum dictumst habitant mauris, tempor platea tu… #>  2 \"Dolor iaculis lacus enim, velit neque, id consectetur, vitae odio iaculis\\n… #>  3 \"Felis dui in aenean nullam et, sed. Quis et morbi sodales sapien maximus ar… #>  4 \"Luctus penatibus nulla nullam varius in aenean consectetur vel. Cursus et\\n… #>  5 \"Maximus ac tempor quisque adipiscing nec porttitor. Volutpat vel parturient… #>  6 \"Nec parturient eros efficitur arcu adipiscing, ac. Dictumst a fermentum don… #>  7 \"Sed mauris magna augue dapibus enim. Nisi, mi maximus finibus in volutpat\\n… #>  8 \"Sem vehicula torquent, et dui fringilla vitae tortor sit arcu vestibulum.\\n… #>  9 \"Sit vestibulum elementum, tempor, ut in, at fringilla adipiscing. Purus mon… #> 10 \"Ultricies condimentum ac aenean sollicitudin, vel molestie nibh. Et ac, nis… #> 11 \"Venenatis, ut lacus et donec. Hac urna ac sagittis velit nascetur vestibulu…"},{"path":"https://zwcrowley.github.io/bre/reference/openendedFlextable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"Create Formatted Flextable Open-ended Text","code":""},{"path":"https://zwcrowley.github.io/bre/reference/openendedFlextable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"","code":"openendedFlextable(df, header_label)"},{"path":"https://zwcrowley.github.io/bre/reference/openendedFlextable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"df Required, tibble data frame containing character variable text. header_label Required, label header table (can description prompt full question text).","code":""},{"path":"https://zwcrowley.github.io/bre/reference/openendedFlextable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"flextable object nicely formatted BRE branding alphabetically order randomization.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/openendedFlextable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"Made text example nicely formatted table Aenean malesuada pellentesque maecenas sed et. ut. Porta vestibulum.Ut maecenas sed mauris et nascetur tincidunt dictumst. Id neque efficiturvivamus nunc nisi natoque magna. Vestibulum ac nisl ut non fermentum, urna.Eu tempor pretium et porta, sociis iaculis. Vitae ante vestibulum ipsumsenectus, gravida curabitur ornare vel. donec, nec ipsum ullamcorper. Donec,conubia sociis viverra maecenas aliquet neque etiam, sed diam. Mollis dolor ,sed augue praesent, tempus. Sed ipsum eu sed lacinia inceptos feugiat finibuspellentesque egestas primis. Sed habitasse sed sem ex nostra et. Eget eu cubilia proin. Nec nascetur dui primis cum etiam semper, sedarcu ut commodo congue. Proin litora ligula gravida ut? Ac laoreet, vel feugiat!Sociis non justo nostra, sed, quam, litora dignissim tortor. Mauris proinlacus eget scelerisque, finibus nec laoreet. Vel mi pretium duis pellentesque aiaculis. Duis mi sed ultricies donec ex nibh tempus sit. Felis adipiscing. Ipsum venenatis bibendum ad, dapibus suscipit bibendum nulla. Lacinia urna,tincidunt sapien consequat suspendisse. Mi eleifend tempus cubilia tortor, sit.Mus, ex et aliquam dui tortor. Laoreet sit dapibus mollis leo maximus viverradiam, pellentesque sed nec. Ut integer sit accumsan sed imperdiet etiam quisvestibulum magna iaculis. Penatibus condimentum enim ut magna aenean et, hac nonconubia odio. ligula, montes nisi ac class lacus eget. Est tellus tempor eused vivamus. Sit elit augue varius. Odio nibh congue, integer euismod id rutrumfermentum ex. Sagittis eu id lacus libero maecenas porttitor. Quis malesuadaquis arcu nibh, nec, justo per. Sit consectetur sapien consequat temporpenatibus eu non nec. Sapien nam curabitur sed eros aliquet, nulla mi. Phasellus urna fermentum phasellus mauris, nam nisl lacus tincidunt. Maecenasa, sit sollicitudin sollicitudin urna! Mi senectus ex lobortis fringilla sedornare sed ex. Est quisque nam, eu arcu, tincidunt torquent sed mi. Lectusnisl, maecenas lacus dignissim dignissim, nulla porta cum risus. Ridiculusrutrum neque aptent rhoncus platea. Erat fringilla dolor vehicula scelerisquevenenatis, pretium mi. Ut sapien fringilla sapien aliquet blandit vitae nequenascetur eget quis massa mus. Molestie ullamcorper ac varius sit non necsed vel, non . Rhoncus quis consequat, nulla cras aliquet vestibulum et faucibus quis.Mi donec sit ligula sed augue fermentum eu arcu, sem dolor, sed volutpataliquet. Enim vehicula egestas risus fringilla maecenas mauris lobortis sit utegestas. Maximus nunc justo vitae sed orci diam nibh vel vitae. Libero, sodaleslaoreet elit placerat, dolor litora maximus dictum dis accumsan. Placerat nonrutrum ac dis, tristique vitae metus quam. Ultrices neque ac laoreet auguerisus mattis, et. Laoreet potenti cum lacus mauris, habitant, vehiculaac. Euismod turpis efficitur . Ac, cubilia, porta mollis pellentesque ametsem erat netus. Nec ultrices pellentesque, amet risus torquent tempor portavehicula. Sed sociosqu odio dis risus pulvinar enim sit nullam. Nisl non atfelis efficitur, diam vel vitae sed massa. Vitae sit urna feugiat donec dolor. Suspendisse justo inceptos suspendisse mollis consequat ac duis semper.Porttitor ut lacus sed, id taciti blandit ex vel. Lobortis nisl scelerisquedapibus, montes turpis condimentum. Vehicula nec? Vivamus fusce erat semfaucibus semper ligula eros turpis . Sed vitae laoreet, maurisparturient ante. Montes consectetur turpis quis, nibh, ornare dignissim est.Velit aenean luctus justo blandit vestibulum pharetra nostra inceptos et aptentquis faucibus. Vestibulum netus eget, habitant velit ac blandit id leo. Tortor dapibus sapien nec taciti eleifend eleifend vitae aptent. Ultricies inplacerat bibendum sed ullamcorper faucibus felis id, felis aliquam, facilisis.Fusce tortor nec amet amet, dolor libero enim ligula sed nisi. Nunc, lectusvelit non eleifend commodo, montes turpis ut. Sed lacus non litora eget eu,purus tempor velit. Sed pellentesque faucibus hac duis nisl justo, malesuadarutrum amet mi consequat. Ultrices posuere senectus . Ac augue mollisaccumsan eu pellentesque condimentum amet, sed. Ac eros metus ut interdumimperdiet molestie eu. Facilisi mus donec donec, accumsan justo sollicitudin invehicula. Natoque non ad, ac conubia. Ex pellentesque , eu lacus cubilia felisid condimentum et varius. Nisi eu. Ultrices gravida. Id lorem eu tincidunt sodales suscipit mauris id hachabitasse. Inceptos ut finibus cursus, quisque posuere elementum. Nasceturaenean varius sollicitudin. Dictum maximus montes dignissim nunc dis velitdignissim phasellus turpis ad. Sed ut commodo sem non eleifend porta commodorisus porta nibh aliquam. nisi mi tempor neque. Arcu tellus ut nec, ut etsuscipit velit lacus platea nulla. Amet ac duis vel sed. Sit est velit lectusfames ac fringilla dis sem nisl id et elementum rutrum . Ac, pulvinar ipsum eusem , per. Dis sed enim proin blandit id sapien risus habitasse ac. Facilisispenatibus imperdiet ipsum conubia natoque vitae. Adipiscing pretium metusante dapibus condimentum, cras molestie egestas fusce rhoncus. Ut arcu, egestas,morbi rhoncus praesent ac. Lacus ante maximus . Vel finibus, venenatis. Litoraut quis fermentum enim velit felis sed dictumst vel.","code":"# Example data: #  Training usefulness composite scale- 5 variables of that make up a scale: # Responsible, Ethics, Standards, Practices, Morals #  these are all on a 5-point likert scale of 1 to 5 needs to be #  recoded to: c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", #                \"Very useful\", \"Extremely useful\") # levels useful: levels_useful <- c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\",                    \"Very useful\", \"Extremely useful\") # Data: data <- dplyr::tibble(  Responsible = sample(levels_useful, size = 100, replace = TRUE,                        prob = c(0.1, 0.2, 0.3, 0.2, 0.1)),  Ethics = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.2, 0.3, 0.2, 0.1)),  Standards = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.3, 0.3)),  Practices = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.3, 0.3)),  Morals = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.05, 0.05, 0.2, 0.3, 0.4)),  Responsible_oe = ifelse(Responsible == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Ethics_oe = ifelse(Ethics == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Standards_oe = ifelse(Standards == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Practices_oe = ifelse(Practices == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Morals_oe = ifelse(Morals == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_)  ) %>% dplyr::select(dplyr::ends_with(\"_oe\"))  # Set up character vector of text or other things like punctuation to remove from the text data: remove_values <- c(\"N/A\", \".\", \"A\")  # Make a nice table after cleaning up the responses from the variable \"Responsible_oe\": data %>% bre::openendedCleanup(., \"Responsible_oe\", remove_values) %>%   openendedFlextable(., header_label = \"Made up text example in a nicely formatted table\") .cl-bbd10a44{}.cl-bbce1b72{font-family:'Arial';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-bbce1b86{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-bbcf6b4e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-bbcf7328{width:5.589in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bbcf7329{width:5.589in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bbcf7332{width:5.589in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bbcf7333{width:5.589in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bbcf733c{width:5.589in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bbcf733d{width:5.589in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bbcf7346{width:5.589in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bbcf7347{width:5.589in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bbcf7348{width:5.589in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}Made up text example in a nicely formatted tableAenean in malesuada pellentesque maecenas sed et. In ut. Porta in vestibulum.Ut maecenas sed mauris et nascetur tincidunt dictumst. Id neque efficiturvivamus nunc nisi natoque magna. Vestibulum ac nisl ut non fermentum, urna.Eu tempor pretium et in porta, sociis iaculis. Vitae ante vestibulum ipsumsenectus, gravida curabitur ornare vel. A donec, nec ipsum ullamcorper. Donec,conubia sociis viverra maecenas aliquet neque etiam, sed diam. Mollis dolor in,sed augue praesent, tempus. Sed ipsum eu sed lacinia inceptos feugiat finibuspellentesque egestas primis. Sed habitasse sed sem ex nostra et.Eget a eu cubilia in at proin. Nec nascetur dui primis cum etiam semper, in sedarcu ut commodo congue. Proin litora ligula gravida ut? Ac laoreet, vel feugiat!Sociis non justo nostra, a sed, quam, litora in dignissim tortor. Mauris proinlacus eget scelerisque, finibus nec laoreet. Vel mi pretium duis pellentesque aiaculis. Duis mi sed ultricies donec ex nibh tempus sit. Felis adipiscing.Ipsum venenatis bibendum ad, dapibus suscipit bibendum nulla. Lacinia urna,tincidunt sapien consequat suspendisse. Mi eleifend tempus cubilia tortor, sit.Mus, ex et at aliquam dui tortor. Laoreet sit dapibus mollis leo maximus viverradiam, pellentesque sed nec. Ut integer sit accumsan sed imperdiet etiam quisvestibulum magna iaculis. Penatibus condimentum enim ut magna aenean et, hac nonconubia odio. In ligula, montes nisi ac class lacus eget. Est tellus tempor eused vivamus. Sit elit augue varius. Odio nibh congue, integer euismod id rutrumfermentum ex. Sagittis eu id lacus libero in maecenas porttitor. Quis malesuadaquis arcu nibh, nec, justo per. Sit consectetur sapien consequat temporpenatibus eu non nec. Sapien nam curabitur sed eros aliquet, nulla mi.Phasellus urna fermentum phasellus mauris, nam nisl lacus tincidunt. Maecenasa, sit sollicitudin sollicitudin urna! Mi senectus ex lobortis fringilla sedornare sed ex. Est quisque nam, eu arcu, tincidunt torquent sed mi. Lectusnisl, maecenas lacus dignissim dignissim, nulla porta cum risus. Ridiculusrutrum neque aptent rhoncus platea. Erat fringilla dolor vehicula scelerisquevenenatis, pretium mi. Ut sapien fringilla in sapien aliquet blandit vitae nequenascetur eget quis massa mus. Molestie in ullamcorper ac varius at sit non necsed vel, non in.Rhoncus quis consequat, nulla cras aliquet vestibulum at et faucibus a quis.Mi donec sit ligula sed augue fermentum eu arcu, sem dolor, sed at volutpataliquet. Enim vehicula egestas risus fringilla maecenas mauris lobortis sit utegestas. Maximus nunc justo vitae sed orci diam nibh vel vitae. Libero, sodaleslaoreet elit placerat, dolor litora maximus dictum dis accumsan. Placerat nonrutrum ac dis, tristique vitae metus quam. Ultrices neque ac laoreet auguerisus mattis, a et. Laoreet potenti in cum lacus mauris, habitant, vehiculaac. Euismod turpis efficitur at. Ac, cubilia, porta in mollis pellentesque ametsem erat netus. Nec ultrices pellentesque, amet risus torquent tempor portavehicula. Sed sociosqu odio dis risus pulvinar enim sit nullam. Nisl non atfelis efficitur, diam vel vitae sed massa. Vitae sit urna feugiat donec dolor.Suspendisse justo inceptos suspendisse mollis consequat ac duis semper.Porttitor ut a in lacus sed, id taciti blandit ex vel. Lobortis nisl scelerisquedapibus, montes turpis condimentum. Vehicula nec? Vivamus fusce erat semfaucibus semper ligula eros turpis in in. Sed vitae in laoreet, maurisparturient ante. Montes consectetur turpis quis, nibh, ornare dignissim est.Velit aenean luctus justo blandit vestibulum pharetra nostra inceptos et aptentquis faucibus. Vestibulum netus eget, habitant velit ac blandit id leo.Tortor dapibus sapien nec taciti eleifend eleifend vitae aptent. Ultricies inplacerat bibendum sed ullamcorper faucibus a felis id, felis aliquam, facilisis.Fusce tortor nec amet amet, dolor libero enim in ligula sed nisi. Nunc, lectusvelit non eleifend commodo, montes turpis ut. Sed lacus non litora eget eu,purus tempor velit. Sed pellentesque faucibus hac duis nisl justo, malesuadarutrum amet mi consequat. Ultrices a posuere senectus in. Ac augue mollisaccumsan eu pellentesque condimentum amet, sed. Ac eros metus ut interdumimperdiet molestie eu. Facilisi mus donec donec, accumsan justo sollicitudin invehicula. Natoque non ad, ac conubia. Ex pellentesque in, eu lacus cubilia felisid condimentum et varius. Nisi eu.Ultrices gravida. Id lorem eu tincidunt sodales suscipit mauris id hachabitasse. Inceptos ut finibus cursus, quisque posuere elementum. Nasceturaenean varius sollicitudin. Dictum maximus montes dignissim nunc dis velitdignissim phasellus turpis ad. Sed ut commodo sem non eleifend porta commodorisus porta nibh aliquam. A nisi mi tempor neque. Arcu tellus ut nec, ut etsuscipit velit lacus platea nulla. Amet ac duis vel sed. Sit est velit lectusfames ac fringilla dis sem nisl id et elementum rutrum at. Ac, pulvinar ipsum eusem in, per. Dis sed enim proin blandit id sapien risus habitasse ac. Facilisispenatibus in imperdiet ipsum conubia natoque vitae. Adipiscing pretium metusante dapibus condimentum, cras molestie egestas fusce rhoncus. Ut arcu, egestas,morbi rhoncus praesent ac. Lacus ante maximus at. Vel finibus, venenatis. Litoraut quis fermentum enim velit felis sed dictumst vel."},{"path":"https://zwcrowley.github.io/bre/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://zwcrowley.github.io/bre/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://zwcrowley.github.io/bre/reference/qualColors.html","id":null,"dir":"Reference","previous_headings":"","what":"BRE Qualitative Colors as a Vector — qualColors","title":"BRE Qualitative Colors as a Vector — qualColors","text":"utils function loading Qualitative color scale Blackstone Research Evaluation colors charts.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/qualColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BRE Qualitative Colors as a Vector — qualColors","text":"","code":"qualColors(add_names = FALSE)"},{"path":"https://zwcrowley.github.io/bre/reference/qualColors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BRE Qualitative Colors as a Vector — qualColors","text":"add_names Required, logical, FALSE returns vector hex color codes, TRUE returns named vector color names can used select .","code":""},{"path":"https://zwcrowley.github.io/bre/reference/qualColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BRE Qualitative Colors as a Vector — qualColors","text":"vector named vector hex colors Qualitative color scale Blackstone Research Evaluation.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/qualColors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BRE Qualitative Colors as a Vector — qualColors","text":"","code":"# Full color palette with names: qualColors(add_names = TRUE) #>         orange       sky blue   bluish green        magenta     vermillion  #>      \"#E69F00\"      \"#56B4E9\"      \"#009E73\"      \"#CC79A7\"      \"#D55E00\"  #>           blue viridis purple      dark grey     dark green       bre blue  #>      \"#0072B2\"    \"#440154FF\"      \"#999999\"      \"#117733\"      \"#283251\"  #>   yellow green  #>      \"#999933\"   # function to show color, names and hex codes as visual: show_colors2 <- function(colors) {     labels_color <- purrr::map_chr(seq_along(colors),                                    \\(x) paste0(\"'\",names(colors)[x], \"': \", colors[x]))     labels_text_color <- labelColorMaker(colors = colors)     ggplot2::ggplot(data.frame(id = rev(seq_along(colors)), color = rev(colors))) +         ggplot2::geom_tile(ggplot2::aes(1, id, fill = rev(color))) +         ggplot2::geom_text(ggplot2::aes(1, id, label = labels_color), color = labels_text_color) +         ggplot2::scale_fill_identity() +         ggplot2::scale_color_identity() +         ggplot2::theme_void() } show_colors2(colors = qualColors(add_names = TRUE))"},{"path":"https://zwcrowley.github.io/bre/reference/qualFillColors.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"function create custom qualitative colors palette Okabe-Ito palette, reversed rev_colors set TRUE. Drops black yellow use BRE charts adds three colors: \"#440154FF\", \"#283251\", \"#999933\".","code":""},{"path":"https://zwcrowley.github.io/bre/reference/qualFillColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"","code":"qualFillColors(n_colors = 11, rev_colors = FALSE)"},{"path":"https://zwcrowley.github.io/bre/reference/qualFillColors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"n_colors Required, supply non-negative integer desired number color hex codes return. rev_colors Logical, defaults FALSE, true returns reverse color codes darkest color comes first.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/qualFillColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"character vector hex color codes length n_colors.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/qualFillColors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"","code":"# Returns the full color palette: qualFillColors() #>  [1] \"#E69F00\"   \"#56B4E9\"   \"#009E73\"   \"#CC79A7\"   \"#D55E00\"   \"#0072B2\"   #>  [7] \"#440154FF\" \"#999999\"   \"#117733\"   \"#283251\"   \"#999933\"    # Returns the first 5 colors in the palette: qualFillColors(n_colors = 5) #> [1] \"#E69F00\" \"#56B4E9\" \"#009E73\" \"#CC79A7\" \"#D55E00\"  # Returns the first 5 colors in the palette reversed: qualFillColors(n_colors = 5, rev_colors = TRUE) #> [1] \"#D55E00\" \"#CC79A7\" \"#009E73\" \"#56B4E9\" \"#E69F00\""},{"path":"https://zwcrowley.github.io/bre/reference/recodeCat.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode Numeric Variables to Factor Variables — recodeCat","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"Recode Numeric Variables Factor Variables","code":""},{"path":"https://zwcrowley.github.io/bre/reference/recodeCat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"","code":"recodeCat(df, scale_labels)"},{"path":"https://zwcrowley.github.io/bre/reference/recodeCat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"df Required, tibble/data frame survey items numeric variables need converted factor variables, Can anywhere 3 7 point scales. scale_labels Required, named character vector labels desired scale levels new factor variables. function use vector convert numeric variables factor variables, levels must supplied correct range otherwise else NA returned variables outside range user supplied values. named character vector new labels \"name\" old labels \"variable\" like : c(\"\" = \"\") look like : levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\", \"Good\" = \"4\", \"Extensive\" = \"5\")","code":""},{"path":"https://zwcrowley.github.io/bre/reference/recodeCat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"tibble original numeric variables along new variables now factors prefix cat_{variable_name}, levels taken scale_labels character vector.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/recodeCat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"","code":"items <- dplyr::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 )  levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\",                      \"Good\" = \"4\", \"Extensive\" = \"5\")  recodeCat(df = items, scale_labels = levels_min_ext) #> # A tibble: 9 × 20 #>   pre_Organization post_Organization pre_Source post_Source pre_Publish #>              <dbl>             <dbl>      <dbl>       <dbl>       <dbl> #> 1                1                 2          2           4           1 #> 2                2                 3          2           4           1 #> 3                3                 4          3           5           1 #> 4                4                 5          5           5           2 #> 5                5                 5          4           4           2 #> 6                4                 5          3           5           2 #> 7                3                 4          2           4           3 #> 8                2                 3          1           3           3 #> 9                1                 2          2           4           3 #> # ℹ 15 more variables: post_Publish <dbl>, pre_Write <dbl>, post_Write <dbl>, #> #   pre_Research <dbl>, post_Research <dbl>, cat_pre_Organization <fct>, #> #   cat_post_Organization <fct>, cat_pre_Source <fct>, cat_post_Source <fct>, #> #   cat_pre_Publish <fct>, cat_post_Publish <fct>, cat_pre_Write <fct>, #> #   cat_post_Write <fct>, cat_pre_Research <fct>, cat_post_Research <fct>"},{"path":"https://zwcrowley.github.io/bre/reference/seqFillColors.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"function create sequential color scale using Blues 3, reversed slightly darkened.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/seqFillColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"","code":"seqFillColors(n_colors)"},{"path":"https://zwcrowley.github.io/bre/reference/seqFillColors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"n_colors Required, number color hex codes return.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/seqFillColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"character vector hex color codes length n_colors Blues 3 palette.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/seqFillColors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"","code":"# Returns the 5 colors in the sequential palette: seqFillColors(n_colors = 5) #> [1] \"#DDDDDD\" \"#AEC3DF\" \"#7798BF\" \"#0466A2\" \"#023163\"  # Returns the 7 colors colors in the sequential palette:: seqFillColors(n_colors = 7) #> [1] \"#DDDDDD\" \"#BDCFE6\" \"#9FB5D5\" \"#7798BF\" \"#4677A7\" \"#00548B\" \"#023163\""},{"path":"https://zwcrowley.github.io/bre/reference/stackedBarChart.html","id":null,"dir":"Reference","previous_headings":"","what":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"stackedBarChart() creates stacked bar chart returns ggplot object Blackstone Research Evaluation branding.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/stackedBarChart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"","code":"stackedBarChart(   df,   scale_labels,   fill_colors = \"seq\",   pre_post = FALSE,   overall_n = TRUE,   percent_label = TRUE,   question_labels = NULL,   question_order = FALSE,   width = NULL )"},{"path":"https://zwcrowley.github.io/bre/reference/stackedBarChart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"df Required, tibble/data frame survey items categorical/character variables, inserted stacked bar chart Blackstone Research Evaluation branding. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). fill_colors Default \"seq\", \"seq\", color scale fill bar set blue sequential palette. set \"div\", blue-red diverging color palette, otherwise user can input character vector hex codes least long character vector passed scale_labels argument. pre_post Logical, default FALSE. true, returns pre-post stacked bar chart. overall_n Logical, default TRUE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. percent_label Logical, default TRUE. FALSE, labels bars number answers per response. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest positive valenced response options top plot descending. width Input value 0.3 0.8 set thickness bars. Default NULL.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/stackedBarChart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"ggplot2 object plots items stacked bar chart can exported.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/stackedBarChart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"","code":"items <- tibble::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 )  items_single <- tibble::tibble(   Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4), )  # Set scale_labels for recodeCat function: # scale_labels as a named character vector, items in correct order: levels_min_ext <- c(   \"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\",   \"Good\" = \"4\", \"Extensive\" = \"5\" )  # bar_scale_labels as just the names from levels_min_ext: bar_scale_labels <- names(levels_min_ext)  # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(   \"Publish a lot of high quality papers\" = \"Publish\",   \"Write a lot of research papers\" = \"Write\",   \"Research in a lab with faculty\" = \"Research\",   \"Organization of a large research project\" = \"Organization\",   \"Source work for a research paper\" = \"Source\" )  # Recode the numeric to factor variables using the levels from levels_min_ext and # select the factor variables:: cat_items <- bre::recodeCat(items, levels_min_ext) %>%                  dplyr::select(dplyr::where(is.factor)) cat_items_single <- bre::recodeCat(items_single, levels_min_ext) %>%                         dplyr::select(dplyr::where(is.factor))  # Pass the factor variables and the levels to stackedBarChart: stackedBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = NULL, percent_label = TRUE, width = NULL )  stackedBarChart(   df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,   question_labels = NULL, percent_label = TRUE, width = NULL )  stackedBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = question_labels, question_order = FALSE, percent_label = TRUE, width = NULL )  stackedBarChart(   df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,   question_labels = question_labels, question_order = FALSE, percent_label = TRUE, width = NULL )"},{"path":"https://zwcrowley.github.io/bre/reference/tblSumm.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"Creates summary table counts percentages data frame pre-processed dataSumm() returns flextable object.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/tblSumm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"","code":"tblSumm(df, totals = TRUE)"},{"path":"https://zwcrowley.github.io/bre/reference/tblSumm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"df tibble data frame pre-processed dataSumm() summary includes 5 columns: item, response, n_answers, percent_answers percent_answers_label. Item name original item, Response categorical responses possible item. n_answers count response, percent_answers percentage response percent_answers_label character variable percentage labelled percent sign use label. totals true, returns summary table last row totals, false, final row totals. Set True default.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/tblSumm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"flextable object 3 columns, response, counts percentages, Colors set Blackstone Research Evaluation branding","code":""},{"path":"https://zwcrowley.github.io/bre/reference/tblSumm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"Response Percent Count Faculty 40% 8 Graduate student 25% 5 Postdoc 20% 4 Undergraduate student 15% 3 Total - 20","code":"data <- dplyr::tibble(   role = c(     \"Faculty\", \"Postdoc\", \"Undergraduate student\", \"Graduate student\",     \"Graduate student\", \"Postdoc\", \"Postdoc\", \"Faculty\",     \"Faculty\", \"Graduate student\", \"Graduate student\", \"Postdoc\",     \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Graduate student\",     \"Undergraduate student\", \"Undergraduate student\"   ) )  role_summ <- data %>%   dplyr::select(role) %>%   bre::dataSumm()  role_summ %>% tblSumm() .cl-bd795856{}.cl-bd768fa4{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-bd768fae{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-bd768fb8{font-family:'Arial';font-size:9pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-bd77a5b0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-bd77a5ba{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-bd77adda{width:1.564in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ade4{width:0.795in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ade5{width:0.686in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77adee{width:1.564in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77adf8{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77adf9{width:0.686in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77adfa{width:1.564in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ae02{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ae03{width:0.686in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ae0c{width:1.564in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ae0d{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ae16{width:0.686in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ae17{width:1.564in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ae18{width:0.795in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd77ae20{width:0.686in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}ResponsePercentCountFaculty40%8Graduate student25%5Postdoc20%4Undergraduate student15%3Total-20"},{"path":"https://zwcrowley.github.io/bre/reference/testFlextable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"Create Flextable Blackstone Research Evaluation Branding","code":""},{"path":"https://zwcrowley.github.io/bre/reference/testFlextable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"","code":"testFlextable(data)"},{"path":"https://zwcrowley.github.io/bre/reference/testFlextable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"data Required, tibble/data frame summary/descriptice test statistics.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/testFlextable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"nicely formatted table flextable() object.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/testFlextable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"group variable Mean SD grad Organization 2.75 1.7078251 grad Source 2.50 1.2909944 grad Publish 1.75 0.9574271 grad Write 2.75 0.9574271 grad Research 2.50 1.2909944 undergrad Organization 2.80 1.3038405 undergrad Source 2.80 1.3038405 undergrad Publish 2.20 0.8366600 undergrad Write 3.20 0.8366600 undergrad Research 2.80 1.3038405","code":"# Example data: data <- dplyr::tibble(   Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   group = factor(c(       \"grad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\",       \"undergrad\", \"undergrad\", \"grad\", \"undergrad\"                     ), levels = c(\"grad\", \"undergrad\")     ) ) # Summarise the data into mean and sd for each numeric column, grouped by \"group\": data <- data %>% dplyr::group_by(group) %>%   dplyr::summarise(dplyr::across(                                    .cols = dplyr::where(is.numeric),                                    .fns =  list(Mean = mean, SD = sd),                                    .names = \"{col}_{fn}\"                                                   )) %>%              dplyr::ungroup() %>%              tidyr::pivot_longer(cols = -group,                                  names_pattern = \"([^_]+)_(.*)\",                                  names_to = c(\"variable\", \"stat\"),                                  values_to = \"value\",                                  values_drop_na = TRUE) %>%              tidyr::pivot_wider(names_from = stat, values_from = value)  # Make a nice table with the function: data %>% testFlextable() .cl-bda235be{}.cl-bd9e9508{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-bd9e9512{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-bd9fb172{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-bd9fb173{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-bd9fba14{width:0.918in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba15{width:1.073in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba1e{width:0.702in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba1f{width:0.942in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba20{width:0.918in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba28{width:1.073in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba29{width:0.702in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba2a{width:0.942in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba32{width:0.918in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba3c{width:1.073in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba3d{width:0.702in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba3e{width:0.942in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba46{width:0.918in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba47{width:1.073in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba48{width:0.702in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bd9fba50{width:0.942in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}groupvariableMeanSDgradOrganization2.751.7078251gradSource2.501.2909944gradPublish1.750.9574271gradWrite2.750.9574271gradResearch2.501.2909944undergradOrganization2.801.3038405undergradSource2.801.3038405undergradPublish2.200.8366600undergradWrite3.200.8366600undergradResearch2.801.3038405"},{"path":"https://zwcrowley.github.io/bre/reference/test_flextable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Flextable in Blackstone Research and Evaluation Branding — test_flextable","title":"Create Flextable in Blackstone Research and Evaluation Branding — test_flextable","text":"Create Flextable Blackstone Research Evaluation Branding","code":""},{"path":"https://zwcrowley.github.io/bre/reference/test_flextable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Flextable in Blackstone Research and Evaluation Branding — test_flextable","text":"","code":"test_flextable(data)"},{"path":"https://zwcrowley.github.io/bre/reference/test_flextable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Flextable in Blackstone Research and Evaluation Branding — test_flextable","text":"data Required, tibble/data frame summary/descriptice test statistics.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/test_flextable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Flextable in Blackstone Research and Evaluation Branding — test_flextable","text":"nicely formatted table flextable() object.","code":""},{"path":"https://zwcrowley.github.io/bre/reference/test_flextable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Flextable in Blackstone Research and Evaluation Branding — test_flextable","text":"group variable Mean SD grad Organization 2.75 1.7078251 grad Source 2.50 1.2909944 grad Publish 1.75 0.9574271 grad Write 2.75 0.9574271 grad Research 2.50 1.2909944 undergrad Organization 2.80 1.3038405 undergrad Source 2.80 1.3038405 undergrad Publish 2.20 0.8366600 undergrad Write 3.20 0.8366600 undergrad Research 2.80 1.3038405","code":"# Example data: data <- dplyr::tibble(   Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   group = factor(c(       \"grad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\",       \"undergrad\", \"undergrad\", \"grad\", \"undergrad\"                     ), levels = c(\"grad\", \"undergrad\")     ) ) # Summarise the data into mean and sd for each numeric column, grouped by \"group\": data <- data %>% dplyr::group_by(group) %>%   dplyr::summarise(dplyr::across(                                    .cols = dplyr::where(is.numeric),                                    .fns =  list(Mean = mean, SD = sd),                                    .names = \"{col}_{fn}\"                                                   )) %>%              dplyr::ungroup() %>%              tidyr::pivot_longer(cols = -group,                                  names_pattern = \"([^_]+)_(.*)\",                                  names_to = c(\"variable\", \"stat\"),                                  values_to = \"value\",                                  values_drop_na = TRUE) %>%              tidyr::pivot_wider(names_from = stat, values_from = value)  # Make a nice table with the function: data %>% test_flextable() .cl-03c37b08{}.cl-03b722ae{font-family:'Gill Sans MT';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-03b722c2{font-family:'Gill Sans MT';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-03bb7f0c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-03bb7f16{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-03bb9410{width:0.861in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb941a{width:1.013in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9424{width:0.65in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9438{width:0.871in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9439{width:0.861in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9442{width:1.013in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9443{width:0.65in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9444{width:0.871in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9445{width:0.861in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb944c{width:1.013in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb944d{width:0.65in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9456{width:0.871in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9460{width:0.861in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9461{width:1.013in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb9462{width:0.65in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-03bb946a{width:0.871in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}groupvariableMeanSDgradOrganization2.751.7078251gradSource2.501.2909944gradPublish1.750.9574271gradWrite2.750.9574271gradResearch2.501.2909944undergradOrganization2.801.3038405undergradSource2.801.3038405undergradPublish2.200.8366600undergradWrite3.200.8366600undergradResearch2.801.3038405"},{"path":"https://zwcrowley.github.io/bre/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported package rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way.   enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions).   simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data pronoun object represents current slice data. variable name string, use .data pronoun subset variable [[.   Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround.   Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually :   Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data %>%     group_by(...) %>%     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data %>%     group_by(!!!dots) %>%     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars %>% summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data %>%     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data %>%     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"}]
