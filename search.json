[{"path":"https://zwcrowley.github.io/blackstone/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 blackstone authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"read-in-example-data","dir":"Articles","previous_headings":"","what":"Read in Example Data","title":"Data Analysis and Statistical Inference","text":"First, read data merged cleaned vignette Importing Cleaning Data:","code":"# Read in clean SM data: sm_data <- readr::read_csv(blackstone::blackstoneExample(\"sm_data_clean.csv\"), show_col_types = FALSE)  ## Set up character vectors of likert scale levels: ## Knowledge scale levels_knowledge <- c(\"Not knowledgeable at all\", \"A little knowledgeable\", \"Somewhat knowledgeable\", \"Very knowledgeable\", \"Extremely knowledgeable\") ## Research Items scale: levels_confidence <- c(\"Not at all confident\", \"Slightly confident\", \"Somewhat confident\", \"Very confident\", \"Extremely confident\") ## Ability Items scale:  levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") ## Ethics Items scale: levels_agree5 <- c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor disagree\", \"Agree\", \"Strongly agree\")  # Demographic levels: gender_levels <- c(\"Female\",\"Male\",\"Non-binary\", \"Do not wish to specify\") ethnicity_levels <- c(\"White (Non-Hispanic/Latino)\", \"Asian\", \"Black\",  \"Hispanic or Latino\", \"American Indian or Alaskan Native\",                       \"Native Hawaiian or other Pacific Islander\", \"Do not wish to specify\") first_gen_levels <- c(\"Yes\", \"No\", \"I'm not sure\")  # Use mutate() for convert each item in each scale to a factor with vectors above, across() will perform a function for items selected using contains() or can be selected  # by variables names individually using a character vector: _knowledge or use c(\"pre_knowledg\",\"post_knowledge\") # Also create new numeric variables for all the likert scale items and use the suffix '_num' to denote numeric: sm_data <- sm_data %>% dplyr::mutate(dplyr::across(tidyselect::contains(\"_knowledge\"), ~ factor(., levels = levels_knowledge)), # match each name pattern to select to each factor level                                      dplyr::across(tidyselect::contains(\"_knowledge\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all knowledge items                                      dplyr::across(tidyselect::contains(\"research_\"), ~ factor(., levels = levels_confidence)),                                       dplyr::across(tidyselect::contains(\"research_\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all research items                                      dplyr::across(tidyselect::contains(\"ability_\"), ~ factor(., levels = levels_min_ext)),                                      dplyr::across(tidyselect::contains(\"ability_\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all ability items                                      # select ethics items but not the open_ended responses:                                      dplyr::across(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_oe\"), ~ factor(., levels = levels_agree5)),                                      dplyr::across(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_oe\"), as.numeric, .names = \"{.col}_num\"), # new numeric items for all ethics items                                      # individually convert all demographics to factor variables:                                      gender = factor(gender, levels = gender_levels),                                      ethnicity = factor(ethnicity, levels = ethnicity_levels),                                      first_gen = factor(first_gen, levels = first_gen_levels),                                      ) sm_data #> # A tibble: 100 × 97 #>   respondent_id collector_id start_date end_date   ip_address      email_address #>           <dbl>        <dbl> <date>     <date>     <chr>           <chr>         #> 1  114628000001    431822954 2024-06-05 2024-06-06 227.224.138.113 coraima59@me… #> 2  114628000002    431822954 2024-06-21 2024-06-22 110.241.132.50  mstamm@hermi… #> 3  114628000003    431822954 2024-06-14 2024-06-15 165.58.112.64   precious.fei… #> 4  114628000004    431822954 2024-06-15 2024-06-16 49.34.121.147   ines52@gmail… #> 5  114628000005    431822954 2024-06-15 2024-06-16 115.233.66.80   franz44@hotm… #> # ℹ 95 more rows #> # ℹ 91 more variables: first_name <chr>, last_name <chr>, unique_id <dbl>, #> #   pre_knowledge <fct>, pre_research_1 <fct>, pre_research_2 <fct>, #> #   pre_research_3 <fct>, pre_research_4 <fct>, pre_research_5 <fct>, #> #   pre_research_6 <fct>, pre_research_7 <fct>, pre_research_8 <fct>, #> #   pre_ability_1 <fct>, pre_ability_2 <fct>, pre_ability_3 <fct>, #> #   pre_ability_4 <fct>, pre_ability_5 <fct>, pre_ability_6 <fct>, …"},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"likert-scale-table","dir":"Articles","previous_headings":"","what":"Likert Scale Table","title":"Data Analysis and Statistical Inference","text":"common task creating frequency tables counts percentages likert scale items, blackstone likertTable() : Question allconfident Slightlyconfident Somewhatconfident Veryconfident Extremelyconfident n pre_research_1 10 (10%) 8 (8%) 41 (41%) 27 (27%) 14 (14%) 100 pre_research_2 56 (56%) 19 (19%) 8 (8%) 9 (9%) 8 (8%) 100 pre_research_3 32 (32%) 23 (23%) 15 (15%) 20 (20%) 10 (10%) 100 pre_research_4 9 (9%) 24 (24%) 32 (32%) 24 (24%) 11 (11%) 100 pre_research_5 40 (40%) 18 (18%) 21 (21%) 13 (13%) 8 (8%) 100 pre_research_6 17 (17%) 25 (25%) 25 (25%) 16 (16%) 17 (17%) 100 pre_research_7 59 (59%) 13 (13%) 11 (11%) 10 (10%) 7 (7%) 100 pre_research_8 21 (21%) 19 (19%) 23 (23%) 19 (19%) 18 (18%) 100 post_research_1 2 (2%) 26 (26%) 23 (23%) 25 (25%) 24 (24%) 100 post_research_2 12 (12%) 14 (14%) 12 (12%) 14 (14%) 48 (48%) 100 post_research_3 8 (8%) 22 (22%) 21 (21%) 23 (23%) 26 (26%) 100 post_research_4 2 (2%) 24 (24%) 25 (25%) 19 (19%) 30 (30%) 100 post_research_5 14 (14%) 19 (19%) 19 (19%) 19 (19%) 29 (29%) 100 post_research_6 5 (5%) 3 (3%) 24 (24%) 28 (28%) 40 (40%) 100 post_research_7 11 (11%) 10 (10%) 14 (14%) 17 (17%) 48 (48%) 100 post_research_8 4 (4%) 7 (7%) 23 (23%) 23 (23%) 43 (43%) 100","code":"# Research items pre and post frequency table, with counts and percentages: use levels_confidence character vector # use likertTable to return frequency table, passing the scale_labels: (can also label the individual questions using the arg question_label) sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>%                  blackstone::likertTable(., scale_labels = levels_confidence)"},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"using-functional-programming-to-speed-up-analysis","dir":"Articles","previous_headings":"Likert Scale Table","what":"Using Functional Programming to Speed Up Analysis","title":"Data Analysis and Statistical Inference","text":"one approach use functional programming purrr package create many frequency tables : Question Notknowledgeableat littleknowledgeable Somewhatknowledgeable Veryknowledgeable Extremelyknowledgeable n pre_knowledge 65 (65%) 11 (11%) 9 (9%) 9 (9%) 6 (6%) 100 post_knowledge 7 (7%) 14 (14%) 9 (9%) 24 (24%) 46 (46%) 100 Question allconfident Slightlyconfident Somewhatconfident Veryconfident Extremelyconfident n pre_research_1 10 (10%) 8 (8%) 41 (41%) 27 (27%) 14 (14%) 100 pre_research_2 56 (56%) 19 (19%) 8 (8%) 9 (9%) 8 (8%) 100 pre_research_3 32 (32%) 23 (23%) 15 (15%) 20 (20%) 10 (10%) 100 pre_research_4 9 (9%) 24 (24%) 32 (32%) 24 (24%) 11 (11%) 100 pre_research_5 40 (40%) 18 (18%) 21 (21%) 13 (13%) 8 (8%) 100 pre_research_6 17 (17%) 25 (25%) 25 (25%) 16 (16%) 17 (17%) 100 pre_research_7 59 (59%) 13 (13%) 11 (11%) 10 (10%) 7 (7%) 100 pre_research_8 21 (21%) 19 (19%) 23 (23%) 19 (19%) 18 (18%) 100 post_research_1 2 (2%) 26 (26%) 23 (23%) 25 (25%) 24 (24%) 100 post_research_2 12 (12%) 14 (14%) 12 (12%) 14 (14%) 48 (48%) 100 post_research_3 8 (8%) 22 (22%) 21 (21%) 23 (23%) 26 (26%) 100 post_research_4 2 (2%) 24 (24%) 25 (25%) 19 (19%) 30 (30%) 100 post_research_5 14 (14%) 19 (19%) 19 (19%) 19 (19%) 29 (29%) 100 post_research_6 5 (5%) 3 (3%) 24 (24%) 28 (28%) 40 (40%) 100 post_research_7 11 (11%) 10 (10%) 14 (14%) 17 (17%) 48 (48%) 100 post_research_8 4 (4%) 7 (7%) 23 (23%) 23 (23%) 43 (43%) 100 Question Minimal Slight Moderate Good Extensive n pre_ability_1 9 (9%) 28 (28%) 37 (37%) 15 (15%) 11 (11%) 100 pre_ability_2 24 (24%) 14 (14%) 27 (27%) 22 (22%) 13 (13%) 100 pre_ability_3 26 (26%) 30 (30%) 19 (19%) 19 (19%) 6 (6%) 100 pre_ability_4 43 (43%) 27 (27%) 13 (13%) 4 (4%) 13 (13%) 100 pre_ability_5 32 (32%) 18 (18%) 26 (26%) 17 (17%) 7 (7%) 100 pre_ability_6 26 (26%) 12 (12%) 18 (18%) 26 (26%) 18 (18%) 100 post_ability_1 3 (3%) 20 (20%) 23 (23%) 20 (20%) 34 (34%) 100 post_ability_2 2 (2%) 11 (11%) 11 (11%) 29 (29%) 47 (47%) 100 post_ability_3 11 (11%) 19 (19%) 22 (22%) 15 (15%) 33 (33%) 100 post_ability_4 9 (9%) 6 (6%) 9 (9%) 23 (23%) 53 (53%) 100 post_ability_5 12 (12%) 19 (19%) 16 (16%) 27 (27%) 26 (26%) 100 post_ability_6 6 (6%) 11 (11%) 29 (29%) 29 (29%) 25 (25%) 100 Question Stronglydisagree Disagree Neitheragree nordisagree Agree Stronglyagree n pre_ethics_1 10 (10%) 16 (16%) 45 (45%) 20 (20%) 9 (9%) 100 pre_ethics_2 20 (20%) 15 (15%) 27 (27%) 23 (23%) 15 (15%) 100 pre_ethics_3 28 (28%) 16 (16%) 30 (30%) 12 (12%) 14 (14%) 100 pre_ethics_4 50 (50%) 17 (17%) 12 (12%) 6 (6%) 15 (15%) 100 pre_ethics_5 14 (14%) 16 (16%) 31 (31%) 30 (30%) 9 (9%) 100 post_ethics_1 4 (4%) 18 (18%) 24 (24%) 30 (30%) 24 (24%) 100 post_ethics_2 7 (7%) 10 (10%) 13 (13%) 31 (31%) 39 (39%) 100 post_ethics_3 7 (7%) 26 (26%) 14 (14%) 28 (28%) 25 (25%) 100 post_ethics_4 10 (10%) 7 (7%) 6 (6%) 19 (19%) 58 (58%) 100 post_ethics_5 3 (3%) 14 (14%) 25 (25%) 31 (31%) 27 (27%) 100","code":"# Another way to make a list of many freq_tables to print out with other data analysis later on,  # using pmap() to do multiple likertTable() at once: # Set up tibbles of each set of scales that contain all pre and post data: # research: research_df <- sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) # knowledge: knowledge_df <- sm_data %>% dplyr::select(tidyselect::contains(\"_knowledge\") & !tidyselect::contains(\"_num\") & where(is.factor)) # ability: ability_df <- sm_data %>% dplyr::select(tidyselect::contains(\"ability_\") & !tidyselect::contains(\"_num\") & where(is.factor)) # ethics: ethics_df <- sm_data %>% dplyr::select(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_oe\") & !tidyselect::contains(\"_num\") & where(is.factor))   # set up tibble with the columns as the args to pass to likertTable(), each row of the column `df` is the tibble of items and  # each row of `scale_labels` is the vector of likert scale labels: freq_params <- tibble::tribble(   ~df,           ~scale_labels, # name of columns (these need to match the names of the arguments in the function that you want to use later in `purrr::pmap()`)    knowledge_df,  levels_knowledge,     research_df,   levels_confidence,      ability_df,    levels_min_ext,    ethics_df,     levels_agree5 ) # Create a named list of frequency tables by using `purrr::pmap()` which takes in a tibble where each column is an argument that is passed to the function, and  # each row is contains the inputs for a single output, so here each row will be one frequency table that is return to a list and named for easy retrieval later on: freq_tables <- freq_params %>% purrr::pmap(blackstone::likertTable) %>%      purrr::set_names(., c(\"Knowledge Items\", \"Research Items\", \"Ability Items\", \"Ethics Items\"))  # Can select the list by position or by name: # freq_tables[[1]] # by list position freq_tables[[\"Knowledge Items\"]] # by name freq_tables[[\"Research Items\"]] freq_tables[[\"Ability Items\"]] freq_tables[[\"Ethics Items\"]]"},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"grouped-demograpic-table","dir":"Articles","previous_headings":"","what":"Grouped Demograpic Table","title":"Data Analysis and Statistical Inference","text":"blackstone contains function create frequency tables demographics (combined demographics table) can also grouped variable, like role cohort well: groupedTable(). Question Response n = 1001 Gender    Female 47 (47%)  Male 50 (50%)  Non-binary 2 (2%)  wish specify 1 (1%) Race/Ethnicity    White (Non-Hispanic/Latino) 36 (36%)  Asian 23 (23%)  Black 7 (7%)  Hispanic Latino 18 (18%)  American Indian Alaskan Native 5 (5%)  Native Hawaiian Pacific Islander 7 (7%)  wish specify 4 (4%) First-GenerationCollege Student    Yes 59 (59%)  39 (39%)  sure 2 (2%) 1n (%)","code":"# Set up labels for variables # Labels for questions column of table, pass to question_labels argument: demos_labels <- c('Gender' = \"gender\",                   'Race/Ethnicity' = \"ethnicity\",                   'First-Generation College Student' = \"first_gen\")  sm_data %>% dplyr::select(gender, ethnicity, first_gen) %>% # select the demographic vars                  blackstone::groupedTable(question_labels = demos_labels) # pass the new labels for the 'Question' column."},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"statistical-inference-t-test-or-wilcoxon-test","dir":"Articles","previous_headings":"","what":"Statistical Inference: T-test or Wilcoxon test","title":"Data Analysis and Statistical Inference","text":"section, run simple statistical tests using pipe-friendly functions contained rstatix package.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"running-normality-tests-then-t-test-or-wilcoxon-test","dir":"Articles","previous_headings":"Single Pre-Post Items","what":"Running Normality Tests, then T-test or Wilcoxon test:","title":"Data Analysis and Statistical Inference","text":"Since large number surveys sample size smaller 30, important check normality assumption running statistical tests. data distributed normally can use T-tests (parametric tests) simple hypothesis testing pre-post items, see changes surveys statistically significant. data distributed normally (non-normal) use non-parametric statistical tests, like Wilcoxon test. Determining data distributed normally includes visual statistical tests.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"normality-visualizations-density-and-qq-quantile-quantile-plots","dir":"Articles","previous_headings":"Single Pre-Post Items > Running Normality Tests, then T-test or Wilcoxon test:","what":"Normality Visualizations: Density and QQ (Quantile-Quantile) Plots","title":"Data Analysis and Statistical Inference","text":"ggpubr package contains functions create density QQ plots visually inspect data distributed normally.   data normally distributed, density plot shaped like bell curve QQ plot sample observations (points), lined along 45-degree reference line within shaded confidence interval. data probably distributed normally, lets run statistical test confirm. Next, run Shapiro-Wilk’s test. null hypothesis test sample distribution normal. means test significant (p-value < 0.05), distribution non-normal. rstatix::shapiro_test() returns tibble three column, column named p p-value Shapiro’s test. Data normally distributed knowledge items (since p-value < 0.05)- use Wilcoxon test.","code":"# First create a difference score for the pre and post items: sm_data <- sm_data %>% dplyr::mutate(knowledge_diff = post_knowledge_num - pre_knowledge_num)  # get difference of pre and post scores # Density plot: ggpubr::ggdensity(sm_data, \"knowledge_diff\", fill = \"lightgray\") # QQ plot: ggpubr::ggqqplot(sm_data, \"knowledge_diff\") sm_data %>% rstatix::shapiro_test(knowledge_diff) #> # A tibble: 1 × 3 #>   variable       statistic           p #>   <chr>              <dbl>       <dbl> #> 1 knowledge_diff     0.885 0.000000301"},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"wilcoxon-test","dir":"Articles","previous_headings":"Single Pre-Post Items","what":"Wilcoxon test","title":"Data Analysis and Statistical Inference","text":"couple ways run Wilcoxon test- either pipe-friendly version rstatix::wilcox_test() base R wilcox.test must pass variable numeric vector. Wilcoxon test significant, significant difference pre post scores knowledge scores.","code":"# Either use a pipe-friendly version of `wilcox_test()` from `rstatix`, need to covert to long form and have `timing` as a variable: knowledge_wilcoxon <- sm_data %>% dplyr::select(tidyselect::contains(\"_knowledge\") & tidyselect::contains(\"_num\")) %>%  # select the data                                   tidyr::pivot_longer(tidyselect::contains(c(\"pre_\", \"post_\")), names_to = \"question\", values_to = \"response\") %>% # pivot to long-form                                   tidyr::separate(.data$question, into = c(\"timing\", \"question\"), sep = \"_\", extra = \"merge\") %>% # Separate out the prefix to get timing                                   rstatix::wilcox_test(response ~ timing, paired = TRUE, detailed = TRUE) # Run the Wilcoxon test using column \"response\" (numeric values) on \"timing\" (pre or post) knowledge_wilcoxon #> # A tibble: 1 × 12 #>   estimate .y.   group1 group2    n1    n2 statistic        p conf.low conf.high #> *    <dbl> <chr> <chr>  <chr>  <int> <int>     <dbl>    <dbl>    <dbl>     <dbl> #> 1     2.50 resp… post   pre      100   100     3800. 1.23e-13     2.00      3.00 #> # ℹ 2 more variables: method <chr>, alternative <chr> # Or use the simple base R wilcox.test with each pre and post item: wilcox.test(sm_data[[\"post_knowledge_num\"]], sm_data[[\"pre_knowledge_num\"]], paired = TRUE) #>  #>  Wilcoxon signed rank test with continuity correction #>  #> data:  sm_data[[\"post_knowledge_num\"]] and sm_data[[\"pre_knowledge_num\"]] #> V = 3800, p-value = 0.0000000000001 #> alternative hypothesis: true location shift is not equal to 0"},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"composite-scales-multiple-items","dir":"Articles","previous_headings":"","what":"Composite Scales (multiple items)","title":"Data Analysis and Statistical Inference","text":"surveys conduct use composite scales items measure underlying concept. average together create reliable measure can used statistical inference.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"creating-composite-scores","dir":"Articles","previous_headings":"Composite Scales (multiple items)","what":"Creating Composite Scores","title":"Data Analysis and Statistical Inference","text":"Create composite scores pre post data taking mean set items, get difference scores pre post mean:","code":"sm_data <- sm_data %>% dplyr::rowwise() %>% # Get the mean for each individual by row     dplyr::mutate(pre_research_mean = mean(dplyr::c_across(tidyselect::contains(\"pre_research_\") & tidyselect::contains(\"_num\"))), # pre mean for each individual                   post_research_mean = mean(dplyr::c_across(tidyselect::contains(\"post_research_\") & tidyselect::contains(\"_num\"))), # post mean for each individual                   diff_research = post_research_mean - pre_research_mean # get difference scores of pre and post means.     ) %>% dplyr::ungroup()"},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"normality-testing-of-composite-scales","dir":"Articles","previous_headings":"Composite Scales (multiple items) > Creating Composite Scores","what":"Normality Testing of Composite Scales","title":"Data Analysis and Statistical Inference","text":"Run visual inspection difference scores pre post mean research items:   Visually, data appears normally distributed, Next, run Shapiro-Wilk’s test confirm. Data normally distributed research composite items (since p-values > 0.05)- use T-test.","code":"# Density plot: ggpubr::ggdensity(sm_data, \"diff_research\", fill = \"lightgray\") # QQ plot: ggpubr::ggqqplot(sm_data, \"diff_research\") sm_data %>% rstatix::shapiro_test(diff_research) # not significant, data likely normal #> # A tibble: 1 × 3 #>   variable      statistic     p #>   <chr>             <dbl> <dbl> #> 1 diff_research     0.991 0.720"},{"path":"https://zwcrowley.github.io/blackstone/articles/analysis.html","id":"t-test-of-composite-scales","dir":"Articles","previous_headings":"Composite Scales (multiple items) > Creating Composite Scores","what":"T-test of Composite Scales","title":"Data Analysis and Statistical Inference","text":"T-test significant, mean difference pre post scores 1.02. vignette Data Visualization explain create visuals using blackstone example data analyzed vignette.","code":"# Either use a pipe-friendly version of wilcox_test from `rstatix`, need to covert to long form and have `timing` as a variable: research_t_test <- sm_data %>% dplyr::select(pre_research_mean, post_research_mean) %>% # select the pre and post means for research items                                tidyr::pivot_longer(tidyselect::contains(c(\"pre_\", \"post_\")), names_to = \"question\", values_to = \"response\") %>% # pivot to long-form                                tidyr::separate(.data[[\"question\"]], into = c(\"timing\", \"question\"), sep = \"_\", extra = \"merge\") %>% # Separate out the prefix to get timing                                rstatix::t_test(response ~ timing, paired = TRUE, detailed = TRUE)# Run the T-test using column \"response\" (numeric values) on \"timing\" (pre or post) research_t_test #> # A tibble: 1 × 13 #>   estimate .y.      group1 group2    n1    n2 statistic        p    df conf.low #> *    <dbl> <chr>    <chr>  <chr>  <int> <int>     <dbl>    <dbl> <dbl>    <dbl> #> 1     1.02 response post   pre      100   100      15.6 2.43e-28    99    0.890 #> # ℹ 3 more variables: conf.high <dbl>, method <chr>, alternative <chr> # Or use the simple base R wilcox.test with each pre and post item: t.test(sm_data[[\"post_research_mean\"]], sm_data[[\"pre_research_mean\"]],  paired = TRUE) #>  #>  Paired t-test #>  #> data:  sm_data[[\"post_research_mean\"]] and sm_data[[\"pre_research_mean\"]] #> t = 16, df = 99, p-value <0.0000000000000002 #> alternative hypothesis: true mean difference is not equal to 0 #> 95 percent confidence interval: #>  0.8899 1.1501 #> sample estimates: #> mean difference  #>            1.02"},{"path":"https://zwcrowley.github.io/blackstone/articles/blackstone.html","id":"overview-of-data-workflow","dir":"Articles","previous_headings":"","what":"Overview of Data Workflow","title":"Introduction to blackstone","text":"Import clean data survey provider: vignette(\"import_clean\"). Simple data analysis statistical inference: vignette(\"analysis\"). Data visualization output report writing: vignette(\"data_visualization\").","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/blackstone.html","id":"importing-data-from-surveymonkey","dir":"Articles","previous_headings":"","what":"Importing data from SurveyMonkey","title":"Introduction to blackstone","text":"current survey provider SurveyMonkey, blackstone contains several functions makes process reading SurveyMonkey data R manageable process creates codebook data along way. SurveyMonkey exports data two header rows, work R, tibbles dataframes can one row names. import data SurveyMonkey using example data provided blackstone, fake dataset pre (baseline) survey. three steps process: Create codebook. codebook, first column header_1 first header SurveyMonkey data, second column header_2 second header, third column combined_header combination two headers, position column number position combined_header, variable_name cleaned version combined_header column edit change column names later shorter meaningful names. variable_name column renames variables SurveyMonkey data. Edit codebook create meaningful variable names. Read data rename variables codebook. SurveyMonkey example data now imported names taken codebook column variable_name: vignette Importing Cleaning Data goes deeper detail example data use blackstone import clean data.","code":"# File path for pre example data: pre_data_fp <- blackstone::blackstoneExample(\"sm_data_pre.csv\") # 1. Create the codebook: codebook_pre <- blackstone::createCodebook(pre_data_fp) codebook_pre #> # A tibble: 32 × 5 #>   header_1      header_2 combined_header position variable_name #>   <chr>         <chr>    <chr>              <int> <chr>         #> 1 Respondent ID NA       Respondent ID          1 respondent_id #> 2 Collector ID  NA       Collector ID           2 collector_id  #> 3 Start Date    NA       Start Date             3 start_date    #> 4 End Date      NA       End Date               4 end_date      #> 5 IP Address    NA       IP Address             5 ip_address    #> # ℹ 27 more rows # Step 2. Edit the codebook:  # Set up sequential naming convections for matrix-style questions with shared likert scale response options: # 8 items that are matrix-style likert scales- turned into a scale called `research`- here is how to easily name them all at once: # Rows 11 to 18 belong to the \"research\" matrix question (you will have to look at the codebook and match the header_1 and header_2 to variable_name to change) research_items <- codebook_pre[[\"variable_name\"]][11:18] research_names <- paste0(\"research_\", seq_along(research_items)) %>% purrr::set_names(., research_items) # Create a new named vector of names for these columns # 6 items that are matrix-style likert scales- turned into a scale called `ability`- Rows 19 to 24 named `variable_name`: ability_items <- codebook_pre[[\"variable_name\"]][19:24] ability_names <- paste0(\"ability_\", seq_along(ability_items)) %>% purrr::set_names(., ability_items) # Create a new named vector of names for these columns # 6 items that are matrix-style likert scales- turned into a scale called `ethics`- Rows 19 to 24 named `variable_name`: ethics_items <- codebook_pre[[\"variable_name\"]][25:29] ethics_names <- paste0(\"ethics_\", seq_along(ethics_items)) %>% purrr::set_names(., ethics_items) # Create a new named vector of names for these columns # Edit the `variable_names` column: Use dplyr::mutate() and dplyr::case_match() to change the column `variable_name`: codebook_pre <- codebook_pre %>% dplyr::mutate(     variable_name = dplyr::case_match(         variable_name, # column to match         'custom_data_1' ~ \"unique_id\", # changes 'custom_data_1' to \"unique_id\"         'to_what_extent_are_you_knowledgeable_in_conducting_research_in_your_field_of_study' ~ \"knowledge\",         'with_which_gender_do_you_most_closely_identify' ~ \"gender\",         'which_race_ethnicity_best_describes_you_please_choose_only_one' ~ \"ethnicity\",         'are_you_a_first_generation_college_student' ~ \"first_gen\",         names(research_names) ~ research_names[variable_name], # takes the above named vector and when the name matches, applies new value in that position as replacement.         names(ability_names) ~ ability_names[variable_name],   # Same for `ability_names`         names(ethics_names) ~ ethics_names[variable_name],   # Same for `ability_names`         .default = variable_name # returns default value from original `variable_name` if not changed.         )     ) codebook_pre #> # A tibble: 32 × 5 #>   header_1      header_2 combined_header position variable_name #>   <chr>         <chr>    <chr>              <int> <chr>         #> 1 Respondent ID NA       Respondent ID          1 respondent_id #> 2 Collector ID  NA       Collector ID           2 collector_id  #> 3 Start Date    NA       Start Date             3 start_date    #> 4 End Date      NA       End Date               4 end_date      #> 5 IP Address    NA       IP Address             5 ip_address    #> # ℹ 27 more rows # Write out the edited codebook to save for future use- # Be sure to double check questions match new names before writing out: # readr::write_csv(codebook_pre, file = \"{filepath-to-codebok}\") # 3. Read in the data and rename the vars using readRenameData(), passing the file path and the edited codebook: pre_data <- blackstone::readRenameData(pre_data_fp, codebook = codebook_pre) pre_data #> # A tibble: 100 × 32 #>   respondent_id collector_id start_date end_date   ip_address      email_address #>           <dbl>        <dbl> <date>     <date>     <chr>           <chr>         #> 1  114628000001    431822954 2024-06-05 2024-06-06 227.224.138.113 coraima59@me… #> 2  114628000002    431822954 2024-06-21 2024-06-22 110.241.132.50  mstamm@hermi… #> 3  114628000003    431822954 2024-06-14 2024-06-15 165.58.112.64   precious.fei… #> 4  114628000004    431822954 2024-06-15 2024-06-16 49.34.121.147   ines52@gmail… #> 5  114628000005    431822954 2024-06-15 2024-06-16 115.233.66.80   franz44@hotm… #> # ℹ 95 more rows #> # ℹ 26 more variables: first_name <chr>, last_name <chr>, unique_id <dbl>, #> #   knowledge <chr>, research_1 <chr>, research_2 <chr>, research_3 <chr>, #> #   research_4 <chr>, research_5 <chr>, research_6 <chr>, research_7 <chr>, #> #   research_8 <chr>, ability_1 <chr>, ability_2 <chr>, ability_3 <chr>, #> #   ability_4 <chr>, ability_5 <chr>, ability_6 <chr>, ethics_1 <chr>, #> #   ethics_2 <chr>, ethics_3 <chr>, ethics_4 <chr>, ethics_5 <chr>, … names(pre_data) #>  [1] \"respondent_id\" \"collector_id\"  \"start_date\"    \"end_date\"      #>  [5] \"ip_address\"    \"email_address\" \"first_name\"    \"last_name\"     #>  [9] \"unique_id\"     \"knowledge\"     \"research_1\"    \"research_2\"    #> [13] \"research_3\"    \"research_4\"    \"research_5\"    \"research_6\"    #> [17] \"research_7\"    \"research_8\"    \"ability_1\"     \"ability_2\"     #> [21] \"ability_3\"     \"ability_4\"     \"ability_5\"     \"ability_6\"     #> [25] \"ethics_1\"      \"ethics_2\"      \"ethics_3\"      \"ethics_4\"      #> [29] \"ethics_5\"      \"gender\"        \"ethnicity\"     \"first_gen\""},{"path":"https://zwcrowley.github.io/blackstone/articles/blackstone.html","id":"data-analysis-and-statistical-inference","dir":"Articles","previous_headings":"","what":"Data Analysis and Statistical Inference","title":"Introduction to blackstone","text":"First, read data merged cleaned vignette Importing Cleaning Data:","code":"# Read in clean SM data: sm_data <- readr::read_csv(blackstone::blackstoneExample(\"sm_data_clean.csv\"), show_col_types = FALSE)  ## Set up character vectors of likert scale levels: ## Knowledge scale levels_knowledge <- c(\"Not knowledgeable at all\", \"A little knowledgeable\", \"Somewhat knowledgeable\", \"Very knowledgeable\", \"Extremely knowledgeable\") ## Research Items scale: levels_confidence <- c(\"Not at all confident\", \"Slightly confident\", \"Somewhat confident\", \"Very confident\", \"Extremely confident\") ## Ability Items scale:  levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") ## Ethics Items scale: levels_agree5 <- c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor disagree\", \"Agree\", \"Strongly agree\")  # Demographic levels: gender_levels <- c(\"Female\",\"Male\",\"Non-binary\", \"Do not wish to specify\") ethnicity_levels <- c(\"White (Non-Hispanic/Latino)\", \"Asian\", \"Black\",  \"Hispanic or Latino\", \"American Indian or Alaskan Native\",                       \"Native Hawaiian or other Pacific Islander\", \"Do not wish to specify\") first_gen_levels <- c(\"Yes\", \"No\", \"I'm not sure\")  # Use mutate() for convert each item in each scale to a factor with vectors above, across() will perform a function for items selected using contains() or can be selected  # by variables names individually using a character vector: _knowledge or use c(\"pre_knowledg\",\"post_knowledge\") # Also create new numeric variables for all the likert scale items and use the suffix '_num' to denote numeric: sm_data <- sm_data %>% dplyr::mutate(dplyr::across(tidyselect::contains(\"_knowledge\"), ~ factor(., levels = levels_knowledge)), # match each name pattern to select to each factor level                                      dplyr::across(tidyselect::contains(\"_knowledge\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all knowledge items                                      dplyr::across(tidyselect::contains(\"research_\"), ~ factor(., levels = levels_confidence)),                                       dplyr::across(tidyselect::contains(\"research_\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all research items                                      dplyr::across(tidyselect::contains(\"ability_\"), ~ factor(., levels = levels_min_ext)),                                      dplyr::across(tidyselect::contains(\"ability_\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all ability items                                      # select ethics items but not the open_ended responses:                                      dplyr::across(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_oe\"), ~ factor(., levels = levels_agree5)),                                      dplyr::across(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_oe\"), as.numeric, .names = \"{.col}_num\"), # new numeric items for all ethics items                                      # individually convert all demographics to factor variables:                                      gender = factor(gender, levels = gender_levels),                                      ethnicity = factor(ethnicity, levels = ethnicity_levels),                                      first_gen = factor(first_gen, levels = first_gen_levels),                                      ) sm_data #> # A tibble: 100 × 97 #>   respondent_id collector_id start_date end_date   ip_address      email_address #>           <dbl>        <dbl> <date>     <date>     <chr>           <chr>         #> 1  114628000001    431822954 2024-06-05 2024-06-06 227.224.138.113 coraima59@me… #> 2  114628000002    431822954 2024-06-21 2024-06-22 110.241.132.50  mstamm@hermi… #> 3  114628000003    431822954 2024-06-14 2024-06-15 165.58.112.64   precious.fei… #> 4  114628000004    431822954 2024-06-15 2024-06-16 49.34.121.147   ines52@gmail… #> 5  114628000005    431822954 2024-06-15 2024-06-16 115.233.66.80   franz44@hotm… #> # ℹ 95 more rows #> # ℹ 91 more variables: first_name <chr>, last_name <chr>, unique_id <dbl>, #> #   pre_knowledge <fct>, pre_research_1 <fct>, pre_research_2 <fct>, #> #   pre_research_3 <fct>, pre_research_4 <fct>, pre_research_5 <fct>, #> #   pre_research_6 <fct>, pre_research_7 <fct>, pre_research_8 <fct>, #> #   pre_ability_1 <fct>, pre_ability_2 <fct>, pre_ability_3 <fct>, #> #   pre_ability_4 <fct>, pre_ability_5 <fct>, pre_ability_6 <fct>, …"},{"path":"https://zwcrowley.github.io/blackstone/articles/blackstone.html","id":"likert-scale-table","dir":"Articles","previous_headings":"Data Analysis and Statistical Inference","what":"Likert Scale Table","title":"Introduction to blackstone","text":"common task creating frequency tables counts percentages likert scale items, blackstone likertTable() : Question allconfident Slightlyconfident Somewhatconfident Veryconfident Extremelyconfident n pre_research_1 10 (10%) 8 (8%) 41 (41%) 27 (27%) 14 (14%) 100 pre_research_2 56 (56%) 19 (19%) 8 (8%) 9 (9%) 8 (8%) 100 pre_research_3 32 (32%) 23 (23%) 15 (15%) 20 (20%) 10 (10%) 100 pre_research_4 9 (9%) 24 (24%) 32 (32%) 24 (24%) 11 (11%) 100 pre_research_5 40 (40%) 18 (18%) 21 (21%) 13 (13%) 8 (8%) 100 pre_research_6 17 (17%) 25 (25%) 25 (25%) 16 (16%) 17 (17%) 100 pre_research_7 59 (59%) 13 (13%) 11 (11%) 10 (10%) 7 (7%) 100 pre_research_8 21 (21%) 19 (19%) 23 (23%) 19 (19%) 18 (18%) 100 post_research_1 2 (2%) 26 (26%) 23 (23%) 25 (25%) 24 (24%) 100 post_research_2 12 (12%) 14 (14%) 12 (12%) 14 (14%) 48 (48%) 100 post_research_3 8 (8%) 22 (22%) 21 (21%) 23 (23%) 26 (26%) 100 post_research_4 2 (2%) 24 (24%) 25 (25%) 19 (19%) 30 (30%) 100 post_research_5 14 (14%) 19 (19%) 19 (19%) 19 (19%) 29 (29%) 100 post_research_6 5 (5%) 3 (3%) 24 (24%) 28 (28%) 40 (40%) 100 post_research_7 11 (11%) 10 (10%) 14 (14%) 17 (17%) 48 (48%) 100 post_research_8 4 (4%) 7 (7%) 23 (23%) 23 (23%) 43 (43%) 100","code":"# Research items pre and post frequency table, with counts and percentages: use levels_confidence character vector # use likertTable to return frequency table, passing the scale_labels: (can also label the individual questions using the arg question_label) sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>%                  blackstone::likertTable(., scale_labels = levels_confidence)"},{"path":"https://zwcrowley.github.io/blackstone/articles/blackstone.html","id":"grouped-demograpic-table","dir":"Articles","previous_headings":"Data Analysis and Statistical Inference","what":"Grouped Demograpic table","title":"Introduction to blackstone","text":"blackstone contains function create frequency tables demographics can grouped variable like role cohort well: [groupedTable()]. Question Response n = 1001 Gender    Female 47 (47%)  Male 50 (50%)  Non-binary 2 (2%)  wish specify 1 (1%) Race/Ethnicity    White (Non-Hispanic/Latino) 36 (36%)  Asian 23 (23%)  Black 7 (7%)  Hispanic Latino 18 (18%)  American Indian Alaskan Native 5 (5%)  Native Hawaiian Pacific Islander 7 (7%)  wish specify 4 (4%) First-GenerationCollege Student    Yes 59 (59%)  39 (39%)  sure 2 (2%) 1n (%)","code":"# Set up labels for variables # Labels for questions column of table, pass to question_labels argument: demos_labels <- c('Gender' = \"gender\",                   'Race/Ethnicity' = \"ethnicity\",                   'First-Generation College Student' = \"first_gen\")  sm_data %>% dplyr::select(gender, ethnicity, first_gen) %>% # select the demographic vars                  blackstone::groupedTable(question_labels = demos_labels) # pass the new labels for the 'Question' column."},{"path":[]},{"path":"https://zwcrowley.github.io/blackstone/articles/blackstone.html","id":"running-normality-test-on-single-pre-post-items","dir":"Articles","previous_headings":"Data Analysis and Statistical Inference > Statistical Inference: T-test or Wilcoxon test","what":"Running Normality Test on Single Pre-Post Items","title":"Introduction to blackstone","text":"Data normally distributed knowledge items (since p-value < 0.05)- use Wilcoxon test. Wilcoxon test significant, significant difference pre post scores knowledge scores. vignette Data analysis Statistical Inference goes deeper detail use blackstone perform analysis statistical tests example data.","code":"# Use a pipe-friendly version of `shapiro_test()` from `rstatix`, need to covert create a differnce score of post_knowledge_num - pre_knowledge_num named `knowledge_diff`: sm_data %>% dplyr::select(tidyselect::contains(\"_knowledge\") & tidyselect::contains(\"_num\")) %>%  # select knowledge pre and post numeric items     dplyr::mutate(knowledge_diff = post_knowledge_num - pre_knowledge_num) %>% # get difference of pre and post scores     rstatix::shapiro_test(knowledge_diff) #> # A tibble: 1 × 3 #>   variable       statistic           p #>   <chr>              <dbl>       <dbl> #> 1 knowledge_diff     0.885 0.000000301 # Use a pipe-friendly version of `wilcox_test()` from `rstatix`, need to covert to long form and have `timing` as a variable, # the column named `p` is the p-value: sm_data %>% dplyr::select(tidyselect::contains(\"_knowledge\") & tidyselect::contains(\"_num\")) %>%              tidyr::pivot_longer(tidyselect::contains(c(\"pre_\", \"post_\")), names_to = \"question\", values_to = \"response\") %>%             tidyr::separate(.data$question, into = c(\"timing\", \"question\"), sep = \"_\", extra = \"merge\") %>%              rstatix::wilcox_test(response ~ timing, paired = TRUE, detailed = TRUE) #> # A tibble: 1 × 12 #>   estimate .y.   group1 group2    n1    n2 statistic        p conf.low conf.high #> *    <dbl> <chr> <chr>  <chr>  <int> <int>     <dbl>    <dbl>    <dbl>     <dbl> #> 1     2.50 resp… post   pre      100   100     3800. 1.23e-13     2.00      3.00 #> # ℹ 2 more variables: method <chr>, alternative <chr>"},{"path":"https://zwcrowley.github.io/blackstone/articles/blackstone.html","id":"data-visualization","dir":"Articles","previous_headings":"","what":"Data Visualization","title":"Introduction to blackstone","text":"blackstone functions create 3 types charts data visualization: stacked bar charts, diverging stacked bar charts, arrow charts. functions stacked bar charts diverging stacked bar charts can use two different color palettes: blue sequential palette blue-red diverging color palette. blue sequential palette used likert scales one clear direction like: confident, Slightly confident, Somewhat confident, confident, Extremely confident blue-red diverging color palette used items likert scale folded runs negative positive valence like : Strongly disagree, Disagree, Neither agree disagree, Agree, Strongly agree introduction show create stacked bar chart, see vignette Data Visualization full explanation data visualization functions blackstone.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/blackstone.html","id":"stacked-bar-charts","dir":"Articles","previous_headings":"Data Visualization","what":"Stacked Bar Charts","title":"Introduction to blackstone","text":"common visual used reporting Blackstone Research Evaluation stacked bar chart, blackstone function makes creating charts fast easy: stackedBarChart(). stackedBarChart() takes tibble factor/character variables turn stacked bar chart. requirement character vector scale labels likert scale makes items tibble (one use set factors data cleaning section).","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/blackstone.html","id":"pre-post-stacked-bar-chart-with-overall-n-and-percentages","dir":"Articles","previous_headings":"Data Visualization > Stacked Bar Charts","what":"Pre-post Stacked Bar Chart with Overall n and Percentages:","title":"Introduction to blackstone","text":"default, stackedBarChart() uses blue sequential palette color bars sorts items ones highest post items highest counts/percentages.  vignette Data Visualization goes deeper detail use blackstone create data visualizations example data.","code":"# Research Items scale: levels_confidence <- c(\"Not at all confident\", \"Slightly confident\", \"Somewhat confident\", \"Very confident\", \"Extremely confident\")  # select variables and pass them to `stackedBarChart()` along with scale_labels. sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>% # select the factor variables for the research items     blackstone::stackedBarChart(., scale_labels = levels_confidence, pre_post = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"read-in-example-data","dir":"Articles","previous_headings":"","what":"Read in Example Data","title":"Data Visualization","text":"First, read data merged cleaned vignette Importing Cleaning Data:","code":"# Read in clean SM data: sm_data <- readr::read_csv(blackstone::blackstoneExample(\"sm_data_clean.csv\"), show_col_types = FALSE)  ## Set up character vectors of likert scale levels: ## Knowledge scale levels_knowledge <- c(\"Not knowledgeable at all\", \"A little knowledgeable\", \"Somewhat knowledgeable\", \"Very knowledgeable\", \"Extremely knowledgeable\") ## Research Items scale: levels_confidence <- c(\"Not at all confident\", \"Slightly confident\", \"Somewhat confident\", \"Very confident\", \"Extremely confident\") ## Ability Items scale:  levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") ## Ethics Items scale: levels_agree5 <- c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor disagree\", \"Agree\", \"Strongly agree\")  # Demographic levels: gender_levels <- c(\"Female\",\"Male\",\"Non-binary\", \"Do not wish to specify\") ethnicity_levels <- c(\"White (Non-Hispanic/Latino)\", \"Asian\", \"Black\",  \"Hispanic or Latino\", \"American Indian or Alaskan Native\",                       \"Native Hawaiian or other Pacific Islander\", \"Do not wish to specify\") first_gen_levels <- c(\"Yes\", \"No\", \"I'm not sure\")  # Use mutate() for convert each item in each scale to a factor with vectors above, across() will perform a function for items selected using contains() or can be selected  # by variables names individually using a character vector: _knowledge or use c(\"pre_knowledg\",\"post_knowledge\") # Also create new numeric variables for all the likert scale items and use the suffix '_num' to denote numeric: sm_data <- sm_data %>% dplyr::mutate(dplyr::across(tidyselect::contains(\"_knowledge\"), ~ factor(., levels = levels_knowledge)), # match each name pattern to select to each factor level                                      dplyr::across(tidyselect::contains(\"_knowledge\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all knowledge items                                      dplyr::across(tidyselect::contains(\"research_\"), ~ factor(., levels = levels_confidence)),                                       dplyr::across(tidyselect::contains(\"research_\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all research items                                      dplyr::across(tidyselect::contains(\"ability_\"), ~ factor(., levels = levels_min_ext)),                                      dplyr::across(tidyselect::contains(\"ability_\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all ability items                                      # select ethics items but not the open_ended responses:                                      dplyr::across(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_oe\"), ~ factor(., levels = levels_agree5)),                                      dplyr::across(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_oe\"), as.numeric, .names = \"{.col}_num\"), # new numeric items for all ethics items                                      # individually convert all demographics to factor variables:                                      gender = factor(gender, levels = gender_levels),                                      ethnicity = factor(ethnicity, levels = ethnicity_levels),                                      first_gen = factor(first_gen, levels = first_gen_levels),                                      ) sm_data #> # A tibble: 100 × 97 #>   respondent_id collector_id start_date end_date   ip_address      email_address #>           <dbl>        <dbl> <date>     <date>     <chr>           <chr>         #> 1  114628000001    431822954 2024-06-05 2024-06-06 227.224.138.113 coraima59@me… #> 2  114628000002    431822954 2024-06-21 2024-06-22 110.241.132.50  mstamm@hermi… #> 3  114628000003    431822954 2024-06-14 2024-06-15 165.58.112.64   precious.fei… #> 4  114628000004    431822954 2024-06-15 2024-06-16 49.34.121.147   ines52@gmail… #> 5  114628000005    431822954 2024-06-15 2024-06-16 115.233.66.80   franz44@hotm… #> # ℹ 95 more rows #> # ℹ 91 more variables: first_name <chr>, last_name <chr>, unique_id <dbl>, #> #   pre_knowledge <fct>, pre_research_1 <fct>, pre_research_2 <fct>, #> #   pre_research_3 <fct>, pre_research_4 <fct>, pre_research_5 <fct>, #> #   pre_research_6 <fct>, pre_research_7 <fct>, pre_research_8 <fct>, #> #   pre_ability_1 <fct>, pre_ability_2 <fct>, pre_ability_3 <fct>, #> #   pre_ability_4 <fct>, pre_ability_5 <fct>, pre_ability_6 <fct>, …"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"color-palettes","dir":"Articles","previous_headings":"","what":"Color Palettes","title":"Data Visualization","text":"blackstone functions create 3 types charts data visualization: stacked bar charts, diverging stacked bar charts, arrow charts. functions stacked bar charts diverging stacked bar charts can use two different color palettes: blue sequential palette blue-red diverging color palette. blue sequential palette used likert scales one clear direction like: confident, Slightly confident, Somewhat confident, confident, Extremely confident blue-red diverging color palette used items likert scale folded runs negative positive valence like : Strongly disagree, Disagree, Neither agree disagree, Agree, Strongly agree next three sections show examples use functions.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"stacked-bar-charts","dir":"Articles","previous_headings":"","what":"Stacked Bar Charts","title":"Data Visualization","text":"common visual used reporting Blackstone Research Evaluation stacked bar chart, blackstone function makes creating charts fast easy: stackedBarChart(). stackedBarChart() takes tibble factor/character variables turn stacked bar chart. requirement character vector scale labels likert scale makes items tibble (one use set factors data cleaning section).","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"pre-post-stacked-bar-chart-with-overall-n-and-percentages","dir":"Articles","previous_headings":"Stacked Bar Charts","what":"Pre-post Stacked Bar Chart with Overall n and Percentages","title":"Data Visualization","text":"default, stackedBarChart() uses blue sequential palette color bars sorts items ones highest post items highest counts/percentages.","code":"# Research Items scale: levels_confidence <- c(\"Not at all confident\", \"Slightly confident\", \"Somewhat confident\", \"Very confident\", \"Extremely confident\")  # select variables and pass them to `stackedBarChart()` along with scale_labels. sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>% # select the factor variables for the research items     blackstone::stackedBarChart(., scale_labels = levels_confidence, pre_post = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"pre-post-stacked-bar-chart-with-individual-item-n-and-counts","dir":"Articles","previous_headings":"Stacked Bar Charts","what":"Pre-post Stacked Bar Chart with Individual Item n and Counts","title":"Data Visualization","text":"","code":"# Select variables and pass them to `stackedBarChart()` along with scale_labels, change the arguements `percent_label` and `overall_n` both to FALSE: sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>% # select the factor variables for the research items     blackstone::stackedBarChart(., scale_labels = levels_confidence, pre_post = TRUE, percent_label = FALSE, overall_n = FALSE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"pre-post-stacked-bar-chart-with-blue-red-diverging-color-palette","dir":"Articles","previous_headings":"Stacked Bar Charts","what":"Pre-post Stacked Bar Chart with Blue-Red Diverging Color Palette","title":"Data Visualization","text":"","code":"## Ethics Items scale: levels_agree5 <- c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor disagree\", \"Agree\", \"Strongly agree\")  # select variables and pass them to `stackedBarChart()` along with scale_labels,  # change `fill_colors` to \"div\" to use the blue-red diverging color palette: sm_data %>% dplyr::select(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_num\") & # select the factor variables for the ethics items                               !tidyselect::contains(\"_oe\") & where(is.factor)) %>%              blackstone::stackedBarChart(., scale_labels = levels_agree5, pre_post = TRUE, fill_colors = \"div\")"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"pre-post-stacked-bar-chart-with-new-question-labels-and-order","dir":"Articles","previous_headings":"Stacked Bar Charts","what":"Pre-post Stacked Bar Chart with New Question Labels and Order:","title":"Data Visualization","text":"","code":"# Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"), where the  # names are the new question labels and the old names are the values without pre or post prefixes: # Here I will use paste0 to create 8 research items like they appear without prefixes: research_question_labels <- paste0(paste0(\"research_\", 1:8)) # Set new labels as names of `research_question_labels` names(research_question_labels) <- c(\"Research relevant background literature\", \"Identify a scientific problem\",                                       \"Develop testable and realistic research questions\", \"Develop a falsifiable hypothesis\",                                       \"Conduct quantitative data analysis\", \"Design an experiment/Create a research design\",                                       \"Interpret findings and making recommendations\", \"Scientific or technical writing\")  # select variables and pass them to `stackedBarChart()` along with scale_labels, also pass research_question_labels to `question_labels` and set `question_order` to TRUE. sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>% # select the factor variables for the research items     blackstone::stackedBarChart(., scale_labels = levels_confidence, pre_post = TRUE, question_labels = research_question_labels, question_order = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"single-time-point-stacked-bar-chart-with-new-question-labels-and-order","dir":"Articles","previous_headings":"Stacked Bar Charts","what":"Single time point Stacked Bar Chart with New Question Labels and Order","title":"Data Visualization","text":"","code":"# Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"), where the  # names are the new question labels and the old names are the values without pre or post prefixes: # Here I will use paste0 to create 8 research items like they appear without prefixes: research_question_labels <- paste0(paste0(\"post_research_\", 1:8)) # Set new labels as names of `research_question_labels` names(research_question_labels) <- c(\"Research relevant background literature\", \"Identify a scientific problem\",                                       \"Develop testable and realistic research questions\", \"Develop a falsifiable hypothesis\",                                       \"Conduct quantitative data analysis\", \"Design an experiment/Create a research design\",                                       \"Interpret findings and making recommendations\", \"Scientific or technical writing\")  # select variables and pass them to `stackedBarChart()` along with scale_labels, set pre_post to FALSE (default), #  also pass research_question_labels to `question_labels` and set `question_order` to TRUE. sm_data %>% dplyr::select(tidyselect::contains(\"post_research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>% # select the factor variables for the research items     blackstone::stackedBarChart(., scale_labels = levels_confidence, question_labels = research_question_labels, question_order = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"diverging-stacked-bar-charts","dir":"Articles","previous_headings":"","what":"Diverging Stacked Bar Charts","title":"Data Visualization","text":"Another common visual used reporting Blackstone Research Evaluation diverging stacked bar chart, refer now diverging bar chart. blackstone function make type chart, called: divBarChart(). diverging bar charts created using divBarChart(), diverge just mid-point likert scale items supplied function. See examples . divBarChart() arguments stackedBarChart(), using requirements.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"pre-post-diverging-bar-chart-with-overall-n-and-percentages","dir":"Articles","previous_headings":"Diverging Stacked Bar Charts","what":"Pre-post Diverging Bar Chart with Overall n and Percentages","title":"Data Visualization","text":"default, divBarChart() uses blue sequential palette color bars sorts items ones highest post items highest counts/percentages.","code":"# Research Items scale: levels_confidence <- c(\"Not at all confident\", \"Slightly confident\", \"Somewhat confident\", \"Very confident\", \"Extremely confident\")  # select variables and pass them to `divBarChart()` along with scale_labels. sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>% # select the factor variables for the research items     blackstone::divBarChart(., scale_labels = levels_confidence, pre_post = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"pre-post-diverging-bar-chart-with-individual-item-n-and-counts","dir":"Articles","previous_headings":"Diverging Stacked Bar Charts","what":"Pre-post Diverging Bar Chart with Individual Item n and Counts","title":"Data Visualization","text":"","code":"# Select variables and pass them to `divBarChart()` along with scale_labels, change the arguements `percent_label` and `overall_n` both to FALSE: sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>% # select the factor variables for the research items     blackstone::divBarChart(., scale_labels = levels_confidence, pre_post = TRUE, percent_label = FALSE, overall_n = FALSE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"pre-post-diverging-bar-chart-with-blue-red-diverging-color-palette","dir":"Articles","previous_headings":"Diverging Stacked Bar Charts","what":"Pre-post Diverging Bar Chart with Blue-Red Diverging Color Palette","title":"Data Visualization","text":"","code":"## Ethics Items scale: levels_agree5 <- c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor disagree\", \"Agree\", \"Strongly agree\")  # select variables and pass them to `divBarChart()` along with scale_labels,  # change `fill_colors` to \"div\" to use the blue-red diverging color palette: sm_data %>% dplyr::select(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_num\") & # select the factor variables for the ethics items                               !tidyselect::contains(\"_oe\") & where(is.factor)) %>%              blackstone::divBarChart(., scale_labels = levels_agree5, pre_post = TRUE, fill_colors = \"div\")"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"pre-post-stacked-bar-chart-with-new-question-labels-and-order-1","dir":"Articles","previous_headings":"Diverging Stacked Bar Charts","what":"Pre-post Stacked Bar Chart with New Question Labels and Order","title":"Data Visualization","text":"","code":"# Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"), where the  # names are the new question labels and the old names are the values without pre or post prefixes: # Here I will use paste0 to create 8 research items like they appear without prefixes: research_question_labels <- paste0(paste0(\"research_\", 1:8)) # Set new labels as names of `research_question_labels` names(research_question_labels) <- c(\"Research relevant background literature\", \"Identify a scientific problem\",                                       \"Develop testable and realistic research questions\", \"Develop a falsifiable hypothesis\",                                       \"Conduct quantitative data analysis\", \"Design an experiment/Create a research design\",                                       \"Interpret findings and making recommendations\", \"Scientific or technical writing\")  # select variables and pass them to `divBarChart()` along with scale_labels, also pass research_question_labels to `question_labels` and set `question_order` to TRUE. sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>% # select the factor variables for the research items     blackstone::divBarChart(., scale_labels = levels_confidence, pre_post = TRUE, question_labels = research_question_labels, question_order = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"single-time-point-stacked-bar-chart-with-new-question-labels-and-order-1","dir":"Articles","previous_headings":"Diverging Stacked Bar Charts","what":"Single time point Stacked Bar Chart with New Question Labels and Order","title":"Data Visualization","text":"","code":"# Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"), where the  # names are the new question labels and the old names are the values without pre or post prefixes: # Here I will use paste0 to create 8 research items like they appear without prefixes: research_question_labels <- paste0(paste0(\"post_research_\", 1:8)) # Set new labels as names of `research_question_labels` names(research_question_labels) <- c(\"Research relevant background literature\", \"Identify a scientific problem\",                                       \"Develop testable and realistic research questions\", \"Develop a falsifiable hypothesis\",                                       \"Conduct quantitative data analysis\", \"Design an experiment/Create a research design\",                                       \"Interpret findings and making recommendations\", \"Scientific or technical writing\")  # select variables and pass them to `divBarChart()` along with scale_labels, set pre_post to FALSE (default), #  also pass research_question_labels to `question_labels` and set `question_order` to TRUE. sm_data %>% dplyr::select(tidyselect::contains(\"post_research_\") & !tidyselect::contains(\"_num\") & where(is.factor)) %>% # select the factor variables for the research items     blackstone::divBarChart(., scale_labels = levels_confidence, question_labels = research_question_labels, question_order = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"arrow-charts","dir":"Articles","previous_headings":"","what":"Arrow Charts","title":"Data Visualization","text":"Arrow charts show difference means two time points, blackstone two functions create arrow charts: arrowChart() arrowChartGroup(). use tibble numeric pre-post data main input, also require character vector scale labels numeric scale makes items tibble. rest arguments two arrow chart functions sames stacked bar chart functions.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"arrow-chart-with-defaults","dir":"Articles","previous_headings":"Arrow Charts > arrowChart()","what":"Arrow Chart with defaults","title":"Data Visualization","text":"default, arrowChart() sorts items/arrows ones highest post average arrows dark blue color hex code #283251.","code":"# Research Items scale: levels_confidence <- c(\"Not at all confident\", \"Slightly confident\", \"Somewhat confident\", \"Very confident\", \"Extremely confident\")  # select variables and pass them to `divBarChart()` along with scale_labels. sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & tidyselect::contains(\"_num\") & where(is.numeric)) %>% # select the numeric variables for the research items     blackstone::arrowChart(., scale_labels = levels_confidence)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"arrow-chart-with-individual-item-n","dir":"Articles","previous_headings":"Arrow Charts > arrowChart()","what":"Arrow Chart with Individual Item n","title":"Data Visualization","text":"","code":"# Select variables and pass them to `divBarChart()` along with scale_labels, change the arguement `overall_n` both to FALSE: sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & tidyselect::contains(\"_num\") & where(is.numeric)) %>% # select the numeric variables for the research items     blackstone::arrowChart(., scale_labels = levels_confidence, overall_n = FALSE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"arrow-chart-with-new-question-labels-and-order","dir":"Articles","previous_headings":"Arrow Charts > arrowChart()","what":"Arrow Chart with New Question Labels and Order","title":"Data Visualization","text":"","code":"# Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"), where the  # names are the new question labels and the old names are the values without pre or post prefixes: # Here I will use paste0 to create 8 research items like they appear without prefixes: research_question_labels <- paste0(paste0(\"research_\", 1:8)) # Set new labels as names of `research_question_labels` names(research_question_labels) <- c(\"Research relevant background literature\", \"Identify a scientific problem\",                                       \"Develop testable and realistic research questions\", \"Develop a falsifiable hypothesis\",                                       \"Conduct quantitative data analysis\", \"Design an experiment/Create a research design\",                                       \"Interpret findings and making recommendations\", \"Scientific or technical writing\") # Select variables and pass them to `arrowChart()` along with scale_labels, and also pass research_question_labels to `question_labels` and set `question_order` to TRUE: sm_data %>% dplyr::select(tidyselect::contains(\"research_\") & tidyselect::contains(\"_num\") & where(is.numeric)) %>% # select the numeric variables for the research items     blackstone::arrowChart(., scale_labels = levels_confidence, question_labels = research_question_labels, question_order = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"arrowchartgroup","dir":"Articles","previous_headings":"Arrow Charts","what":"arrowChartGroup()","title":"Data Visualization","text":"arrowChartGroup() allows user create arrow chart pre-post averages grouped third variable, also showing overall pre-post average arrow.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"arrow-chart-by-group-with-defaults","dir":"Articles","previous_headings":"Arrow Charts > arrowChartGroup()","what":"Arrow Chart by Group with defaults","title":"Data Visualization","text":"#E69F00, #56B4E9, #009E73, #CC79A7, #D55E00, #0072B2, #440154FF, #999999, #117733, #283251, #999933 arrowChartGroup() returns pre-post averages group passed group_levels well “Overall” whole sample always color black, also order group_levels also determining order arrows legend.","code":"# Research Items scale: levels_confidence <- c(\"Not at all confident\", \"Slightly confident\", \"Somewhat confident\", \"Very confident\", \"Extremely confident\")  # select variables and pass them to `arrowChartGroup()` along with scale_labels, the grouping variable in `group` and the levels for each group in `group_levels`: sm_data %>% dplyr::select(gender, tidyselect::contains(\"research_\") & tidyselect::contains(\"_num\") & where(is.numeric)) %>% # select the numeric variables for the research items     blackstone::arrowChartGroup(., group = \"gender\", group_levels = gender_levels, scale_labels = levels_confidence)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"arrow-chart-with-individual-item-n-1","dir":"Articles","previous_headings":"Arrow Charts > arrowChartGroup()","what":"Arrow Chart with Individual Item n","title":"Data Visualization","text":"","code":"# Select variables and pass them to `divBarChart()` along with scale_labels, change the argument `overall_n` both to FALSE: sm_data %>% dplyr::select(gender, tidyselect::contains(\"research_\") & tidyselect::contains(\"_num\") & where(is.numeric)) %>% # select the numeric variables for the research items     blackstone::arrowChartGroup(., group = \"gender\", group_levels = gender_levels,scale_labels = levels_confidence, overall_n = FALSE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/data_visualization.html","id":"arrow-chart-with-new-question-labels-and-order-1","dir":"Articles","previous_headings":"Arrow Charts > arrowChartGroup()","what":"Arrow Chart with New Question Labels and Order","title":"Data Visualization","text":"","code":"# Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"), where the  # names are the new question labels and the old names are the values without pre or post prefixes: # Here I will use paste0 to create 8 research items like they appear without prefixes: research_question_labels <- paste0(paste0(\"research_\", 1:8)) # Set new labels as names of `research_question_labels` names(research_question_labels) <- c(\"Research relevant background literature\", \"Identify a scientific problem\",                                       \"Develop testable and realistic research questions\", \"Develop a falsifiable hypothesis\",                                       \"Conduct quantitative data analysis\", \"Design an experiment/Create a research design\",                                       \"Interpret findings and making recommendations\", \"Scientific or technical writing\") # Select variables and pass them to `arrowChart()` along with scale_labels, and also pass research_question_labels to `question_labels` and set `question_order` to TRUE: sm_data %>% dplyr::select(gender, tidyselect::contains(\"research_\") & tidyselect::contains(\"_num\") & where(is.numeric)) %>% # select the numeric variables for the research items     blackstone::arrowChartGroup(., group = \"gender\", group_levels = gender_levels,scale_labels = levels_confidence, question_labels = research_question_labels, question_order = TRUE)"},{"path":[]},{"path":"https://zwcrowley.github.io/blackstone/articles/import_clean.html","id":"importing-data-from-surveymonkey","dir":"Articles","previous_headings":"Data Cleaning and Manipulation","what":"Importing data from SurveyMonkey","title":"Importing and Cleaning Data","text":"current survey provider SurveyMonkey, blackstone contains several functions makes process reading SurveyMonkey data R manageable process creates codebook data along way. SurveyMonkey exports data two header rows, work R tibbles dataframes can one row names. import data SurveyMonkey using example data provided blackstone, fake dataset pre (baseline) survey. three steps process: Create codebook. Edit save codebook create meaningful variable names. Read data rename variables codebook.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/blackstone/articles/import_clean.html","id":"creating-the-codebook","dir":"Articles","previous_headings":"Data Cleaning and Manipulation > Pre Survey Data","what":"1. Creating the codebook","title":"Importing and Cleaning Data","text":"codebook, first column header_1 first header SurveyMonkey data, second column header_2 second header, third column combined_header combination two headers, position column number position combined_header, variable_name cleaned version combined_header column edit change column names later shorter meaningful names. variable_name column renames variables SurveyMonkey data.","code":"# File path for pre example data: pre_data_fp <- blackstone::blackstoneExample(\"sm_data_pre.csv\") # 1. Create the codebook: codebook_pre <- blackstone::createCodebook(pre_data_fp) codebook_pre #> # A tibble: 32 × 5 #>   header_1      header_2 combined_header position variable_name #>   <chr>         <chr>    <chr>              <int> <chr>         #> 1 Respondent ID NA       Respondent ID          1 respondent_id #> 2 Collector ID  NA       Collector ID           2 collector_id  #> 3 Start Date    NA       Start Date             3 start_date    #> 4 End Date      NA       End Date               4 end_date      #> 5 IP Address    NA       IP Address             5 ip_address    #> # ℹ 27 more rows"},{"path":"https://zwcrowley.github.io/blackstone/articles/import_clean.html","id":"editing-and-saving-the-codebook","dir":"Articles","previous_headings":"Data Cleaning and Manipulation > Pre Survey Data","what":"2. Editing and Saving the Codebook","title":"Importing and Cleaning Data","text":"","code":"# Step 2. Edit the codebook:  # Set up sequential naming convections for matrix-style questions with shared likert scale response options: # 8 items that are matrix-style likert scales- turned into a scale called `research`- here is how to easily name them all at once: # Rows 11 to 18 belong to the \"research\" matrix question (you will have to look at the codebook and match the header_1 and header_2 to variable_name to change) research_items <- codebook_pre[[\"variable_name\"]][11:18] research_names <- paste0(\"research_\", seq_along(research_items)) %>% purrr::set_names(., research_items) # Create a new named vector of names for these columns # 6 items that are matrix-style likert scales- turned into a scale called `ability`- Rows 19 to 24 named `variable_name`: ability_items <- codebook_pre[[\"variable_name\"]][19:24] ability_names <- paste0(\"ability_\", seq_along(ability_items)) %>% purrr::set_names(., ability_items) # Create a new named vector of names for these columns # 6 items that are matrix-style likert scales- turned into a scale called `ethics`- Rows 19 to 24 named `variable_name`: ethics_items <- codebook_pre[[\"variable_name\"]][25:29] ethics_names <- paste0(\"ethics_\", seq_along(ethics_items)) %>% purrr::set_names(., ethics_items) # Create a new named vector of names for these columns # Edit the `variable_names` column: Use dplyr::mutate() and dplyr::case_match() to change the column `variable_name`: codebook_pre <- codebook_pre %>% dplyr::mutate(     variable_name = dplyr::case_match(         variable_name, # column to match         'custom_data_1' ~ \"unique_id\", # changes 'custom_data_1' to \"unique_id\"         'to_what_extent_are_you_knowledgeable_in_conducting_research_in_your_field_of_study' ~ \"knowledge\",         'with_which_gender_do_you_most_closely_identify' ~ \"gender\",         'which_race_ethnicity_best_describes_you_please_choose_only_one' ~ \"ethnicity\",         'are_you_a_first_generation_college_student' ~ \"first_gen\",         names(research_names) ~ research_names[variable_name], # takes the above named vector and when the name matches, applies new value in that position as replacement.         names(ability_names) ~ ability_names[variable_name],   # Same for `ability_names`         names(ethics_names) ~ ethics_names[variable_name],   # Same for `ability_names`         .default = variable_name # returns default value from original `variable_name` if not changed.         )     ) codebook_pre #> # A tibble: 32 × 5 #>   header_1      header_2 combined_header position variable_name #>   <chr>         <chr>    <chr>              <int> <chr>         #> 1 Respondent ID NA       Respondent ID          1 respondent_id #> 2 Collector ID  NA       Collector ID           2 collector_id  #> 3 Start Date    NA       Start Date             3 start_date    #> 4 End Date      NA       End Date               4 end_date      #> 5 IP Address    NA       IP Address             5 ip_address    #> # ℹ 27 more rows  # Write out the edited codebook to save for future use- # Be sure to double check questions match new names before writing out: # readr::write_csv(codebook_pre, file = \"{filepath-to-codebok}\")"},{"path":"https://zwcrowley.github.io/blackstone/articles/import_clean.html","id":"import-the-data-and-rename-the-variables-with-the-codebook","dir":"Articles","previous_headings":"Data Cleaning and Manipulation > Pre Survey Data","what":"3. Import the Data and Rename the Variables with the Codebook","title":"Importing and Cleaning Data","text":"SurveyMonkey example data now imported names taken codebook column variable_name:","code":"# 3. Read in the data and rename the vars using readRenameData(), passing the file path and the edited codebook: pre_data <- blackstone::readRenameData(pre_data_fp, codebook = codebook_pre) pre_data #> # A tibble: 100 × 32 #>   respondent_id collector_id start_date end_date   ip_address      email_address #>           <dbl>        <dbl> <date>     <date>     <chr>           <chr>         #> 1  114628000001    431822954 2024-06-05 2024-06-06 227.224.138.113 coraima59@me… #> 2  114628000002    431822954 2024-06-21 2024-06-22 110.241.132.50  mstamm@hermi… #> 3  114628000003    431822954 2024-06-14 2024-06-15 165.58.112.64   precious.fei… #> 4  114628000004    431822954 2024-06-15 2024-06-16 49.34.121.147   ines52@gmail… #> 5  114628000005    431822954 2024-06-15 2024-06-16 115.233.66.80   franz44@hotm… #> # ℹ 95 more rows #> # ℹ 26 more variables: first_name <chr>, last_name <chr>, unique_id <dbl>, #> #   knowledge <chr>, research_1 <chr>, research_2 <chr>, research_3 <chr>, #> #   research_4 <chr>, research_5 <chr>, research_6 <chr>, research_7 <chr>, #> #   research_8 <chr>, ability_1 <chr>, ability_2 <chr>, ability_3 <chr>, #> #   ability_4 <chr>, ability_5 <chr>, ability_6 <chr>, ethics_1 <chr>, #> #   ethics_2 <chr>, ethics_3 <chr>, ethics_4 <chr>, ethics_5 <chr>, … names(pre_data) #>  [1] \"respondent_id\" \"collector_id\"  \"start_date\"    \"end_date\"      #>  [5] \"ip_address\"    \"email_address\" \"first_name\"    \"last_name\"     #>  [9] \"unique_id\"     \"knowledge\"     \"research_1\"    \"research_2\"    #> [13] \"research_3\"    \"research_4\"    \"research_5\"    \"research_6\"    #> [17] \"research_7\"    \"research_8\"    \"ability_1\"     \"ability_2\"     #> [21] \"ability_3\"     \"ability_4\"     \"ability_5\"     \"ability_6\"     #> [25] \"ethics_1\"      \"ethics_2\"      \"ethics_3\"      \"ethics_4\"      #> [29] \"ethics_5\"      \"gender\"        \"ethnicity\"     \"first_gen\""},{"path":"https://zwcrowley.github.io/blackstone/articles/import_clean.html","id":"post-survey-data","dir":"Articles","previous_headings":"Data Cleaning and Manipulation","what":"Post Survey Data","title":"Importing and Cleaning Data","text":"process post data, variables can use codebook. example additional post variables new codebook need created rename variables reading data readRenameData(). Finally, important add pre_ post_ prefixes unique variables merging datasets, (.e. survey items differ pre-post- SM items demos identical):","code":"# File path for pre example data: post_data_fp <- blackstone::blackstoneExample(\"sm_data_post.csv\") # 1. Create the codebook using the filepath: codebook_post <- blackstone::createCodebook(post_data_fp) codebook_post #> # A tibble: 37 × 5 #>   header_1      header_2 combined_header position variable_name #>   <chr>         <chr>    <chr>              <int> <chr>         #> 1 Respondent ID NA       Respondent ID          1 respondent_id #> 2 Collector ID  NA       Collector ID           2 collector_id  #> 3 Start Date    NA       Start Date             3 start_date    #> 4 End Date      NA       End Date               4 end_date      #> 5 IP Address    NA       IP Address             5 ip_address    #> # ℹ 32 more rows  # Step 2. Edit the codebook:  # Set up sequential naming convections for matrix-style questions with shared likert scale response options: # 8 items that are matrix-style likert scales- turned into a scale called `research`- here is how to easily name them all at once: # Rows 11 to 18 belong to the \"research\" matrix question (you will have to look at the codebook and match the header_1 and header_2 to variable_name to change) research_items <- codebook_post[[\"variable_name\"]][11:18] research_names <- paste0(\"research_\", seq_along(research_items)) %>% purrr::set_names(., research_items) # Create a new named vector of names for these columns # 6 items that are matrix-style likert scales- turned into a scale called `ability`- Rows 19 to 24 named `variable_name`: ability_items <- codebook_post[[\"variable_name\"]][19:24] ability_names <- paste0(\"ability_\", seq_along(ability_items)) %>% purrr::set_names(., ability_items) # Create a new named vector of names for these columns # 6 items that are matrix-style likert scales- turned into a scale called `ethics`- Rows 19 to 24 named `variable_name`: ethics_items <- codebook_post[[\"variable_name\"]][25:29] ethics_names <- paste0(\"ethics_\", seq_along(ethics_items)) %>% purrr::set_names(., ethics_items) # Create a new named vector of names for these columns # 5 items that are Open-ended follow up when corresponeding ethics items were answered \"Strongly disagree\"or \"Disagree\"- Rows 30 to 34 named `variable_name`: ethics_items_oe <- codebook_post[[\"variable_name\"]][30:34] ethics_names_oe <- paste0(\"ethics_\", seq_along(ethics_items), \"_oe\") %>% purrr::set_names(., ethics_items_oe) # Create a new named vector of names for these columns # Edit the `variable_names` column: Use dplyr::mutate() and dplyr::case_match() to change the column `variable_name`: codebook_post <- codebook_post %>% dplyr::mutate(     variable_name = dplyr::case_match(         variable_name, # column to match         'custom_data_1' ~ \"unique_id\", # changes 'custom_data_1' to \"unique_id\"         'to_what_extent_are_you_knowledgeable_in_conducting_research_in_your_field_of_study' ~ \"knowledge\",         'with_which_gender_do_you_most_closely_identify' ~ \"gender\",         'which_race_ethnicity_best_describes_you_please_choose_only_one' ~ \"ethnicity\",         'are_you_a_first_generation_college_student' ~ \"first_gen\",         names(research_names) ~ research_names[variable_name], # takes the above named vector and when the name matches, applies new value in that position as replacement.         names(ability_names) ~ ability_names[variable_name],   # Same for `ability_names`         names(ethics_names) ~ ethics_names[variable_name],   # Same for `ability_names`         names(ethics_names_oe) ~ ethics_names_oe[variable_name],   # Same for `ethics_names_oe`         .default = variable_name # returns default value from original `variable_name` if not changed.         )     ) codebook_post #> # A tibble: 37 × 5 #>   header_1      header_2 combined_header position variable_name #>   <chr>         <chr>    <chr>              <int> <chr>         #> 1 Respondent ID NA       Respondent ID          1 respondent_id #> 2 Collector ID  NA       Collector ID           2 collector_id  #> 3 Start Date    NA       Start Date             3 start_date    #> 4 End Date      NA       End Date               4 end_date      #> 5 IP Address    NA       IP Address             5 ip_address    #> # ℹ 32 more rows # Write out the edited codebook to save for future use- # Be sure to double check questions match new names before writing out: # readr::write_csv(codebook_post, file = \"{filepath-to-codebok}\") # 3. Read in the data and rename the vars using readRenameData(), passing the file path and the edited codebook: post_data <- blackstone::readRenameData(post_data_fp, codebook = codebook_post) post_data #> # A tibble: 100 × 37 #>   respondent_id collector_id start_date end_date   ip_address      email_address #>           <dbl>        <dbl> <date>     <date>     <chr>           <chr>         #> 1  114628000001    431822954 2024-06-05 2024-06-06 227.224.138.113 coraima59@me… #> 2  114628000002    431822954 2024-06-21 2024-06-22 110.241.132.50  mstamm@hermi… #> 3  114628000003    431822954 2024-06-14 2024-06-15 165.58.112.64   precious.fei… #> 4  114628000004    431822954 2024-06-15 2024-06-16 49.34.121.147   ines52@gmail… #> 5  114628000005    431822954 2024-06-15 2024-06-16 115.233.66.80   franz44@hotm… #> # ℹ 95 more rows #> # ℹ 31 more variables: first_name <chr>, last_name <chr>, unique_id <dbl>, #> #   knowledge <chr>, research_1 <chr>, research_2 <chr>, research_3 <chr>, #> #   research_4 <chr>, research_5 <chr>, research_6 <chr>, research_7 <chr>, #> #   research_8 <chr>, ability_1 <chr>, ability_2 <chr>, ability_3 <chr>, #> #   ability_4 <chr>, ability_5 <chr>, ability_6 <chr>, ethics_1 <chr>, #> #   ethics_2 <chr>, ethics_3 <chr>, ethics_4 <chr>, ethics_5 <chr>, … # Pre data: pre_data <- pre_data %>% dplyr::rename_with(~ paste0(\"pre_\", .), .cols = c(knowledge:ethics_5)) # Pre data: post_data <- post_data %>% dplyr::rename_with(~ paste0(\"post_\", .), .cols = c(knowledge:ethics_5_oe))"},{"path":"https://zwcrowley.github.io/blackstone/articles/import_clean.html","id":"merging-data","dir":"Articles","previous_headings":"Data Cleaning and Manipulation","what":"Merging Data","title":"Importing and Cleaning Data","text":"Merge pre-post data joining variables shared common. dplyr package many joining functions, commonly use dplyr::left_join() keeps observations first table provided merges observations second match. data analysis, want use post data primary table merge pre data since post surveys drop participants, can run analysis complete data.","code":"# left_join() will automatically join by all the shared columns, be sure to include all shared variables that should be identical pre-post to the 'by = join_by()' as an arg # (otherwise you will get a message about additional variables to be joined by): sm_data <- post_data %>% dplyr::left_join(pre_data, by = dplyr::join_by(respondent_id, collector_id, start_date, end_date, ip_address, email_address,                                                                          first_name, last_name, unique_id, gender, ethnicity, first_gen)) sm_data #> # A tibble: 100 × 57 #>   respondent_id collector_id start_date end_date   ip_address      email_address #>           <dbl>        <dbl> <date>     <date>     <chr>           <chr>         #> 1  114628000001    431822954 2024-06-05 2024-06-06 227.224.138.113 coraima59@me… #> 2  114628000002    431822954 2024-06-21 2024-06-22 110.241.132.50  mstamm@hermi… #> 3  114628000003    431822954 2024-06-14 2024-06-15 165.58.112.64   precious.fei… #> 4  114628000004    431822954 2024-06-15 2024-06-16 49.34.121.147   ines52@gmail… #> 5  114628000005    431822954 2024-06-15 2024-06-16 115.233.66.80   franz44@hotm… #> # ℹ 95 more rows #> # ℹ 51 more variables: first_name <chr>, last_name <chr>, unique_id <dbl>, #> #   post_knowledge <chr>, post_research_1 <chr>, post_research_2 <chr>, #> #   post_research_3 <chr>, post_research_4 <chr>, post_research_5 <chr>, #> #   post_research_6 <chr>, post_research_7 <chr>, post_research_8 <chr>, #> #   post_ability_1 <chr>, post_ability_2 <chr>, post_ability_3 <chr>, #> #   post_ability_4 <chr>, post_ability_5 <chr>, post_ability_6 <chr>, …"},{"path":"https://zwcrowley.github.io/blackstone/articles/import_clean.html","id":"data-cleaning","dir":"Articles","previous_headings":"Data Cleaning and Manipulation","what":"Data Cleaning","title":"Importing and Cleaning Data","text":"Convert likert scales factors (ordering) demographics. Create numeric variables factor variables use statistical tests later . applicable, drop “Missing”/NA observations. data cleaned vignette used example data vignettes Data analysis Statistical Inference Data Visualization showcase functions contained blackstone.","code":"## Knowledge scale levels_knowledge <- c(\"Not knowledgeable at all\", \"A little knowledgeable\", \"Somewhat knowledgeable\", \"Very knowledgeable\", \"Extremely knowledgeable\") ## Research Items scale: levels_confidence <- c(\"Not at all confident\", \"Slightly confident\", \"Somewhat confident\", \"Very confident\", \"Extremely confident\") ## Ability Items scale:  levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") ## Ethics Items scale: levels_agree5 <- c(\"Strongly disagree\", \"Disagree\", \"Neither agree nor disagree\", \"Agree\", \"Strongly agree\")  # Demographic levels: gender_levels <- c(\"Female\",\"Male\",\"Non-binary\", \"Do not wish to specify\") ethnicity_levels <- c(\"White (Non-Hispanic/Latino)\", \"Asian\", \"Black\",  \"Hispanic or Latino\", \"American Indian or Alaskan Native\",                       \"Native Hawaiian or other Pacific Islander\", \"Do not wish to specify\") first_gen_levels <- c(\"Yes\", \"No\", \"I'm not sure\")  # Use mutate() for convert each item in each scale to a factor with vectors above, across() will perform a function for items selected using contains() or can be selected  # by variables names individually using a character vector: _knowledge or use c(\"pre_knowledg\",\"post_knowledge\") # Also create new numeric variables for all the likert scale items and use the suffix '_num' to denote numeric: sm_data <- sm_data %>% dplyr::mutate(dplyr::across(tidyselect::contains(\"_knowledge\"), ~ factor(., levels = levels_knowledge)), # match each name pattern to select to each factor level                                      dplyr::across(tidyselect::contains(\"_knowledge\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all knowledge items                                      dplyr::across(tidyselect::contains(\"research_\"), ~ factor(., levels = levels_confidence)),                                       dplyr::across(tidyselect::contains(\"research_\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all research items                                      dplyr::across(tidyselect::contains(\"ability_\"), ~ factor(., levels = levels_min_ext)),                                      dplyr::across(tidyselect::contains(\"ability_\"), as.numeric, .names = \"{.col}_num\"), # create new numeric items for all ability items                                      # select ethics items but not the open_ended responses:                                      dplyr::across(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_oe\"), ~ factor(., levels = levels_agree5)),                                      dplyr::across(tidyselect::contains(\"ethics_\") & !tidyselect::contains(\"_oe\"), as.numeric, .names = \"{.col}_num\"), # new numeric items for all ethics items                                      # individually convert all demographics to factor variables:                                      gender = factor(gender, levels = gender_levels),                                      ethnicity = factor(ethnicity, levels = ethnicity_levels),                                      first_gen = factor(first_gen, levels = first_gen_levels),                                      ) sm_data #> # A tibble: 100 × 97 #>   respondent_id collector_id start_date end_date   ip_address      email_address #>           <dbl>        <dbl> <date>     <date>     <chr>           <chr>         #> 1  114628000001    431822954 2024-06-05 2024-06-06 227.224.138.113 coraima59@me… #> 2  114628000002    431822954 2024-06-21 2024-06-22 110.241.132.50  mstamm@hermi… #> 3  114628000003    431822954 2024-06-14 2024-06-15 165.58.112.64   precious.fei… #> 4  114628000004    431822954 2024-06-15 2024-06-16 49.34.121.147   ines52@gmail… #> 5  114628000005    431822954 2024-06-15 2024-06-16 115.233.66.80   franz44@hotm… #> # ℹ 95 more rows #> # ℹ 91 more variables: first_name <chr>, last_name <chr>, unique_id <dbl>, #> #   post_knowledge <fct>, post_research_1 <fct>, post_research_2 <fct>, #> #   post_research_3 <fct>, post_research_4 <fct>, post_research_5 <fct>, #> #   post_research_6 <fct>, post_research_7 <fct>, post_research_8 <fct>, #> #   post_ability_1 <fct>, post_ability_2 <fct>, post_ability_3 <fct>, #> #   post_ability_4 <fct>, post_ability_5 <fct>, post_ability_6 <fct>, …"},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"introduction-and-installation-of-r-and-rstudio","dir":"Articles","previous_headings":"","what":"Introduction and Installation of R and RStudio","title":"Setup and RStudio Projects","text":"RStudio integrated development environment (IDE) designed run R, open-source programming language statistical computing graphics. R RStudio kept date, current release can found respective links : “Install R” “Install RStudio”.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"shared-workflow","dir":"Articles","previous_headings":"","what":"Shared Workflow","title":"Setup and RStudio Projects","text":"Blackstone Research Evaluation, strive utilize best practices data science starts implementing shared workflow order make work reproducible across projects. shared workflow ensure anyone BRE able open work product (Rmarkdown files ‘.Rmd’ R scripts ‘.R’) run local machine reproduce exact results original author. ‘code truth’ approach reduces confusion saves time since R work code produced unnecessary spend lot time pointing clicking save files create figures applications. order achieve , must use standard workflow, file management, setup RStudio.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"file-management","dir":"Articles","previous_headings":"","what":"File Management","title":"Setup and RStudio Projects","text":"work products (Rmarkdown files ‘.Rmd’ R scripts ‘.R’) created course completing data analysis task, including data cleaning transformation, saved correct Blackstone Google Drive project folder.1 project folders Blackstone Google Drive standard folder structure, looks something like :2 raw survey data files kept correct project year folder Phase 2 - Evaluation/Data folder. survey data ‘Year 4 (2023-2024)’ project save Phase 2 - Evaluation/Data/Year 4 (2023-2024). Using subfolders project year level help organize data pre post surveys, multiple surveys different topics given year. data analysis files kept correct project year folder Phase 2 - Evaluation/Data Analysis folder. Later, go use RStudio Projects create subfolder correct project year folder Phase 2 - Evaluation/Data Analysis folder organize files run analyses Google Drive folder importing data Phase 2 - Evaluation/Data subfolders. First, lets turn basic setup RStudio.","code":"#> /home/runner/work/_temp/Library/blackstone/2429_DEMO #> ├── Archive #> ├── Phase1_Sales_Finance #> ├── Phase2_Evaluation #> │   ├── Client_Meeting_Notes #> │   ├── Concept_Data_Analysis_Guide #> │   ├── Data #> │   │   ├── Year1_(2020-2021) #> │   │   ├── Year2_(2021-2022) #> │   │   ├── Year3_(2022-2023) #> │   │   └── Year4_(2023-2024) #> │   ├── Data_Analysis #> │   │   ├── Year1_(2020-2021) #> │   │   ├── Year2_(2021-2022) #> │   │   ├── Year3_(2022-2023) #> │   │   └── Year4_(2023-2024) #> │   ├── Instruments #> │   └── Logic_Model #> └── Phase3_Reporting"},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"rstudio-setup","dir":"Articles","previous_headings":"","what":"RStudio Setup","title":"Setup and RStudio Projects","text":"workflow data analysis BRE center around producing R code reproducible anyone. need maintain RStudio settings help facilitate process. first step make sure new R session blank slate nothing done previously carries current work. two ways : Either run usethis::use_blank_slate()3 RStudio, go top menu bar select ‘Tools’, ‘Global Options’, ‘General’ settings make sure ‘Workspace’ section (blue box) matches options figure 1 : Figure 1: RStudio Global Options ensure new R session starts empty global environment (data variables previous session). Also, important routinely restart R session re-run code make sure everything code produces expected results, figures, outputs. can done RStudio first saving current work Rmarkdown file(s) (.Rmd) R script(s) (.R) file, selecting ‘Session’ top menu bar, clicking ‘Restart R’.4 clear global environment unload R packages. Re-run code ensure includes everything necessary complete assigned data tasks.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"introduction-to-rstudio-projects","dir":"Articles","previous_headings":"Creating and using RStudio Projects","what":"Introduction to RStudio Projects","title":"Setup and RStudio Projects","text":"order shared workflow, standard way set organize files necessary project work BRE. also need way set working directory5 R session reproducible across different users. Using setwd() code work original author, subsequent users change file path. RStudio supports RStudio Projects. RStudio Project allows user launch RStudio associated folder designated current working directory. Designating new existing folder RStudio Project creates new file folder extension .Rproj, file saves settings Project, among things. next section, go use file set relative file paths using designated Project folder root directory. Double-clicking .Rproj, launch fresh RStudio instance new R process working directory set parent folder. allows user easily switch projects worry setting working directory starting new R process/clean global environment. Multiple instances RStudio can also opened different Projects time. file browser RStudio instance show current working directory, see figure 2: Figure 2: RStudio File Browser also shown just R Console shown figure 3: Figure 3: RStudio Console Working Directory","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"creating-an-rstudio-project","dir":"Articles","previous_headings":"Creating and using RStudio Projects","what":"Creating an RStudio Project","title":"Setup and RStudio Projects","text":"create new RStudio Project, go top menu bar select ‘File’, click ‘New Project…’, launch ‘New Project Wizard’. first page ‘Create Project’, Select ‘New Directory’: Figure 4.1: New Project Wizard- Create Project second page ‘Project Type’, Select ‘New Project’: Figure 4.2: New Project Wizard- Project Type third page ‘Create New Project’, check box ‘Open new session’ lower-left corner, set ‘Directory name’ ‘analysis_{Initials}’, ‘Create project subdirectory ’. click ‘Browse…’, navigate correct project folder: shown next figure 4.4. Figure 4.3: New Project Wizard- Name Set Parent Folder hypothetically, tasked data analysis Year 4 (2023-2024) project, go set parent folder (new project folder created) Phase 2 - Evaluation/Data Analysis/Year 4 (2023-2024). click ‘Browse…’ next ‘Create project subdirectory ’: navigate project folder Google Drive go evaluation folder- ‘Phase 2 - Evaluation’, ‘Data Analysis’ ‘Year 4 (2023-2024)’ click ‘Open’ Figure 4.4: Browse Correct Project Folder Finally, setting correct parent folder, back third page ‘Create New Project’. completed steps, settings resemble figure 4.5 can proceed click ‘Create Project’ lower-right corner. launch new Project named ‘analysis_{Initials}’ Figure 4.5: New Project Wizard- Create New Project Another way create RStudio Project using rstudioapi6 package, allows interact RStudio R code. code creates new folder, creates .Rproj file name, running last line code open new RStudio Project new RStudio instance:7 Now RStudio Project can use save files necessary data analysis task inside folder don’t worry using setwd() manage working directory. also","code":"# file path for new `analysis` folder: analysis_fp <- fs::path(\"Phase 2 - Evaluation\", \"Data Analysis\", \"Year 4 (2023-2024)\", \"analysis\") # Create a new folder named `analysis` in for \"Data Analysis\"/Year4_(2023-2024): fs::dir_create(analysis_fp) # Data Analysis Year 4  # Creating a new RStudio Project in the `analysis` folder: rstudioapi::initializeProject(path = analysis_fp)  # Open the new project in a a new `RStudio` instance: rstudioapi::openProject(path = analysis_fp, newSession = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"managing-file-paths-with-the-here-package","dir":"Articles","previous_headings":"","what":"Managing File Paths with the here Package","title":"Setup and RStudio Projects","text":"order highlight another advantage working RStudio Project, let’s say tasked data analysis hypothetical Blackstone project. project folder named 2429_DEMO Blackstone Google Drive analysis fourth year (Year 4 (2023-2024)). completed steps create RStudio Project Phase 2 - Evaluation/Data Analysis/Year 4 (2023-2024) folder named ‘analysis’ shown directory tree , subfolder Phase 2 - Evaluation/Data Analysis/Year 4 (2023-2024) named ‘analysis’ RStudio Project file named analysis.Rproj. also created Rmarkdown file folder called report.Rmd. launch RStudio Project can either go top menu bar RStudio, click ‘File’, ‘Open Project…’ navigate analysis.Rproj click ‘Open’ go operating system’s File Finder/Explorer navigate analysis.Rproj double-click . confirm RStudio Project open current RStudio instance go top-right corner RStudio. Figure 5: Current RStudio Project (top-right corner IDE) click current RStudio Project shown , drop-menu gives options switch Projects open new RStudio instances run multiple projects . Now, opened RStudio Project file analysis.Rproj working directory set analysis folder file path: /home/runner/work/_temp/Library/blackstone/2429_DEMO/Phase2_Evaluation/Data_Analysis/analysis file path local machine, differ based location 2429_DEMO folder Google Drive Desktop set (different user names shortcut IDs). also creates issue want navigate Data folder code import data analysis. write file path stable time different users?","code":"#> /home/runner/work/_temp/Library/blackstone/2429_DEMO/Phase2_Evaluation/Data_Analysis #> ├── Year1_(2020-2021) #> ├── Year2_(2021-2022) #> ├── Year3_(2022-2023) #> └── Year4_(2023-2024) #>     └── analysis #>         ├── analysis.Rproj #>         └── report.Rmd"},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"introduction-to-the-here-package","dir":"Articles","previous_headings":"Managing File Paths with the here Package","what":"Introduction to the here Package","title":"Setup and RStudio Projects","text":"package solves issue using RStudio Project files (.Rproj) create relative file paths. R anytime set working directory (either using setwd() opening RStudio Project), can reference file paths using paths relative working directory using getwd(). file path changes, either moving folders code running different machines, method longer work. packages provides way always reference location specified RStudio Project files (.Rproj) root directory relative file paths, even working directory switched subfolder RStudio Project folder (case knitting .Rmd file). package two simple functions allow us build reproducible file paths.","code":""},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"using-the-here-package","dir":"Articles","previous_headings":"Managing File Paths with the here Package","what":"Using the here Package","title":"Setup and RStudio Projects","text":"package installed, install : install.packages(\"\") first step set current location file working using ::i_am()8 relative path project root directory. done beginning R script (‘.R’) first code chunk Rmarkdown file (‘.Rmd’). working file report.Rmd contained inside analysis folder look like : ::i_am() finds returns project root directory. Since file report.Rmd contained alongside analysis.Rproj file inside analysis folder, call returns file path analysis folder. called ::i_am(), can load package use () return project root folder. clear, () function differs just returning current working directory. fact, change working directory () still return project root directory set initial call ::i_am().","code":"here::i_am(\"report.Rmd\") #> here() starts at /home/runner/work/_temp/Library/blackstone/2429_DEMO/Phase2_Evaluation/Data_Analysis/Year4_(2023-2024)/analysis library(here) here() #> [1] \"/home/runner/work/_temp/Library/blackstone/2429_DEMO/Phase2_Evaluation/Data_Analysis/Year4_(2023-2024)/analysis\""},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"relative-file-paths-with-here","dir":"Articles","previous_headings":"Managing File Paths with the here Package","what":"Relative File Paths with here()","title":"Setup and RStudio Projects","text":"Now, can use () build relative paths read write data. works including folder file destination inside function, either single string separated commas. wanted build path Data folder example project folder, let’s see work. First, helpful review folder structure: order build path Phase2_EvaluationData_Analysis/Year4_(2023-2024)/analysis (top-level project directory) Phase2_Evaluation/Data folder, need go “” three levels done file paths using “..” like : ../../../ Using () can build relative path analysis `Data folder: path can added file paths complete desired path number files within Data folder. Returning original example evaluation folder, want read data Data/Year 4 (2023-2024) folder run analyses report.Rmd can set series file paths using (). can re-use file path build rest path needed read clean data9 Year 4:","code":"#> /home/runner/work/_temp/Library/blackstone/2429_DEMO/Phase2_Evaluation #> ├── Client_Meeting_Notes #> ├── Concept_Data_Analysis_Guide #> ├── Data #> │   ├── Year1_(2020-2021) #> │   ├── Year2_(2021-2022) #> │   ├── Year3_(2022-2023) #> │   └── Year4_(2023-2024) #> │       ├── clean_data #> │       │   └── sm_data_clean.csv #> │       ├── post_data #> │       │   └── sm_data_post.csv #> │       └── pre_data #> │           └── sm_data_pre.csv #> ├── Data_Analysis #> │   ├── Year1_(2020-2021) #> │   ├── Year2_(2021-2022) #> │   ├── Year3_(2022-2023) #> │   └── Year4_(2023-2024) #> │       └── analysis #> │           ├── analysis.Rproj #> │           └── report.Rmd #> ├── Instruments #> └── Logic_Model # Setting up file path to the Data folder for Year 4: data_fp <- here(\"../../../Data\") # or can be written as: here(\"..\", \"..\" ,\"..\" ,\"Data\") data_fp #> [1] \"/home/runner/work/_temp/Library/blackstone/2429_DEMO/Phase2_Evaluation/Data_Analysis/Year4_(2023-2024)/analysis/../../../Data\" # Setting up file path to the Data folder for Year 4: data_year4_fp <- here(data_fp, \"Year4_(2023-2024)\") # or can be written as: here(\"..\", \"..\" ,\"..\" ,\"Data\", \"Year4_(2023-2024)\") data_year4_fp #> [1] \"/home/runner/work/_temp/Library/blackstone/2429_DEMO/Phase2_Evaluation/Data_Analysis/Year4_(2023-2024)/analysis/../../../Data/Year4_(2023-2024)\" # File path to clean data from Year 4 named: \"sm_data_clean.csv\" here(data_year4_fp, \"clean_data\", \"sm_data_clean.csv\")  #> [1] \"/home/runner/work/_temp/Library/blackstone/2429_DEMO/Phase2_Evaluation/Data_Analysis/Year4_(2023-2024)/analysis/../../../Data/Year4_(2023-2024)/clean_data/sm_data_clean.csv\" # or can be written as: here(\"..\", \"..\" ,\"..\" ,\"Data\", \"Year4_(2023-2024)\", \"clean_data\", \"sm_data_clean.csv\")  # Reading in the clean data from Year 4 named: \"sm_data_clean.csv\" readr::read_csv(file = here(data_year4_fp, \"clean_data\", \"sm_data_clean.csv\"), show_col_types = FALSE, n_max = 3, col_select = c(1,6:12)) #> # A tibble: 3 × 8 #>   respondent_id email_address      first_name last_name unique_id post_knowledge #>           <dbl> <chr>              <chr>      <chr>         <dbl> <chr>          #> 1  114628000001 coraima59@medhurs… Dellia     Collier    24290001 A little know… #> 2  114628000002 mstamm@hermiston.… Etter      Williams…  24290002 Not knowledge… #> 3  114628000003 precious.feil@gma… Marin      Lind       24290003 Extremely kno… #> # ℹ 2 more variables: post_research_1 <chr>, post_research_2 <chr>"},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"try-yourself","dir":"Articles","previous_headings":"","what":"Try Yourself","title":"Setup and RStudio Projects","text":"blackstone R package installation comes full example project directory, analysis folder containing analysis.Proj report.Rmd. final code chunk allows easily access files ever installed local machine. edits make files lost re-install/update blackstone R package. Run code open example project new RStudio instance open report.Rmd copying next line code console new RStudio instance:10","code":"# Code to open the example `analysis` `RStudio` Project (will launch in a new `RStudio` instance): rstudioapi::openProject(path = fs::path_package(\"2429_DEMO/Phase2_Evaluation/Data_Analysis/Year4_(2023-2024)/analysis/analysis.Rproj\", package = \"blackstone\"),                         newSession = TRUE)  # Code to open \"report.Rmd\" (must be in the `analysis` `RStudio` Project): rstudioapi::navigateToFile(   file = \"report.Rmd\" )"},{"path":"https://zwcrowley.github.io/blackstone/articles/setup_projects.html","id":"additional-resources-for-r-rstudio-and-project-workflows","dir":"Articles","previous_headings":"","what":"Additional Resources for R, RStudio, and Project Workflows","title":"Setup and RStudio Projects","text":"R data science: “Workflow: 6.2 Projects” chapter Hadley Wickham Forgot Teach R: “3 Project-oriented workflow” chapter Jenny Bryan, Jim Hester, Shannon Pileggi, E. David Aja “Project-oriented workflow” Tidyverse Blog Post Jenny Bryan","code":""},{"path":"https://zwcrowley.github.io/blackstone/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Zack Crowley. Author, maintainer. Blackstone Research Evaluation. Copyright holder, funder.","code":""},{"path":"https://zwcrowley.github.io/blackstone/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Crowley Z (2024). blackstone: Blackstone Research Evaluation Data Analysis Visualization. R package version 0.0.0.9000, https://zwcrowley.github.io/blackstone/, https://github.com/zwcrowley/blackstone.","code":"@Manual{,   title = {blackstone: Blackstone Research and Evaluation Data Analysis and Visualization},   author = {Zack Crowley},   year = {2024},   note = {R package version 0.0.0.9000, https://zwcrowley.github.io/blackstone/},   url = {https://github.com/zwcrowley/blackstone}, }"},{"path":[]},{"path":"https://zwcrowley.github.io/blackstone/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Blackstone Research and Evaluation Data Analysis and Visualization","text":"goal blackstone make data manipulation, analysis, visualization easier faster Blackstone Research Evaluation. blackstone used create visuals Blackstone Research Evaluation branding well common data cleaning, manipulation, analysis tasks everyone Blackstone Research Evaluation.","code":""},{"path":"https://zwcrowley.github.io/blackstone/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Blackstone Research and Evaluation Data Analysis and Visualization","text":"can install development version blackstone GitHub R package pak : initial installation (upgrading R) also install import fonts extrafont package:","code":"# install.packages(\"pak\") pak::pak(\"zwcrowley/blackstone\") # install.packages(\"extrafont\") library(extrafont) # Import fonts to get \"Arial\", this only has to be done one time, then # `blackstone` package will use the code below to load the fonts automatically  # for the functions that require that step: extrafont::font_import() # Load all fonts: extrafont::loadfonts(\"all\", quiet = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Blackstone Research and Evaluation Data Analysis and Visualization","text":"one use blackstone creates stacked bar chart pre-post data: Stacked Bar Chart Pre-Post Data See vignettes examples functions package work.","code":"library(blackstone) # Example pre-post data: items <- dplyr::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 ) # Set up the named vector to pass to scale_labels,  # follow this pattern- c(\"{new label}\" = \"{original variable name}\"): named_levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\",                            \"Good\" = \"4\", \"Extensive\" = \"5\") # Recode numeric variables to factors using `recodeCat()` and  # select the factor variables: cat_items <- blackstone::recodeCat(df = items,                                     scale_labels = named_levels_min_ext) %>%               dplyr::select(dplyr::where(is.factor))  # `levels_min_ext` as just the names from `named_levels_min_ext`: levels_min_ext <- names(named_levels_min_ext)  # Question labels as a named vector with the naming structure like this: #  c(\"{new label}\" = \"{original variable name}\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                      \"Write a lot of research papers\" = \"Write\",                      \"Research in a lab with faculty\" = \"Research\",                      \"Organization of a large research project\" = \"Organization\",                      \"Source work for a research paper\" = \"Source\")  # With new labels and order taken from `question_labels` argument, each  # item has it's own sample size in the label (overall_n = FALSE): blackstone::stackedBarChart(    df = cat_items, pre_post = TRUE, scale_labels = levels_min_ext,     overall_n = FALSE, question_labels = question_labels,     question_order = TRUE, percent_label = TRUE )"},{"path":"https://zwcrowley.github.io/blackstone/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"Blackstone Research and Evaluation Data Analysis and Visualization","text":"functions visuals added blackstone package needed, sure reach ideas package issues! encounter clear bug need help package, please reach Zack Crowley Google Chat space titled blackstone R package, direct message, email zcrowley@blackstoneevaluation.com.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/addBarChartPrePostTheme.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","title":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","text":"function add plot theme options Pre-Post bar chart, pass args font size family.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/addBarChartPrePostTheme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","text":"","code":"addBarChartPrePostTheme(font_size, font_family)"},{"path":"https://zwcrowley.github.io/blackstone/reference/addBarChartPrePostTheme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","text":"font_size Required, numeric, font size chart. font_family Required, character, name font family use chart.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/addBarChartPrePostTheme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to Add Theme Options to a Pre-Post Bar Chart — addBarChartPrePostTheme","text":"list ggplot2 guides theme objects add ggplot2 object.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/addBarChartTheme.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to Add Theme Options to a Bar Chart — addBarChartTheme","title":"Helper function to Add Theme Options to a Bar Chart — addBarChartTheme","text":"function add plot theme options bar chart, pass args font size family.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/addBarChartTheme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to Add Theme Options to a Bar Chart — addBarChartTheme","text":"","code":"addBarChartTheme(font_size, font_family)"},{"path":"https://zwcrowley.github.io/blackstone/reference/addBarChartTheme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to Add Theme Options to a Bar Chart — addBarChartTheme","text":"font_size Required, numeric, font size chart. font_family Required, character, name font family use chart.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/addBarChartTheme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to Add Theme Options to a Bar Chart — addBarChartTheme","text":"list ggplot2 guides theme objects add ggplot2 object.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/addPlotTag.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to Add a Plot Tag — addPlotTag","title":"Helper function to Add a Plot Tag — addPlotTag","text":"function add plot tag upper left corner ggplot total n sample. Pass args total n, font size family.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/addPlotTag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to Add a Plot Tag — addPlotTag","text":"","code":"addPlotTag(n, font_size, font_family, plot_tag_position = c(-0.01, 1.05))"},{"path":"https://zwcrowley.github.io/blackstone/reference/addPlotTag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to Add a Plot Tag — addPlotTag","text":"n Required, numeric, total n sample chart font_size Required, numeric, font size chart. font_family Required, character, name font family use chart. plot_tag_position Required, character vector length two specifies x y coordinates places plot tag, defaults c(-0.01, 1.05).","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/addPlotTag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to Add a Plot Tag — addPlotTag","text":"list ggplot2 labs theme objects add ggplot2 object.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChart.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"arrowChart() creates pre-post arrow chart averages returns ggplot object.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"","code":"arrowChart(   df,   scale_labels,   arrow_colors = \"#283251\",   overall_n = TRUE,   question_labels = NULL,   question_order = FALSE,   font_family = \"Arial\",   font_size = 10 )"},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"df Required, tibble data frame numeric data items prefix pre_ post_. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). arrow_colors Required, defaults dark blue BRE color code \"#283251\" values, character vector hex codes colors associate item, needs length longer items place chart. overall_n Logical, default TRUE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest post score average top plot descending. font_family Character value set font family text chart, defaults \"Arial\". font_size Numeric value set font size points text chart, defaults size 10.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"ggplot2 object plots items arrow bar chart.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arrow Chart for Blackstone Research and Evaluation — arrowChart","text":"","code":"items <- dplyr::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 ) # Labels for response scales to recode the numeric variables to on the plot: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                      \"Write a lot of research papers\" = \"Write\",                      \"Research in a lab with faculty\" = \"Research\",                      \"Organization of a large research project\" = \"Organization\",                      \"Source work for a research paper\" = \"Source\")  # Example with n for each question and original labels: arrowChart(df = items, scale_labels = levels_min_ext, overall_n = FALSE,            question_labels = NULL, question_order = FALSE)  # With new labels, question_order = FALSE, and overall_n set to TRUE: arrowChart(df = items, scale_labels = levels_min_ext, overall_n = TRUE,            question_labels = question_labels, question_order = FALSE)  # With new labels and order taken from question_labels argument, and overall_n set to FALSE: arrowChart(df = items, scale_labels = levels_min_ext, overall_n = FALSE,            question_labels = question_labels, question_order = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChartGroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"arrowChartGroup() creates pre-post arrow chart group averages returns ggplot object.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChartGroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"","code":"arrowChartGroup(   df,   group,   scale_labels,   group_colors = NULL,   group_levels,   overall_n = TRUE,   question_labels = NULL,   question_order = FALSE,   font_family = \"Arial\",   font_size = 10 )"},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChartGroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"df Required, tibble data frame numeric data items prefix pre_ post_; categorical group variable split data (e.g. role, gender, education level, etc.). group Required, name grouping variable quoted character string, e.g. \"role\", \"gender\", \"edu_level\", etc.. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). group_colors Required, character vector hex codes colors associate group supplied group_levels argument. , e.g. data two groups function creates overall group function need 'group_colors' character vector three colors. group_colors need order want associated group based factor levels group variable. Defaults BRE custom qualitative palette black always color \"Overall\" group. group_levels Required, character vector factor levels grouping variable, e.g. grouping variable gender : \"male\", \"female\", \"non-binary\". overall_n Logical, default TRUE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest post score average top plot descending. font_family Character value set font family text chart, defaults \"Arial\". font_size Numeric value set font size points text chart, defaults size 10.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChartGroup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"ggplot2 object plots items arrow bar chart.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/arrowChartGroup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arrow Chart by Group for Blackstone Research and Evaluation — arrowChartGroup","text":"","code":"items <- dplyr::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1,   edu_level = factor(        c(       \"grad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\",       \"undergrad\", \"undergrad\", \"grad\", \"undergrad\"       ),       levels = c(\"grad\", \"undergrad\")       ) )  # Labels for response scales to recode the numeric variables to on the plot: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                      \"Write a lot of research papers\" = \"Write\",                      \"Research in a lab with faculty\" = \"Research\",                      \"Organization of a large research project\" = \"Organization\",                      \"Source work for a research paper\" = \"Source\")  # Example grouped by the variable \"edu_level\", with n for each question and original labels: arrowChartGroup(df = items, group = \"edu_level\", scale_labels = levels_min_ext,                 group_levels = c(\"grad\", \"undergrad\"), overall_n = FALSE,                 question_labels = NULL, question_order = FALSE)   # With new labels, question_order = FALSE, and overall_n set to TRUE: arrowChartGroup(df = items, group = \"edu_level\", scale_labels = levels_min_ext,                 group_levels = c(\"grad\", \"undergrad\"), overall_n = TRUE,                 question_labels = question_labels, question_order = FALSE)   # With new labels and order taken from question_labels argument, and overall_n set to FALSE: arrowChartGroup(df = items, group = \"edu_level\", scale_labels = levels_min_ext,                 group_levels = c(\"grad\", \"undergrad\"), overall_n = FALSE,                 question_labels = question_labels, question_order = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstone-package.html","id":null,"dir":"Reference","previous_headings":"","what":"blackstone: Blackstone Research and Evaluation Data Analysis and Visualization — blackstone-package","title":"blackstone: Blackstone Research and Evaluation Data Analysis and Visualization — blackstone-package","text":"goal `blackstone` make data manipulation, analysis, visualization easier faster Blackstone Research Evaluation. `blackstone` contains functions create visuals Blackstone Research Evaluation branding well common data cleaning, manipulation, analysis tasks everyone Blackstone Research Evaluation.","code":""},{"path":[]},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstone-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"blackstone: Blackstone Research and Evaluation Data Analysis and Visualization — blackstone-package","text":"Maintainer: Zack Crowley zcrowley@blackstoneevaluation.com contributors: Blackstone Research Evaluation [copyright holder, funder]","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstoneColors.html","id":null,"dir":"Reference","previous_headings":"","what":"blackstone Colors as a Named Vector — blackstoneColors","title":"blackstone Colors as a Named Vector — blackstoneColors","text":"utils function loading Blackstone Research Evaluation colors charts.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstoneColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blackstone Colors as a Named Vector — blackstoneColors","text":"","code":"blackstoneColors"},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstoneColors.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"blackstone Colors as a Named Vector — blackstoneColors","text":"object class character length 4.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstoneColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"blackstone Colors as a Named Vector — blackstoneColors","text":"named vector hex colors Blackstone Research Evaluation.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstoneExample.html","id":null,"dir":"Reference","previous_headings":"","what":"Get path to blackstone example data — blackstoneExample","title":"Get path to blackstone example data — blackstoneExample","text":"blackstone comes bundled example files inst/extdata directory. function make easy access.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstoneExample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get path to blackstone example data — blackstoneExample","text":"","code":"blackstoneExample(path = NULL)"},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstoneExample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get path to blackstone example data — blackstoneExample","text":"path Name file. NULL, example files listed.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/blackstoneExample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get path to blackstone example data — blackstoneExample","text":"","code":"blackstoneExample() #> [1] \"annual.csv\"        \"annual.xlsx\"       \"baseline.csv\"      #> [4] \"baseline.xlsx\"     \"fake_data.csv\"     \"sm_data_clean.csv\" #> [7] \"sm_data_demo.csv\"  \"sm_data_post.csv\"  \"sm_data_pre.csv\"   blackstoneExample(\"fake_data.csv\") #> /home/runner/work/_temp/Library/blackstone/extdata/fake_data.csv"},{"path":"https://zwcrowley.github.io/blackstone/reference/createCodebook.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a codebook for SurveyMonkey data — createCodebook","title":"Create a codebook for SurveyMonkey data — createCodebook","text":"createCodebook() creates partial codebook can edited create useful variable names SurveyMonkey data. returns long form tibble use code book SurveyMonkey data, returns 5 columns described variable_name column used function readRenameData() rename variable names data imported R.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/createCodebook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a codebook for SurveyMonkey data — createCodebook","text":"","code":"createCodebook(file_path)"},{"path":"https://zwcrowley.github.io/blackstone/reference/createCodebook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a codebook for SurveyMonkey data — createCodebook","text":"file_path Required, file path extension .csv .xlsx.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/createCodebook.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a codebook for SurveyMonkey data — createCodebook","text":"tibble 5 columns: header_1, header_2, combined_header, variable_name position. header_1 first header row, header_2 second header row, combined_header combination two headers, position column number combined_header, variable_name cleaned version combined_header column edit change column names later shorter meaningful names.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/customCols.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function that makes selections from a color palette. — customCols","title":"Helper function that makes selections from a color palette. — customCols","text":"function return hex color codes color palette name numbered position.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/customCols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function that makes selections from a color palette. — customCols","text":"","code":"customCols(pal = qualColors(), cols = NULL)"},{"path":"https://zwcrowley.github.io/blackstone/reference/customCols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function that makes selections from a color palette. — customCols","text":"pal Required, named color palette named vector color hex codes, defaults qualColors. cols Required, character vector names numbered position use select named vector color hex codes , defaults NULL returns full palette.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/customCols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function that makes selections from a color palette. — customCols","text":"named character vector color hex codes.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/dataSumm.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a data frame that is a summary table of counts and percentages — dataSumm","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"Creates data frame summary table counts percentages","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/dataSumm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"","code":"dataSumm(var, na.rm = TRUE, sort_n = FALSE)"},{"path":"https://zwcrowley.github.io/blackstone/reference/dataSumm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"var column selected tibble/data frame categorical/factor variable summarized table. na.rm Logical, defaults TRUE. Drops NA values. sort_n Logical, defaults FALSE. TRUE, sorts data count response (n_answers). FALSE, sorts response.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/dataSumm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"tibble data 5 columns: item, response, n_answers, percent_answers percent_answers_label. Item name original item, Response categorical responses possible item. n_answers count response, percent_answers percentage response percent_answers_label character variable percentage labelled percent sign use label.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/dataSumm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a data frame that is a summary table of counts and percentages — dataSumm","text":"","code":"data <- tibble::tibble(   role = factor(c(     \"Faculty\", \"Postdoc\", \"Undergraduate student\", \"Graduate student\",     \"Graduate student\", \"Postdoc\", \"Postdoc\", \"Faculty\",     \"Faculty\", \"Graduate student\", \"Graduate student\", \"Postdoc\",     \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Graduate student\",     \"Undergraduate student\", \"Undergraduate student\", \"NA\", \"NA\"   ), levels = c(\"Undergraduate student\", \"Graduate student\", \"Postdoc\",\"Faculty\")) )  data %>%   dplyr::select(role) %>%   dataSumm() #> # A tibble: 4 × 5 #>   question response              n_answers percent_answers percent_answers_label #>   <chr>    <fct>                     <int>           <dbl> <chr>                 #> 1 role     Undergraduate student         3            0.15 15%                   #> 2 role     Graduate student              5            0.25 25%                   #> 3 role     Postdoc                       4            0.2  20%                   #> 4 role     Faculty                       8            0.4  40%                    # Includes NA values and sorted by count of response: data %>%   dplyr::select(role) %>%   dataSumm(na.rm = FALSE, sort_n = TRUE) #> # A tibble: 5 × 5 #>   question response              n_answers percent_answers percent_answers_label #>   <chr>    <fct>                     <int>           <dbl> <chr>                 #> 1 role     Faculty                       8          0.364  36%                   #> 2 role     Graduate student              5          0.227  23%                   #> 3 role     Postdoc                       4          0.182  18%                   #> 4 role     Undergraduate student         3          0.136  14%                   #> 5 role     NA                            2          0.0909 9%"},{"path":"https://zwcrowley.github.io/blackstone/reference/dataVizCleaning.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"Creates data frame summary table counts percentages","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/dataVizCleaning.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"","code":"dataVizCleaning(df, scale_labels, pre_post = FALSE, na_remove = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/reference/dataVizCleaning.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"df Required, tibble/data frame survey items categorical/character variables. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). pre_post Logical, default FALSE. true, returns tibble additional column timing factor variable either Pre Post. na_remove Logical, defaults TRUE. TRUE, Drops NA values; FALSE, turns NA's \"Missing\" adds factor first position scale_labels.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/dataVizCleaning.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"tibble data 5 columns: question, response, n_answers, percent_answers percent_answers_label. question name original item, response categorical responses possible item. n_answers count response, percent_answers percentage response percent_answers_label character variable percentage labelled percent sign use text label. pre_post arg TRUE, column timing added factor variable either Pre Post.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/dataVizCleaning.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a data frame that is a summary table of counts and percentages — dataVizCleaning","text":"","code":"# Fake data for examples, first are single items and the second has pre-post data with # correct prefixes in variable names: items_single <- tibble::tibble(     Organization = c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\",                      \"Good\", \"Moderate\", \"Slight\", \"Minimal\"),     Source = c(\"Slight\", \"Slight\", \"Moderate\", \"Extensive\", \"Good\", \"Moderate\",                 \"Slight\", \"Minimal\", \"Slight\"),     Publish = c(\"Minimal\", \"Minimal\", \"Minimal\", \"Slight\", \"Slight\", \"Slight\",                 \"Moderate\", \"Moderate\", \"Moderate\"),     Write = c(\"Slight\", \"Slight\", \"Slight\", \"Moderate\", \"Moderate\", \"Moderate\",                 \"Good\", \"Good\", \"Good\"),     Research = c(\"Minimal\", \"Minimal\", \"Slight\", \"Slight\", \"Moderate\",                 \"Moderate\", \"Good\", \"Good\", \"Good\") )  items_pre_post <- tibble::tibble(     pre_Organization = c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\",                     \"Extensive\", \"Good\", \"Moderate\", \"Slight\", \"Minimal\"),     post_Organization = c(\"Slight\", \"Moderate\", \"Good\", \"Extensive\",                     \"Extensive\", \"Extensive\", \"Good\", \"Moderate\", \"Slight\"),     pre_Source = c(\"Slight\", \"Slight\", \"Moderate\", \"Extensive\", \"Good\",                     \"Moderate\", \"Slight\", \"Minimal\", \"Slight\"),     post_Source = c(\"Good\", \"Good\", \"Extensive\", \"Extensive\", \"Good\",                     \"Extensive\", \"Good\", \"Moderate\", \"Good\"),     pre_Publish = c(\"Minimal\", \"Minimal\", \"Minimal\", \"Slight\", \"Slight\",                     \"Slight\", \"Moderate\", \"Moderate\", \"Moderate\"),     post_Publish = c(\"Moderate\", \"Moderate\", \"Moderate\", \"Good\", \"Good\",                     \"Good\", \"Extensive\", \"Extensive\", \"Extensive\"),     pre_Write = c(\"Slight\", \"Slight\", \"Slight\", \"Moderate\", \"Moderate\",                     \"Moderate\", \"Good\", \"Good\", \"Good\"),     post_Write = c(\"Moderate\", \"Moderate\", \"Moderate\", \"Good\", \"Good\",                     \"Good\", \"Extensive\", \"Extensive\", \"Extensive\"),     pre_Research = c(\"Minimal\", \"Minimal\", \"Slight\", \"Slight\", \"Moderate\",                     \"Moderate\", \"Good\", \"Good\", \"Good\"),     post_Research = c(\"Slight\", \"Slight\", \"Moderate\", \"Moderate\", \"Good\",                     \"Good\", \"Extensive\", \"Extensive\", \"Extensive\") ) # Add a row of NA values to each fake data set: items_pre_post_na <- dplyr::rows_append(items_pre_post,          tibble::as_tibble_row(purrr::set_names(rep(NA, NCOL(items_pre_post)),          names(items_pre_post)))) items_single_na <- dplyr::rows_append(items_single,          tibble::as_tibble_row(purrr::set_names(rep(NA, NCOL(items_single)),          names(items_single))))  # Likert scale to pass to `scale_labels` that is the order to arrange each variable: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\")  dataVizCleaning(df = items_single, pre_post = FALSE,                 scale_labels = levels_min_ext, na_remove = TRUE) #> # A tibble: 20 × 5 #>    question     response  n_answers percent_answers percent_answers_label #>    <chr>        <fct>         <int>           <dbl> <chr>                 #>  1 Organization Minimal           2           0.222 22%                   #>  2 Organization Slight            2           0.222 22%                   #>  3 Organization Moderate          2           0.222 22%                   #>  4 Organization Good              2           0.222 22%                   #>  5 Organization Extensive         1           0.111 11%                   #>  6 Publish      Minimal           3           0.333 33%                   #>  7 Publish      Slight            3           0.333 33%                   #>  8 Publish      Moderate          3           0.333 33%                   #>  9 Research     Minimal           2           0.222 22%                   #> 10 Research     Slight            2           0.222 22%                   #> 11 Research     Moderate          2           0.222 22%                   #> 12 Research     Good              3           0.333 33%                   #> 13 Source       Minimal           1           0.111 11%                   #> 14 Source       Slight            4           0.444 44%                   #> 15 Source       Moderate          2           0.222 22%                   #> 16 Source       Good              1           0.111 11%                   #> 17 Source       Extensive         1           0.111 11%                   #> 18 Write        Slight            3           0.333 33%                   #> 19 Write        Moderate          3           0.333 33%                   #> 20 Write        Good              3           0.333 33%                   dataVizCleaning(df = items_single_na, pre_post = FALSE,                 scale_labels = levels_min_ext, na_remove = FALSE) #> # A tibble: 25 × 5 #>    question     response  n_answers percent_answers percent_answers_label #>    <chr>        <fct>         <int>           <dbl> <chr>                 #>  1 Organization Missing           1             0.1 10%                   #>  2 Organization Minimal           2             0.2 20%                   #>  3 Organization Slight            2             0.2 20%                   #>  4 Organization Moderate          2             0.2 20%                   #>  5 Organization Good              2             0.2 20%                   #>  6 Organization Extensive         1             0.1 10%                   #>  7 Publish      Missing           1             0.1 10%                   #>  8 Publish      Minimal           3             0.3 30%                   #>  9 Publish      Slight            3             0.3 30%                   #> 10 Publish      Moderate          3             0.3 30%                   #> # ℹ 15 more rows dataVizCleaning(df = items_pre_post, pre_post = TRUE,                 scale_labels = levels_min_ext, na_remove = TRUE) #> # A tibble: 37 × 6 #>    question     timing response  n_answers percent_answers percent_answers_label #>    <chr>        <fct>  <fct>         <int>           <dbl> <chr>                 #>  1 Organization Pre    Minimal           2           0.222 22%                   #>  2 Organization Pre    Slight            2           0.222 22%                   #>  3 Organization Pre    Moderate          2           0.222 22%                   #>  4 Organization Pre    Good              2           0.222 22%                   #>  5 Organization Pre    Extensive         1           0.111 11%                   #>  6 Organization Post   Slight            2           0.222 22%                   #>  7 Organization Post   Moderate          2           0.222 22%                   #>  8 Organization Post   Good              2           0.222 22%                   #>  9 Organization Post   Extensive         3           0.333 33%                   #> 10 Publish      Pre    Minimal           3           0.333 33%                   #> # ℹ 27 more rows dataVizCleaning(df = items_pre_post_na, pre_post = TRUE,                 scale_labels = levels_min_ext, na_remove = FALSE) #> # A tibble: 47 × 6 #>    question     timing response  n_answers percent_answers percent_answers_label #>    <chr>        <fct>  <fct>         <int>           <dbl> <chr>                 #>  1 Organization Pre    Missing           1             0.1 10%                   #>  2 Organization Pre    Minimal           2             0.2 20%                   #>  3 Organization Pre    Slight            2             0.2 20%                   #>  4 Organization Pre    Moderate          2             0.2 20%                   #>  5 Organization Pre    Good              2             0.2 20%                   #>  6 Organization Pre    Extensive         1             0.1 10%                   #>  7 Organization Post   Missing           1             0.1 10%                   #>  8 Organization Post   Slight            2             0.2 20%                   #>  9 Organization Post   Moderate          2             0.2 20%                   #> 10 Organization Post   Good              2             0.2 20%                   #> # ℹ 37 more rows"},{"path":"https://zwcrowley.github.io/blackstone/reference/divBarChart.html","id":null,"dir":"Reference","previous_headings":"","what":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"divBarChart() creates diverging bar chart returns ggplot object Blackstone Research Evaluation branding.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/divBarChart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"","code":"divBarChart(   df,   scale_labels,   fill_colors = \"seq\",   pre_post = FALSE,   overall_n = TRUE,   percent_label = TRUE,   question_labels = NULL,   question_order = FALSE,   width = NULL,   font_family = \"Arial\",   font_size = 10 )"},{"path":"https://zwcrowley.github.io/blackstone/reference/divBarChart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"df Required, tibble/data frame survey items categorical/character variables, inserted stacked bar chart Blackstone Research Evaluation branding. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). fill_colors Default \"seq\", \"seq\", color scale fill bar set blue sequential palette. set \"div\", blue-red diverging color palette, otherwise user can input character vector hex codes least long character vector passed scale_labels argument. pre_post Logical, default FALSE. true, returns pre-post stacked bar chart. overall_n Logical, default TRUE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. percent_label Logical, default TRUE. FALSE, labels bars number answers per response. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest positive valenced response options top plot descending. width Input value 0.3 0.8 set thickness bars. Default NULL. font_family Character value set font family text chart, defaults \"Arial\". font_size Numeric value set font size points text chart, defaults size 10.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/divBarChart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"ggplot2 object plots items stacked bar chart can exported.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/divBarChart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Diverging Bar Chart for Blackstone Research and Evaluation — divBarChart","text":"","code":"items <- tibble::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 )  items_single <- tibble::tibble(   Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4), )  # Set scale_labels for recodeCat function: # scale_labels as a named character vector, items in correct order: levels_min_ext <- c(   \"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\",   \"Good\" = \"4\", \"Extensive\" = \"5\" )  # bar_scale_labels as just the names from levels_min_ext: bar_scale_labels <- names(levels_min_ext)  # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(   \"Publish a lot of high quality papers\" = \"Publish\",   \"Write a lot of research papers\" = \"Write\",   \"Research in a lab with faculty\" = \"Research\",   \"Organization of a large research project\" = \"Organization\",   \"Source work for a research paper\" = \"Source\" )  # Recode the numeric to factor variables using the levels from levels_min_ext and # select the factor variables:: cat_items <- blackstone::recodeCat(items, levels_min_ext) %>%                  dplyr::select(dplyr::where(is.factor)) cat_items_single <- blackstone::recodeCat(items_single, levels_min_ext) %>%                         dplyr::select(dplyr::where(is.factor))  # Pass the factor variables and the levels to stackedBarChart: divBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = NULL, percent_label = TRUE, width = NULL )  divBarChart(   df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,   question_labels = NULL, percent_label = TRUE, width = NULL )  divBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = question_labels, question_order = FALSE, percent_label = TRUE, width = NULL )  divBarChart(   df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,   question_labels = question_labels, question_order = FALSE, percent_label = TRUE, width = NULL )"},{"path":"https://zwcrowley.github.io/blackstone/reference/divFillColors.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"function create diverging color palette using Blue-Red 3 reversed slightly darkened.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/divFillColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"","code":"divFillColors(n_colors)"},{"path":"https://zwcrowley.github.io/blackstone/reference/divFillColors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"n_colors Required, number color hex codes return.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/divFillColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"character vector hex color codes length n_colorsfrom Blue-Red 3 palette package colorspace.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/divFillColors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper to create a diverging color palette using Blue-Red 3 that is reversed. — divFillColors","text":"","code":"# Returns the 5 colors in the diverging palette: divFillColors(n_colors = 5) #> [1] \"#600204\" \"#B88081\" \"#DADADA\" \"#7F8EB8\" \"#012B67\"  # Returns the 7 colors colors in the diverging palette:: divFillColors(n_colors = 7) #> [1] \"#600204\" \"#A25959\" \"#CDA2A3\" \"#DADADA\" \"#A3ADCB\" \"#536DA8\" \"#012B67\""},{"path":"https://zwcrowley.github.io/blackstone/reference/getHeaders.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert two row headers from SurveyMonkey data into long from data — getHeaders","title":"Convert two row headers from SurveyMonkey data into long from data — getHeaders","text":"getHeaders() helper function get headers long form tibble.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/getHeaders.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert two row headers from SurveyMonkey data into long from data — getHeaders","text":"","code":"getHeaders(file_path)"},{"path":"https://zwcrowley.github.io/blackstone/reference/getHeaders.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert two row headers from SurveyMonkey data into long from data — getHeaders","text":"file_path Required, file path extension .csv .xlsx.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/getHeaders.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert two row headers from SurveyMonkey data into long from data — getHeaders","text":"tibble 3 columns: header_1, header_2, combined_header. header_1 first header row, header_2 second header row, combined_header combination two headers.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/groupedTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"groupedTable() creates summary table frequencies percentages can show breakdowns groups totals data passed . table shows item responses row.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/groupedTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"","code":"groupedTable(df, col_group = NULL, question_labels = NULL, str_width = 20)"},{"path":"https://zwcrowley.github.io/blackstone/reference/groupedTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"df Required, tibble data frame categorical/factor data also can contain categorical group variable split data, e.g. role, gender, education level, etc. col_group Default NULL. name categorical group variable split data, e.g. role, gender, education level, etc. Must quotes (e.g. \"role\"). question_labels Default NULL. Takes named character vector supply labels questions sort order questions.named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing table, first item appear top table. See examples. str_width Default 20. character length wrap question column. question_labels supplied long use keep question column large table.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/groupedTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"flextable object columns question, response, counts percentages group total column. Colors set Blackstone Research Evaluation branding","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/groupedTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Grouped Summary Table for Blackstone Research and Evaluation — groupedTable","text":"Question Response 1 (n = 6) 2 (n = 6) Total (n = 12)1 Gender      Female 3 (25%) 4 (33%) 7 (58%)  Male 3 (25%) 2 (17%) 5 (42%) Ethnicity      Asian 1 (8%) 2 (17%) 3 (25%)  Black 1 (8%) 1 (8%) 2 (17%)  Hispanic Latino 1 (8%) 2 (17%) 3 (25%)  white 3 (25%) 1 (8%) 4 (33%) Year school      grad 5 (42%) - 5 (42%)  undergrad 1 (8%) 6 (50%) 7 (58%) Department ofAffiliation      Biology 1 (8%) 4 (33%) 5 (42%)  Chemistry 3 (25%) 1 (8%) 4 (33%)  Physics 2 (17%) 1 (8%) 3 (25%) 1n (%) Question Response n = 121 Gender    Female 7 (58%)  Male 5 (42%) Ethnicity    Asian 3 (25%)  Black 2 (17%)  Hispanic Latino 3 (25%)  white 4 (33%) Year school    grad 5 (42%)  undergrad 7 (58%) Department ofAffiliation    Biology 5 (42%)  Chemistry 4 (33%)  Physics 3 (25%) Cohort    1 6 (50%)  2 6 (50%) 1n (%)","code":"data <- dplyr::tibble(   Cohort = factor(c(1,2,1,2,1,2,1,2,1,2,1,2), levels = c(1, 2)),   gender = factor(c(              \"Female\", \"Female\",\"Female\",\"Male\", \"Female\",\"Male\",              \"Male\", \"Female\",\"Male\", \"Female\", \"Male\", \"Female\"              ), levels = c(\"Female\", \"Male\")),   year = factor(c(       \"grad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\",\"undergrad\",       \"undergrad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\",\"undergrad\"                 ), levels = c(\"grad\", \"undergrad\")),  department = factor(c(       \"Chemistry\", \"Biology\", \"Chemistry\", \"Biology\", \"Physics\",\"Biology\",       \"Biology\", \"Physics\", \"Chemistry\", \"Chemistry\", \"Physics\",\"Biology\"                ), levels = c(\"Biology\", \"Chemistry\", \"Physics\")),  ethnicity = factor(c(       \"Asian\", \"Black\", \"white\", \"Hispanic or Latino\", \"white\",\"Asian\",       \"Black\", \"Asian\", \"white\", \"white\", \"Hispanic or Latino\",\"Hispanic or Latino\"                   ), levels = c( \"Asian\", \"Black\", \"Hispanic or Latino\", \"white\")) )  # Labels for questions column of table, pass to question_labels argument: labels <- c('Gender' = \"gender\",              'Ethnicity' = \"ethnicity\",              'Year in school' = \"year\",              'Department of Affiliation' = \"department\")  # Call groupedTable with a grouping variable: data %>% groupedTable(col_group = \"Cohort\", question_labels = labels) .cl-a8bee30e{}.cl-a8b82e10{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-a8b82e24{font-family:'Arial';font-size:6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;position: relative;bottom:3pt;}.cl-a8b82e2e{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-a8b82e2f{font-family:'Arial';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-a8b82e38{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-a8bae628{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-a8bae63c{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-a8bafd20{width:1.077in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd21{width:1.286in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd2a{width:0.729in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd34{width:0.845in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd35{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd3e{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd3f{width:0.729in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd48{width:0.845in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd52{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd5c{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd5d{width:0.729in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd66{width:0.845in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd67{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd70{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd71{width:0.729in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd7a{width:0.845in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd7b{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd84{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd85{width:0.729in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd86{width:0.845in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd8e{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd8f{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafd98{width:0.729in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafda2{width:0.845in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafda3{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafda4{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafdac{width:0.729in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafdad{width:0.845in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafdb6{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafdc0{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafdc1{width:0.729in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8bafdc2{width:0.845in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}QuestionResponse1 (n = 6)2 (n = 6)Total (n = 12)1GenderFemale3 (25%)4 (33%)7 (58%)Male3 (25%)2 (17%)5 (42%)EthnicityAsian1 (8%)2 (17%)3 (25%)Black1 (8%)1 (8%)2 (17%)Hispanic or Latino1 (8%)2 (17%)3 (25%)white3 (25%)1 (8%)4 (33%)Year in schoolgrad5 (42%)-5 (42%)undergrad1 (8%)6 (50%)7 (58%)Department ofAffiliationBiology1 (8%)4 (33%)5 (42%)Chemistry3 (25%)1 (8%)4 (33%)Physics2 (17%)1 (8%)3 (25%)1n (%)# Call groupedTable without a grouping variable: data %>% groupedTable(question_labels = labels) .cl-a8e8e50a{}.cl-a8e32570{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-a8e3257a{font-family:'Arial';font-size:6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;position: relative;bottom:3pt;}.cl-a8e32584{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-a8e32585{font-family:'Arial';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-a8e3258e{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-a8e5873e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-a8e58748{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-a8e59904{width:1.077in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5990e{width:1.286in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5990f{width:0.723in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59918{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59922{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5992c{width:0.723in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5992d{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59936{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59937{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59938{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59940{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59941{width:0.723in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59942{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5994a{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5994b{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5994c{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5994d{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59954{width:0.723in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59955{width:1.077in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5995e{width:1.286in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e5995f{width:0.723in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59960{width:1.077in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59968{width:1.286in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a8e59972{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}QuestionResponsen = 121GenderFemale7 (58%)Male5 (42%)EthnicityAsian3 (25%)Black2 (17%)Hispanic or Latino3 (25%)white4 (33%)Year in schoolgrad5 (42%)undergrad7 (58%)Department ofAffiliationBiology5 (42%)Chemistry4 (33%)Physics3 (25%)Cohort16 (50%)26 (50%)1n (%)"},{"path":"https://zwcrowley.github.io/blackstone/reference/horzBarChart.html","id":null,"dir":"Reference","previous_headings":"","what":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"horzBarChart() creates horizontal bar chart returns ggplot object Blackstone Research Evaluation branding.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/horzBarChart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"","code":"horzBarChart(df, scale_colors, width = NULL)"},{"path":"https://zwcrowley.github.io/blackstone/reference/horzBarChart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"df Required, tibble/data frame pre-processed dataSumm(). scale_colors Required, character vector colors scale items. width Input value 0.3 0.8 set thickness bars. Default NULL.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/horzBarChart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"ggplot2 object plots items horizontal bar chart can exported.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/horzBarChart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Horizontal Bar Chart for Blackstone Research and Evaluation — horzBarChart","text":"","code":"data <- dplyr::tibble(   role = c(     \"Faculty\", \"Postdoc\", \"Undergraduate student\", \"Graduate student\",     \"Graduate student\", \"Postdoc\", \"Postdoc\", \"Faculty\",     \"Faculty\", \"Graduate student\", \"Graduate student\", \"Postdoc\",     \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Graduate student\",     \"Undergraduate student\", \"Undergraduate student\"   ) )  role_summ <- data %>%   dplyr::select(role) %>%   blackstone::dataSumm()  role_color <- c(\"#2C2C4F\", \"#4B9FA6\", \"#79AB53\", \"#767171\")  horzBarChart(df = role_summ, scale_colors = role_color, width = 0.6)"},{"path":"https://zwcrowley.github.io/blackstone/reference/labelColorMaker.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function that creates text label colors. — labelColorMaker","title":"Helper function that creates text label colors. — labelColorMaker","text":"function label text color charts inside fill bar charts, returns either \"black\" \"white\" depending luminance color scale passed .","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/labelColorMaker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function that creates text label colors. — labelColorMaker","text":"","code":"labelColorMaker(colors, names = NULL)"},{"path":"https://zwcrowley.github.io/blackstone/reference/labelColorMaker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function that creates text label colors. — labelColorMaker","text":"colors Required, character vector hex color codes, usually color palette chart. names Optional, character vector length colors argument add names returned vector.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/labelColorMaker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function that creates text label colors. — labelColorMaker","text":"character vector colors either \"black\" \"white\" labeling text fill colors.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/levelsEnv.html","id":null,"dir":"Reference","previous_headings":"","what":"Levels Environment and home to all scale_labels vectors: — levelsEnv","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"Levels Environment home scale_labels vectors:","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/levelsEnv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"","code":"levelsEnv"},{"path":"https://zwcrowley.github.io/blackstone/reference/levelsEnv.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"object class environment length 3.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/levelsEnv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"levelsEnv","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/levelsEnv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Levels Environment and home to all scale_labels vectors: — levelsEnv","text":"","code":"# TODO: Figure out how to store all scale_labels vectors and how to then # retrieve them when building charts # One potential solution- use environments and retrieve the vectors when using the package # inside scripts and Rmd docs, and eventually when moving to automating reporting in R. # # Try with three levels that are normally used like this in vectors to pass to the # scale_labels argument across blackstone package: # # levels min_ext: # levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # # # levels never to always: # levels_never_always <- c(\"Never\", \"Rarely\", \"Sometimes\", \"Frequently\", \"Always\") # # # levels useful: # levels_useful <- c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", # \"Very useful\", \"Extremely useful\") # # How to make them into a Named list of stacked levels: # stacked_levels <- list(levels_min_ext,levels_never_always,levels_useful) # # Names for named list of \"stacked levels\" using the suffixes for stacked bar charts: # names(stacked_levels) <- c(\"levels_min_ext\",\"levels_never_always\",\"levels_useful\") # # TODO: Test in the file \"R_Reporting_template.Rmd\": # # # EXAMPLE: # url <- \"http://mytext.com\" # file <- \"This is the content I downloaded\" # cacheEnv <- new.env() # assign(url, file, envir=cacheEnv) # get(url, envir=cacheEnv) # # Creating and fill new environment with vectors and parameters for use across the whole package: # Name new environment- \"levelsEnv\": # levelsEnv <- new.env() # Assign each vector to the new environment using this code: # assign(<name of var/vector>, <content of var/vector>, envir=cacheEnv) # both the name and content can be already assigned alias/vars that you pass to the assign() # like in the example above: # # levels min_ext: # levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # assign(\"levels_min_ext\", c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"), # envir = levelsEnv) # how to retrieve and name back to the original vector name- Two Ways- # 1. using get() or 2. using the familiar list extraction: env[[<name of var/vector>]]: # levels_min_ext <- get(\"levels_min_ext\", envir = levelsEnv) # levels_min_ext <- levelsEnv[[\"levels_min_ext\"]] # # Assign two other vectors to the new environment- \"levelsEnv\": # # levels never to always: # levels_never_always <- c(\"Never\", \"Rarely\", \"Sometimes\", \"Frequently\", \"Always\") # assign(\"levels_never_always\", c(\"Never\", \"Rarely\", \"Sometimes\", \"Frequently\", \"Always\"), # envir = levelsEnv) # levels_never_always <- get(\"levels_never_always\", envir = levelsEnv) # # levels useful: # levels_useful <- c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", # \"Very useful\", \"Extremely useful\") # assign(\"levels_useful\", c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", # \"Very useful\", \"Extremely useful\"), envir = levelsEnv) # levels_useful <- get(\"levels_useful\", envir = levelsEnv) # Continue adding variables/vectors/parameters as needed for package/reporting needs..."},{"path":"https://zwcrowley.github.io/blackstone/reference/likertTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"likertTable() creates summary table frequencies percentages Likert scale items can show breakdowns data passed . table contains frequency percent row column Likert scale response, items must scale labels.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/likertTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"","code":"likertTable(df, scale_labels, question_labels = NULL, str_width = 20)"},{"path":"https://zwcrowley.github.io/blackstone/reference/likertTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"df Required, tibble data frame categorical/factor data scale labels. scale_labels Required, character vector labels response scale Likert items, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). question_labels Default NULL. Takes named character vector supply labels questions sort order questions.named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing table, first item appear top table. See examples. str_width Default 20. character length wrap question column. question_labels supplied long use keep question column large table.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/likertTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"flextable object columns question, likert response item, total column items total n item. Colors set Blackstone Research Evaluation branding","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/likertTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Table for Likert Items for Blackstone Research and Evaluation — likertTable","text":"Question Minimal Slight Moderate Good Extensive n Publish lot ofhigh quality papers - 3 (15%) 3 (15%) 4 (20%) 10 (50%) 20 Write lot ofresearch papers - - 2 (10%) 10 (50%) 8 (40%) 20 Research labwith faculty - 1 (5%) 8 (40%) 3 (15%) 8 (40%) 20 Organization ofa large researchproject - 3 (15%) 6 (30%) 5 (25%) 6 (30%) 20 Source work aresearch paper - - 3 (15%) 11 (55%) 6 (30%) 20 Question Minimal Slight Moderate Good Extensive n Organization - 3 (15%) 6 (30%) 5 (25%) 6 (30%) 20 Source - - 3 (15%) 11 (55%) 6 (30%) 20 Publish - 3 (15%) 3 (15%) 4 (20%) 10 (50%) 20 Write - - 2 (10%) 10 (50%) 8 (40%) 20 Research - 1 (5%) 8 (40%) 3 (15%) 8 (40%) 20","code":"data <- tibble::tribble(      ~Organization, ~Source, ~Publish, ~Write, ~Research,                 5L,      3L,       3L,     4L,        5L,                 4L,      4L,       3L,     3L,        3L,                 4L,      4L,       3L,     5L,        3L,                 2L,      5L,       4L,     5L,        3L,                 3L,      4L,       5L,     4L,        5L,                 3L,      4L,       2L,     4L,        2L,                 5L,      4L,       5L,     5L,        3L,                 3L,      5L,       5L,     4L,        3L,                 5L,      4L,       4L,     4L,        5L,                 3L,      5L,       5L,     4L,        3L,                 5L,      4L,       2L,     5L,        5L,                 4L,      3L,       5L,     5L,        4L,                 2L,      4L,       5L,     4L,        3L,                 5L,      4L,       4L,     5L,        4L,                 3L,      5L,       2L,     5L,        5L,                 5L,      4L,       4L,     4L,        5L,                 4L,      4L,       5L,     3L,        5L,                 3L,      5L,       5L,     4L,        4L,                 4L,      3L,       5L,     4L,        5L,                 2L,      5L,       5L,     5L,        3L      )  # Scale labels for the Likert items: levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\") # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(\"Publish a lot of high quality papers\" =  \"Publish\",                   \"Write a lot of research papers\" = \"Write\",                   \"Research in a lab with faculty\" = \"Research\",                   \"Organization of a large research project\" = \"Organization\",                   \"Source work for a research paper\" = \"Source\") # Named Vector for recodeCat(): named_levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\",                     \"Good\" = \"4\", \"Extensive\" = \"5\") # Recode the numeric to factor variables using the levels from levels_min_ext: cat_items <- blackstone::recodeCat(data, named_levels_min_ext) # Select the factor variables, and remove the prefix that recodeCat() added to the factor variables: cat_items <- cat_items %>% dplyr::select(dplyr::where(is.factor)) %>%                            dplyr::rename_with(., ~ stringr::str_remove(.,\"cat_\")) # Another way to convert all to factor variables with levels if already character variables : # cat_items <- data %>% #   mutate(across(everything(),~ factor(., levels = levels_min_ext))) # Pass the factor variables and the levels to likertTable : cat_items %>% likertTable(scale_labels = levels_min_ext, question_labels = question_labels) .cl-a9e9a610{}.cl-a9e2f75c{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-a9e2f766{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-a9e2f770{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-a9e528d8{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-a9e528e2{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-a9e539e0{width:1.335in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e539ea{width:0.764in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e539f4{width:0.723in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e539f5{width:0.872in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e539f6{width:0.792in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e539fe{width:0.887in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e539ff{width:0.424in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a08{width:1.335in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a09{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a12{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a1c{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a1d{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a26{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a27{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a30{width:1.335in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a31{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a3a{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a3b{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a44{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a45{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a4e{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a4f{width:1.335in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a58{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a59{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a5a{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a62{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a6c{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a9e53a6d{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}QuestionMinimalSlightModerateGoodExtensivenPublish a lot ofhigh quality papers-3 (15%)3 (15%)4 (20%)10 (50%)20Write a lot ofresearch papers--2 (10%)10 (50%)8 (40%)20Research in a labwith faculty-1 (5%)8 (40%)3 (15%)8 (40%)20Organization ofa large researchproject-3 (15%)6 (30%)5 (25%)6 (30%)20Source work for aresearch paper--3 (15%)11 (55%)6 (30%)20# Call likertTable without a question_labels: cat_items %>% likertTable(scale_labels = levels_min_ext) .cl-aa084624{}.cl-aa02eb98{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-aa02ebac{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-aa02ebb6{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-aa051be8{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-aa051bf2{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-aa052d36{width:0.994in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d40{width:0.764in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d4a{width:0.723in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d4b{width:0.872in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d54{width:0.792in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d55{width:0.887in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d5e{width:0.424in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d5f{width:0.994in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d68{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d69{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d6a{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d6b{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d72{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d7c{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d7d{width:0.994in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d7e{width:0.764in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d86{width:0.723in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d87{width:0.872in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d90{width:0.792in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d91{width:0.887in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-aa052d9a{width:0.424in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}QuestionMinimalSlightModerateGoodExtensivenOrganization-3 (15%)6 (30%)5 (25%)6 (30%)20Source--3 (15%)11 (55%)6 (30%)20Publish-3 (15%)3 (15%)4 (20%)10 (50%)20Write--2 (10%)10 (50%)8 (40%)20Research-1 (5%)8 (40%)3 (15%)8 (40%)20"},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedCleanup.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean Up and Format Open-ended Text — openendedCleanup","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"Clean Format Open-ended Text","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedCleanup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"","code":"openendedCleanup(df, var, remove_values)"},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedCleanup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"df Required, tibble/data frame containing character variable text. var Required, character variable clean tibble/data frame, needs quotes. remove_values Required, character vector additional text remove text, see example.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedCleanup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"tibble contains one character variable clean text ready use output.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedCleanup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean Up and Format Open-ended Text — openendedCleanup","text":"","code":"# Example data: #  Training usefulness composite scale- 5 variables of that make up a scale: # Responsible, Ethics, Standards, Practices, Morals #  these are all on a 5-point likert scale of 1 to 5 needs to be #  recoded to: c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", #                \"Very useful\", \"Extremely useful\") # levels useful: levels_useful <- c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\",                    \"Very useful\", \"Extremely useful\") # Data: data <- dplyr::tibble(  Responsible = sample(levels_useful, size = 100, replace = TRUE,                        prob = c(0.1, 0.2, 0.3, 0.2, 0.1)),  Ethics = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.2, 0.3, 0.2, 0.1)),  Standards = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.3, 0.3)),  Practices = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.3, 0.3)),  Morals = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.05, 0.05, 0.2, 0.3, 0.4)),  Responsible_oe = ifelse(Responsible == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Ethics_oe = ifelse(Ethics == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Standards_oe = ifelse(Standards == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Practices_oe = ifelse(Practices == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Morals_oe = ifelse(Morals == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_)  ) %>% dplyr::select(dplyr::ends_with(\"_oe\"))  # Set up character vector of text or other things like punctuation to remove from the text data: remove_values <- c(\"N/A\", \".\", \"A\")  # Cleanup the open-ended response in the variable \"Responsible_oe\" with the function: data %>% openendedCleanup(., \"Responsible_oe\", remove_values) #> # A tibble: 11 × 1 #>    Responsible_oe                                                                #>    <chr>                                                                         #>  1 \"Commodo nisi sapien tellus ipsum dictumst habitant mauris, tempor platea tu… #>  2 \"Dolor iaculis lacus enim, velit neque, id consectetur, vitae odio iaculis\\n… #>  3 \"Felis dui in aenean nullam et, sed. Quis et morbi sodales sapien maximus ar… #>  4 \"Luctus penatibus nulla nullam varius in aenean consectetur vel. Cursus et\\n… #>  5 \"Maximus ac tempor quisque adipiscing nec porttitor. Volutpat vel parturient… #>  6 \"Nec parturient eros efficitur arcu adipiscing, ac. Dictumst a fermentum don… #>  7 \"Sed mauris magna augue dapibus enim. Nisi, mi maximus finibus in volutpat\\n… #>  8 \"Sem vehicula torquent, et dui fringilla vitae tortor sit arcu vestibulum.\\n… #>  9 \"Sit vestibulum elementum, tempor, ut in, at fringilla adipiscing. Purus mon… #> 10 \"Ultricies condimentum ac aenean sollicitudin, vel molestie nibh. Et ac, nis… #> 11 \"Venenatis, ut lacus et donec. Hac urna ac sagittis velit nascetur vestibulu…"},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedFlextable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"Create Formatted Flextable Open-ended Text","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedFlextable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"","code":"openendedFlextable(df, header_label)"},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedFlextable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"df Required, tibble data frame containing character variable text. header_label Required, label header table (can description prompt full question text).","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedFlextable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"flextable object nicely formatted BRE branding alphabetically order randomization.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/openendedFlextable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Formatted Flextable for Open-ended Text — openendedFlextable","text":"Made text example nicely formatted table Aenean malesuada pellentesque maecenas sed et. ut. Porta vestibulum.Ut maecenas sed mauris et nascetur tincidunt dictumst. Id neque efficiturvivamus nunc nisi natoque magna. Vestibulum ac nisl ut non fermentum, urna.Eu tempor pretium et porta, sociis iaculis. Vitae ante vestibulum ipsumsenectus, gravida curabitur ornare vel. donec, nec ipsum ullamcorper. Donec,conubia sociis viverra maecenas aliquet neque etiam, sed diam. Mollis dolor ,sed augue praesent, tempus. Sed ipsum eu sed lacinia inceptos feugiat finibuspellentesque egestas primis. Sed habitasse sed sem ex nostra et. Eget eu cubilia proin. Nec nascetur dui primis cum etiam semper, sedarcu ut commodo congue. Proin litora ligula gravida ut? Ac laoreet, vel feugiat!Sociis non justo nostra, sed, quam, litora dignissim tortor. Mauris proinlacus eget scelerisque, finibus nec laoreet. Vel mi pretium duis pellentesque aiaculis. Duis mi sed ultricies donec ex nibh tempus sit. Felis adipiscing. Ipsum venenatis bibendum ad, dapibus suscipit bibendum nulla. Lacinia urna,tincidunt sapien consequat suspendisse. Mi eleifend tempus cubilia tortor, sit.Mus, ex et aliquam dui tortor. Laoreet sit dapibus mollis leo maximus viverradiam, pellentesque sed nec. Ut integer sit accumsan sed imperdiet etiam quisvestibulum magna iaculis. Penatibus condimentum enim ut magna aenean et, hac nonconubia odio. ligula, montes nisi ac class lacus eget. Est tellus tempor eused vivamus. Sit elit augue varius. Odio nibh congue, integer euismod id rutrumfermentum ex. Sagittis eu id lacus libero maecenas porttitor. Quis malesuadaquis arcu nibh, nec, justo per. Sit consectetur sapien consequat temporpenatibus eu non nec. Sapien nam curabitur sed eros aliquet, nulla mi. Phasellus urna fermentum phasellus mauris, nam nisl lacus tincidunt. Maecenasa, sit sollicitudin sollicitudin urna! Mi senectus ex lobortis fringilla sedornare sed ex. Est quisque nam, eu arcu, tincidunt torquent sed mi. Lectusnisl, maecenas lacus dignissim dignissim, nulla porta cum risus. Ridiculusrutrum neque aptent rhoncus platea. Erat fringilla dolor vehicula scelerisquevenenatis, pretium mi. Ut sapien fringilla sapien aliquet blandit vitae nequenascetur eget quis massa mus. Molestie ullamcorper ac varius sit non necsed vel, non . Rhoncus quis consequat, nulla cras aliquet vestibulum et faucibus quis.Mi donec sit ligula sed augue fermentum eu arcu, sem dolor, sed volutpataliquet. Enim vehicula egestas risus fringilla maecenas mauris lobortis sit utegestas. Maximus nunc justo vitae sed orci diam nibh vel vitae. Libero, sodaleslaoreet elit placerat, dolor litora maximus dictum dis accumsan. Placerat nonrutrum ac dis, tristique vitae metus quam. Ultrices neque ac laoreet auguerisus mattis, et. Laoreet potenti cum lacus mauris, habitant, vehiculaac. Euismod turpis efficitur . Ac, cubilia, porta mollis pellentesque ametsem erat netus. Nec ultrices pellentesque, amet risus torquent tempor portavehicula. Sed sociosqu odio dis risus pulvinar enim sit nullam. Nisl non atfelis efficitur, diam vel vitae sed massa. Vitae sit urna feugiat donec dolor. Suspendisse justo inceptos suspendisse mollis consequat ac duis semper.Porttitor ut lacus sed, id taciti blandit ex vel. Lobortis nisl scelerisquedapibus, montes turpis condimentum. Vehicula nec? Vivamus fusce erat semfaucibus semper ligula eros turpis . Sed vitae laoreet, maurisparturient ante. Montes consectetur turpis quis, nibh, ornare dignissim est.Velit aenean luctus justo blandit vestibulum pharetra nostra inceptos et aptentquis faucibus. Vestibulum netus eget, habitant velit ac blandit id leo. Tortor dapibus sapien nec taciti eleifend eleifend vitae aptent. Ultricies inplacerat bibendum sed ullamcorper faucibus felis id, felis aliquam, facilisis.Fusce tortor nec amet amet, dolor libero enim ligula sed nisi. Nunc, lectusvelit non eleifend commodo, montes turpis ut. Sed lacus non litora eget eu,purus tempor velit. Sed pellentesque faucibus hac duis nisl justo, malesuadarutrum amet mi consequat. Ultrices posuere senectus . Ac augue mollisaccumsan eu pellentesque condimentum amet, sed. Ac eros metus ut interdumimperdiet molestie eu. Facilisi mus donec donec, accumsan justo sollicitudin invehicula. Natoque non ad, ac conubia. Ex pellentesque , eu lacus cubilia felisid condimentum et varius. Nisi eu. Ultrices gravida. Id lorem eu tincidunt sodales suscipit mauris id hachabitasse. Inceptos ut finibus cursus, quisque posuere elementum. Nasceturaenean varius sollicitudin. Dictum maximus montes dignissim nunc dis velitdignissim phasellus turpis ad. Sed ut commodo sem non eleifend porta commodorisus porta nibh aliquam. nisi mi tempor neque. Arcu tellus ut nec, ut etsuscipit velit lacus platea nulla. Amet ac duis vel sed. Sit est velit lectusfames ac fringilla dis sem nisl id et elementum rutrum . Ac, pulvinar ipsum eusem , per. Dis sed enim proin blandit id sapien risus habitasse ac. Facilisispenatibus imperdiet ipsum conubia natoque vitae. Adipiscing pretium metusante dapibus condimentum, cras molestie egestas fusce rhoncus. Ut arcu, egestas,morbi rhoncus praesent ac. Lacus ante maximus . Vel finibus, venenatis. Litoraut quis fermentum enim velit felis sed dictumst vel.","code":"# Example data: #  Training usefulness composite scale- 5 variables of that make up a scale: # Responsible, Ethics, Standards, Practices, Morals #  these are all on a 5-point likert scale of 1 to 5 needs to be #  recoded to: c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\", #                \"Very useful\", \"Extremely useful\") # levels useful: levels_useful <- c(\"Not at all useful\", \"Slightly useful\", \"Somewhat useful\",                    \"Very useful\", \"Extremely useful\") # Data: data <- dplyr::tibble(  Responsible = sample(levels_useful, size = 100, replace = TRUE,                        prob = c(0.1, 0.2, 0.3, 0.2, 0.1)),  Ethics = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.2, 0.3, 0.2, 0.1)),  Standards = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.3, 0.3)),  Practices = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.3, 0.3)),  Morals = sample(levels_useful, size = 100, replace = TRUE, prob = c(0.05, 0.05, 0.2, 0.3, 0.4)),  Responsible_oe = ifelse(Responsible == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Ethics_oe = ifelse(Ethics == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Standards_oe = ifelse(Standards == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Practices_oe = ifelse(Practices == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_),  Morals_oe = ifelse(Morals == \"Not at all useful\",                  stringi::stri_rand_lipsum(sample(1:100)), NA_character_)  ) %>% dplyr::select(dplyr::ends_with(\"_oe\"))  # Set up character vector of text or other things like punctuation to remove from the text data: remove_values <- c(\"N/A\", \".\", \"A\")  # Make a nice table after cleaning up the responses from the variable \"Responsible_oe\": data %>% blackstone::openendedCleanup(., \"Responsible_oe\", remove_values) %>%   openendedFlextable(., header_label = \"Made up text example in a nicely formatted table\") .cl-ab28f756{}.cl-ab23e400{font-family:'Arial';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-ab23e414{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-ab261356{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-ab26233c{width:5.589in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ab262346{width:5.589in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ab262350{width:5.589in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ab26235a{width:5.589in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ab26235b{width:5.589in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ab26235c{width:5.589in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ab262364{width:5.589in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ab262365{width:5.589in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ab262366{width:5.589in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}Made up text example in a nicely formatted tableAenean in malesuada pellentesque maecenas sed et. In ut. Porta in vestibulum.Ut maecenas sed mauris et nascetur tincidunt dictumst. Id neque efficiturvivamus nunc nisi natoque magna. Vestibulum ac nisl ut non fermentum, urna.Eu tempor pretium et in porta, sociis iaculis. Vitae ante vestibulum ipsumsenectus, gravida curabitur ornare vel. A donec, nec ipsum ullamcorper. Donec,conubia sociis viverra maecenas aliquet neque etiam, sed diam. Mollis dolor in,sed augue praesent, tempus. Sed ipsum eu sed lacinia inceptos feugiat finibuspellentesque egestas primis. Sed habitasse sed sem ex nostra et.Eget a eu cubilia in at proin. Nec nascetur dui primis cum etiam semper, in sedarcu ut commodo congue. Proin litora ligula gravida ut? Ac laoreet, vel feugiat!Sociis non justo nostra, a sed, quam, litora in dignissim tortor. Mauris proinlacus eget scelerisque, finibus nec laoreet. Vel mi pretium duis pellentesque aiaculis. Duis mi sed ultricies donec ex nibh tempus sit. Felis adipiscing.Ipsum venenatis bibendum ad, dapibus suscipit bibendum nulla. Lacinia urna,tincidunt sapien consequat suspendisse. Mi eleifend tempus cubilia tortor, sit.Mus, ex et at aliquam dui tortor. Laoreet sit dapibus mollis leo maximus viverradiam, pellentesque sed nec. Ut integer sit accumsan sed imperdiet etiam quisvestibulum magna iaculis. Penatibus condimentum enim ut magna aenean et, hac nonconubia odio. In ligula, montes nisi ac class lacus eget. Est tellus tempor eused vivamus. Sit elit augue varius. Odio nibh congue, integer euismod id rutrumfermentum ex. Sagittis eu id lacus libero in maecenas porttitor. Quis malesuadaquis arcu nibh, nec, justo per. Sit consectetur sapien consequat temporpenatibus eu non nec. Sapien nam curabitur sed eros aliquet, nulla mi.Phasellus urna fermentum phasellus mauris, nam nisl lacus tincidunt. Maecenasa, sit sollicitudin sollicitudin urna! Mi senectus ex lobortis fringilla sedornare sed ex. Est quisque nam, eu arcu, tincidunt torquent sed mi. Lectusnisl, maecenas lacus dignissim dignissim, nulla porta cum risus. Ridiculusrutrum neque aptent rhoncus platea. Erat fringilla dolor vehicula scelerisquevenenatis, pretium mi. Ut sapien fringilla in sapien aliquet blandit vitae nequenascetur eget quis massa mus. Molestie in ullamcorper ac varius at sit non necsed vel, non in.Rhoncus quis consequat, nulla cras aliquet vestibulum at et faucibus a quis.Mi donec sit ligula sed augue fermentum eu arcu, sem dolor, sed at volutpataliquet. Enim vehicula egestas risus fringilla maecenas mauris lobortis sit utegestas. Maximus nunc justo vitae sed orci diam nibh vel vitae. Libero, sodaleslaoreet elit placerat, dolor litora maximus dictum dis accumsan. Placerat nonrutrum ac dis, tristique vitae metus quam. Ultrices neque ac laoreet auguerisus mattis, a et. Laoreet potenti in cum lacus mauris, habitant, vehiculaac. Euismod turpis efficitur at. Ac, cubilia, porta in mollis pellentesque ametsem erat netus. Nec ultrices pellentesque, amet risus torquent tempor portavehicula. Sed sociosqu odio dis risus pulvinar enim sit nullam. Nisl non atfelis efficitur, diam vel vitae sed massa. Vitae sit urna feugiat donec dolor.Suspendisse justo inceptos suspendisse mollis consequat ac duis semper.Porttitor ut a in lacus sed, id taciti blandit ex vel. Lobortis nisl scelerisquedapibus, montes turpis condimentum. Vehicula nec? Vivamus fusce erat semfaucibus semper ligula eros turpis in in. Sed vitae in laoreet, maurisparturient ante. Montes consectetur turpis quis, nibh, ornare dignissim est.Velit aenean luctus justo blandit vestibulum pharetra nostra inceptos et aptentquis faucibus. Vestibulum netus eget, habitant velit ac blandit id leo.Tortor dapibus sapien nec taciti eleifend eleifend vitae aptent. Ultricies inplacerat bibendum sed ullamcorper faucibus a felis id, felis aliquam, facilisis.Fusce tortor nec amet amet, dolor libero enim in ligula sed nisi. Nunc, lectusvelit non eleifend commodo, montes turpis ut. Sed lacus non litora eget eu,purus tempor velit. Sed pellentesque faucibus hac duis nisl justo, malesuadarutrum amet mi consequat. Ultrices a posuere senectus in. Ac augue mollisaccumsan eu pellentesque condimentum amet, sed. Ac eros metus ut interdumimperdiet molestie eu. Facilisi mus donec donec, accumsan justo sollicitudin invehicula. Natoque non ad, ac conubia. Ex pellentesque in, eu lacus cubilia felisid condimentum et varius. Nisi eu.Ultrices gravida. Id lorem eu tincidunt sodales suscipit mauris id hachabitasse. Inceptos ut finibus cursus, quisque posuere elementum. Nasceturaenean varius sollicitudin. Dictum maximus montes dignissim nunc dis velitdignissim phasellus turpis ad. Sed ut commodo sem non eleifend porta commodorisus porta nibh aliquam. A nisi mi tempor neque. Arcu tellus ut nec, ut etsuscipit velit lacus platea nulla. Amet ac duis vel sed. Sit est velit lectusfames ac fringilla dis sem nisl id et elementum rutrum at. Ac, pulvinar ipsum eusem in, per. Dis sed enim proin blandit id sapien risus habitasse ac. Facilisispenatibus in imperdiet ipsum conubia natoque vitae. Adipiscing pretium metusante dapibus condimentum, cras molestie egestas fusce rhoncus. Ut arcu, egestas,morbi rhoncus praesent ac. Lacus ante maximus at. Vel finibus, venenatis. Litoraut quis fermentum enim velit felis sed dictumst vel."},{"path":"https://zwcrowley.github.io/blackstone/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://zwcrowley.github.io/blackstone/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/qualColors.html","id":null,"dir":"Reference","previous_headings":"","what":"blackstone Qualitative Colors as a Vector — qualColors","title":"blackstone Qualitative Colors as a Vector — qualColors","text":"utils function loading Qualitative color scale Blackstone Research Evaluation colors charts.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/qualColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"blackstone Qualitative Colors as a Vector — qualColors","text":"","code":"qualColors(add_names = FALSE)"},{"path":"https://zwcrowley.github.io/blackstone/reference/qualColors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"blackstone Qualitative Colors as a Vector — qualColors","text":"add_names Required, logical, FALSE returns vector hex color codes, TRUE returns named vector color names can used select .","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/qualColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"blackstone Qualitative Colors as a Vector — qualColors","text":"vector named vector hex colors Qualitative color scale Blackstone Research Evaluation.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/qualColors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"blackstone Qualitative Colors as a Vector — qualColors","text":"","code":"# Full color palette with names: qualColors(add_names = TRUE) #>          orange        sky blue    bluish green         magenta      vermillion  #>       \"#E69F00\"       \"#56B4E9\"       \"#009E73\"       \"#CC79A7\"       \"#D55E00\"  #>            blue  viridis purple       dark grey      dark green blackstone blue  #>       \"#0072B2\"     \"#440154FF\"       \"#999999\"       \"#117733\"       \"#283251\"  #>    yellow green  #>       \"#999933\"   # function to show color, names and hex codes as visual: show_colors2 <- function(colors) {     labels_color <- purrr::map_chr(seq_along(colors),                                    \\(x) paste0(\"'\",names(colors)[x], \"': \", colors[x]))     labels_text_color <- labelColorMaker(colors = colors)     ggplot2::ggplot(data.frame(id = rev(seq_along(colors)), color = rev(colors))) +         ggplot2::geom_tile(ggplot2::aes(1, id, fill = rev(color))) +         ggplot2::geom_text(ggplot2::aes(1, id, label = labels_color), color = labels_text_color) +         ggplot2::scale_fill_identity() +         ggplot2::scale_color_identity() +         ggplot2::theme_void() } show_colors2(colors = qualColors(add_names = TRUE))"},{"path":"https://zwcrowley.github.io/blackstone/reference/qualFillColors.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"function create custom qualitative colors palette Okabe-Ito palette, reversed rev_colors set TRUE. Drops black yellow use Blackstone charts adds three colors: \"#440154FF\", \"#283251\", \"#999933\".","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/qualFillColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"","code":"qualFillColors(n_colors = 11, rev_colors = FALSE)"},{"path":"https://zwcrowley.github.io/blackstone/reference/qualFillColors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"n_colors Required, supply non-negative integer desired number color hex codes return. rev_colors Logical, defaults FALSE, true returns reverse color codes darkest color comes first.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/qualFillColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"character vector hex color codes length n_colors.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/qualFillColors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper function to create qualitative colors from the Okabe-Ito palette. — qualFillColors","text":"","code":"# Returns the full color palette: qualFillColors() #>  [1] \"#E69F00\"   \"#56B4E9\"   \"#009E73\"   \"#CC79A7\"   \"#D55E00\"   \"#0072B2\"   #>  [7] \"#440154FF\" \"#999999\"   \"#117733\"   \"#283251\"   \"#999933\"    # Returns the first 5 colors in the palette: qualFillColors(n_colors = 5) #> [1] \"#E69F00\" \"#56B4E9\" \"#009E73\" \"#CC79A7\" \"#D55E00\"  # Returns the first 5 colors in the palette reversed: qualFillColors(n_colors = 5, rev_colors = TRUE) #> [1] \"#D55E00\" \"#CC79A7\" \"#009E73\" \"#56B4E9\" \"#E69F00\""},{"path":"https://zwcrowley.github.io/blackstone/reference/readRenameData.html","id":null,"dir":"Reference","previous_headings":"","what":"Import SurveyMonkey data and create new variable names — readRenameData","title":"Import SurveyMonkey data and create new variable names — readRenameData","text":"readRenameData() Reads SurveyMonkey data new variable names taken codebook tibble column named variable_name created using function createCodebook().","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/readRenameData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import SurveyMonkey data and create new variable names — readRenameData","text":"","code":"readRenameData(file_path, codebook)"},{"path":"https://zwcrowley.github.io/blackstone/reference/readRenameData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import SurveyMonkey data and create new variable names — readRenameData","text":"file_path Required, file path extension .csv .xlsx. codebook Required, tibble created using function createCodebook() column named variable_name new names data imported R.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/readRenameData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import SurveyMonkey data and create new variable names — readRenameData","text":"tibble SurveyMonkey data new variable names.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/recodeCat.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode Numeric Variables to Factor Variables — recodeCat","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"Recode Numeric Variables Factor Variables","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/recodeCat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"","code":"recodeCat(df, scale_labels)"},{"path":"https://zwcrowley.github.io/blackstone/reference/recodeCat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"df Required, tibble/data frame survey items numeric variables need converted factor variables, Can anywhere 3 7 point scales. scale_labels Required, named character vector labels desired scale levels new factor variables. function use vector convert numeric variables factor variables, levels must supplied correct range otherwise else NA returned variables outside range user supplied values. named character vector new labels \"name\" old labels \"variable\" like : c(\"\" = \"\") look like : levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\", \"Good\" = \"4\", \"Extensive\" = \"5\")","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/recodeCat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"tibble original numeric variables along new variables now factors prefix cat_{variable_name}, levels taken scale_labels character vector.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/recodeCat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode Numeric Variables to Factor Variables — recodeCat","text":"","code":"items <- dplyr::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 )  levels_min_ext <- c(\"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\",                      \"Good\" = \"4\", \"Extensive\" = \"5\")  recodeCat(df = items, scale_labels = levels_min_ext) #> # A tibble: 9 × 20 #>   pre_Organization post_Organization pre_Source post_Source pre_Publish #>              <dbl>             <dbl>      <dbl>       <dbl>       <dbl> #> 1                1                 2          2           4           1 #> 2                2                 3          2           4           1 #> 3                3                 4          3           5           1 #> 4                4                 5          5           5           2 #> 5                5                 5          4           4           2 #> 6                4                 5          3           5           2 #> 7                3                 4          2           4           3 #> 8                2                 3          1           3           3 #> 9                1                 2          2           4           3 #> # ℹ 15 more variables: post_Publish <dbl>, pre_Write <dbl>, post_Write <dbl>, #> #   pre_Research <dbl>, post_Research <dbl>, cat_pre_Organization <fct>, #> #   cat_post_Organization <fct>, cat_pre_Source <fct>, cat_post_Source <fct>, #> #   cat_pre_Publish <fct>, cat_post_Publish <fct>, cat_pre_Write <fct>, #> #   cat_post_Write <fct>, cat_pre_Research <fct>, cat_post_Research <fct>"},{"path":"https://zwcrowley.github.io/blackstone/reference/seqFillColors.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"function create sequential color scale using Blues 3, reversed slightly darkened.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/seqFillColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"","code":"seqFillColors(n_colors)"},{"path":"https://zwcrowley.github.io/blackstone/reference/seqFillColors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"n_colors Required, number color hex codes return.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/seqFillColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"character vector hex color codes length n_colors Blues 3 palette.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/seqFillColors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper to create a sequential color scale using Blues 3 that is reversed. — seqFillColors","text":"","code":"# Returns the 5 colors in the sequential palette: seqFillColors(n_colors = 5) #> [1] \"#DDDDDD\" \"#AEC3DF\" \"#7798BF\" \"#0466A2\" \"#023163\"  # Returns the 7 colors colors in the sequential palette:: seqFillColors(n_colors = 7) #> [1] \"#DDDDDD\" \"#BDCFE6\" \"#9FB5D5\" \"#7798BF\" \"#4677A7\" \"#00548B\" \"#023163\""},{"path":"https://zwcrowley.github.io/blackstone/reference/stackedBarChart.html","id":null,"dir":"Reference","previous_headings":"","what":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"stackedBarChart() creates stacked bar chart returns ggplot object Blackstone Research Evaluation branding.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/stackedBarChart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"","code":"stackedBarChart(   df,   scale_labels,   fill_colors = \"seq\",   pre_post = FALSE,   overall_n = TRUE,   percent_label = TRUE,   question_labels = NULL,   question_order = FALSE,   width = NULL )"},{"path":"https://zwcrowley.github.io/blackstone/reference/stackedBarChart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"df Required, tibble/data frame survey items categorical/character variables, inserted stacked bar chart Blackstone Research Evaluation branding. scale_labels Required, character vector labels response scale, must desired order, e.g. 5 item scale minimal extensive look like : levels_min_ext <- c(\"Minimal\", \"Slight\", \"Moderate\", \"Good\", \"Extensive\"). fill_colors Default \"seq\", \"seq\", color scale fill bar set blue sequential palette. set \"div\", blue-red diverging color palette, otherwise user can input character vector hex codes least long character vector passed scale_labels argument. pre_post Logical, default FALSE. true, returns pre-post stacked bar chart. overall_n Logical, default TRUE. TRUE, returns overall n questions upper left tag plot. False, adds n question/item respective labels. percent_label Logical, default TRUE. FALSE, labels bars number answers per response. question_labels Default NULL. Takes named character vector supply labels questions sort order questions. named character vector new labels \"name\" old labels \"variable\" sorted desired order appearing plot, first item appear top plot. See examples. question_order Logical, default FALSE. TRUE, question order taken user supplied named character vector passed question_labels, first item top plot . FALSE, question order questions highest positive valenced response options top plot descending. width Input value 0.3 0.8 set thickness bars. Default NULL.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/stackedBarChart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"ggplot2 object plots items stacked bar chart can exported.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/stackedBarChart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stacked Bar Chart for Blackstone Research and Evaluation — stackedBarChart","text":"","code":"items <- tibble::tibble(   pre_Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   post_Organization = dplyr::if_else(pre_Organization < 5, pre_Organization + 1, pre_Organization),   pre_Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   post_Source = dplyr::if_else(pre_Source < 4, pre_Source + 2, pre_Source),   pre_Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   post_Publish = pre_Publish + 2,   pre_Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   post_Write = pre_Write + 1,   pre_Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   post_Research = pre_Research + 1 )  items_single <- tibble::tibble(   Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4), )  # Set scale_labels for recodeCat function: # scale_labels as a named character vector, items in correct order: levels_min_ext <- c(   \"Minimal\" = \"1\", \"Slight\" = \"2\", \"Moderate\" = \"3\",   \"Good\" = \"4\", \"Extensive\" = \"5\" )  # bar_scale_labels as just the names from levels_min_ext: bar_scale_labels <- names(levels_min_ext)  # Question labels as a named vector with the naming structure # like this: c(\"new label\" = \"original variable name\"): question_labels <- c(   \"Publish a lot of high quality papers\" = \"Publish\",   \"Write a lot of research papers\" = \"Write\",   \"Research in a lab with faculty\" = \"Research\",   \"Organization of a large research project\" = \"Organization\",   \"Source work for a research paper\" = \"Source\" )  # Recode the numeric to factor variables using the levels from levels_min_ext and # select the factor variables:: cat_items <- blackstone::recodeCat(items, levels_min_ext) %>%                  dplyr::select(dplyr::where(is.factor)) cat_items_single <- blackstone::recodeCat(items_single, levels_min_ext) %>%                         dplyr::select(dplyr::where(is.factor))  # Pass the factor variables and the levels to stackedBarChart: stackedBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = NULL, percent_label = TRUE, width = NULL )  stackedBarChart(   df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,   question_labels = NULL, percent_label = TRUE, width = NULL )  stackedBarChart(   df = cat_items, pre_post = TRUE, scale_labels = bar_scale_labels,   question_labels = question_labels, question_order = FALSE, percent_label = TRUE, width = NULL )  stackedBarChart(   df = cat_items_single, pre_post = FALSE, scale_labels = bar_scale_labels,   question_labels = question_labels, question_order = FALSE, percent_label = TRUE, width = NULL )"},{"path":"https://zwcrowley.github.io/blackstone/reference/tblSumm.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"Creates summary table counts percentages data frame pre-processed dataSumm() returns flextable object.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/tblSumm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"","code":"tblSumm(df, totals = TRUE)"},{"path":"https://zwcrowley.github.io/blackstone/reference/tblSumm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"df tibble data frame pre-processed dataSumm() summary includes 5 columns: item, response, n_answers, percent_answers percent_answers_label. Item name original item, Response categorical responses possible item. n_answers count response, percent_answers percentage response percent_answers_label character variable percentage labelled percent sign use label. totals true, returns summary table last row totals, false, final row totals. Set True default.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/tblSumm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"flextable object 3 columns, response, counts percentages, Colors set Blackstone Research Evaluation branding","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/tblSumm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a summary table of counts and percentages from a data frame pre-processed with the dataSumm() and returns a flextable object. — tblSumm","text":"Response Percent Count Faculty 40% 8 Graduate student 25% 5 Postdoc 20% 4 Undergraduate student 15% 3 Total - 20","code":"data <- dplyr::tibble(   role = c(     \"Faculty\", \"Postdoc\", \"Undergraduate student\", \"Graduate student\",     \"Graduate student\", \"Postdoc\", \"Postdoc\", \"Faculty\",     \"Faculty\", \"Graduate student\", \"Graduate student\", \"Postdoc\",     \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Faculty\", \"Graduate student\",     \"Undergraduate student\", \"Undergraduate student\"   ) )  role_summ <- data %>%   dplyr::select(role) %>%   blackstone::dataSumm()  role_summ %>% tblSumm() .cl-adc358e4{}.cl-adbcefd6{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-adbcefea{font-family:'Arial';font-size:9pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-adbcefeb{font-family:'Arial';font-size:9pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-adbf143c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-adbf1446{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-adbf2918{width:1.564in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf2922{width:0.795in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf292c{width:0.686in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf2936{width:1.564in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf2937{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf2940{width:0.686in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf2941{width:1.564in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf294a{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf294b{width:0.686in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf2954{width:1.564in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf2955{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf295e{width:0.686in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf295f{width:1.564in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf2968{width:0.795in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adbf2969{width:0.686in;background-color:rgba(246, 246, 246, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}ResponsePercentCountFaculty40%8Graduate student25%5Postdoc20%4Undergraduate student15%3Total-20"},{"path":"https://zwcrowley.github.io/blackstone/reference/testFlextable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"Create Flextable Blackstone Research Evaluation Branding","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/testFlextable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"","code":"testFlextable(data)"},{"path":"https://zwcrowley.github.io/blackstone/reference/testFlextable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"data Required, tibble/data frame summary/descriptice test statistics.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/testFlextable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"nicely formatted table flextable() object.","code":""},{"path":"https://zwcrowley.github.io/blackstone/reference/testFlextable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Flextable in Blackstone Research and Evaluation Branding — testFlextable","text":"group variable Mean SD grad Organization 2.75 1.7078251 grad Source 2.50 1.2909944 grad Publish 1.75 0.9574271 grad Write 2.75 0.9574271 grad Research 2.50 1.2909944 undergrad Organization 2.80 1.3038405 undergrad Source 2.80 1.3038405 undergrad Publish 2.20 0.8366600 undergrad Write 3.20 0.8366600 undergrad Research 2.80 1.3038405","code":"# Example data: data <- dplyr::tibble(   Organization = c(1, 2, 3, 4, 5, 4, 3, 2, 1),   Source = c(2, 2, 3, 5, 4, 3, 2, 1, 2),   Publish = c(1, 1, 1, 2, 2, 2, 3, 3, 3),   Write = c(2, 2, 2, 3, 3, 3, 4, 4, 4),   Research = c(1, 1, 2, 2, 3, 3, 4, 4, 4),   group = factor(c(       \"grad\", \"undergrad\", \"grad\", \"undergrad\", \"grad\",       \"undergrad\", \"undergrad\", \"grad\", \"undergrad\"                     ), levels = c(\"grad\", \"undergrad\")     ) ) # Summarise the data into mean and sd for each numeric column, grouped by \"group\": data <- data %>% dplyr::group_by(group) %>%   dplyr::summarise(dplyr::across(                                    .cols = dplyr::where(is.numeric),                                    .fns =  list(Mean = mean, SD = sd),                                    .names = \"{col}_{fn}\"                                                   )) %>%              dplyr::ungroup() %>%              tidyr::pivot_longer(cols = -group,                                  names_pattern = \"([^_]+)_(.*)\",                                  names_to = c(\"variable\", \"stat\"),                                  values_to = \"value\",                                  values_drop_na = TRUE) %>%              tidyr::pivot_wider(names_from = stat, values_from = value)  # Make a nice table with the function: data %>% testFlextable() .cl-adf81c8c{}.cl-adf1341c{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-adf13430{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-adf4d2ca{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-adf4d2d4{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-adf4e9cc{width:0.918in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9d6{width:1.073in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9d7{width:0.702in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9e0{width:0.942in;background-color:rgba(44, 44, 79, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9e1{width:0.918in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9e2{width:1.073in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9ea{width:0.702in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9eb{width:0.942in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9ec{width:0.918in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9f4{width:1.073in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9f5{width:0.702in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-adf4e9fe{width:0.942in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(190, 190, 190, 1.00);border-top: 1pt solid rgba(190, 190, 190, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}groupvariableMeanSDgradOrganization2.751.7078251gradSource2.501.2909944gradPublish1.750.9574271gradWrite2.750.9574271gradResearch2.501.2909944undergradOrganization2.801.3038405undergradSource2.801.3038405undergradPublish2.200.8366600undergradWrite3.200.8366600undergradResearch2.801.3038405"},{"path":"https://zwcrowley.github.io/blackstone/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported package rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way.   enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions).   simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data pronoun object represents current slice data. variable name string, use .data pronoun subset variable [[.   Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround.   Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually :   Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data %>%     group_by(...) %>%     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data %>%     group_by(!!!dots) %>%     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars %>% summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data %>%     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data %>%     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"}]
